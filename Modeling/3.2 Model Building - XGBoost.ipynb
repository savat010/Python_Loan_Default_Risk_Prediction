{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e258d08",
   "metadata": {
    "papermill": {
     "duration": 0.028808,
     "end_time": "2022-04-22T03:17:36.687328",
     "exception": false,
     "start_time": "2022-04-22T03:17:36.658520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n",
    "In this notebook, we will run an XGBoost Classifier on the training data set that was created in the aggregation notebook. We will use Baysian Optimization to find the best hyper-parameters, fit a model for those best hyper-parameters, and then evaluate the model on the testing data set that was created in the aggregation notebook. Finally, we will find the best features from the XGBoost Classifier and re-run the classifier on those most important features to see if it improves the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9d38df4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:17:36.743206Z",
     "iopub.status.busy": "2022-04-22T03:17:36.742810Z",
     "iopub.status.idle": "2022-04-22T03:17:37.636396Z",
     "shell.execute_reply": "2022-04-22T03:17:37.635659Z"
    },
    "papermill": {
     "duration": 0.924426,
     "end_time": "2022-04-22T03:17:37.638668",
     "exception": false,
     "start_time": "2022-04-22T03:17:36.714242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "import re\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af27d2f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:17:37.695852Z",
     "iopub.status.busy": "2022-04-22T03:17:37.695180Z",
     "iopub.status.idle": "2022-04-22T03:18:22.501908Z",
     "shell.execute_reply": "2022-04-22T03:18:22.501161Z"
    },
    "papermill": {
     "duration": 44.837146,
     "end_time": "2022-04-22T03:18:22.503984",
     "exception": false,
     "start_time": "2022-04-22T03:17:37.666838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/msba-6420-predictive-analytics-project/Alldata_v3/train.csv')\n",
    "train = train.rename(columns = lambda x: re.sub('[^A-Za-z0-9_]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd4364cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:18:22.560045Z",
     "iopub.status.busy": "2022-04-22T03:18:22.559603Z",
     "iopub.status.idle": "2022-04-22T03:18:22.663152Z",
     "shell.execute_reply": "2022-04-22T03:18:22.662449Z"
    },
    "papermill": {
     "duration": 0.134595,
     "end_time": "2022-04-22T03:18:22.665854",
     "exception": false,
     "start_time": "2022-04-22T03:18:22.531259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e1af2a",
   "metadata": {
    "papermill": {
     "duration": 0.025805,
     "end_time": "2022-04-22T03:18:22.718840",
     "exception": false,
     "start_time": "2022-04-22T03:18:22.693035",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Bayesian Optimizer for XGBoost Model\n",
    "\n",
    "We will tune the following hyper-parameters using Bayesian Optimization to reduce the likelihood that the model overfits. We use Bayesian Optimization because it is much faster than grid-search. Rather than using all combinations of the hyper-parameters as done in grid-search, Bayesian optimization uses a surrogate model to choose the next point to evaluate by optimizing the acquisition function. We used a Gaussian Process for this surrogate model because it is flexible and gives us uncertainty estimates. \n",
    "\n",
    "* colsample_bylevel: the subsample ratio of columns when constructing each tree. Subsampling occurs once for every tree constructed\n",
    "* colsample_bytree: the subsample ratio of columns for each level. Subsampling occurs once for every new depth level reached in a tree. Columns are subsampled from the set of columns chosen for the current tree.\n",
    "* max_depth: this is the maximum depth of the tree. Increasing this value will make the model more complex and more likely to overfit.\n",
    "* reg_alpha: L1 regularization to control overfitting.\n",
    "* reg_lambda: L2 regularization to control overfitting.\n",
    "* gamma: this specifies the minimum loss reduction required to make a split. The more conservative the algorithm will be\n",
    "* min_child_weight: minimum sum of weights of all observations required in a child. Higher values are more likely to reduce overfitting, but too high of values can result in underfitting.\n",
    "* n_estimators: number of trees (or rounds) in an XGBoost model. The more trees, the more likely the model will overfit.\n",
    "\n",
    "We will keep the following hyper-parameters constant:\n",
    "* base_score: the probability of the 0 and 1 values in the Target data set. We will set it to 0.5, which is the default.\n",
    "* max_delta_step: maximum delta step we allow each treeâ€™s weight estimation to be. We will set it to 0, so there will be no constraint on the step. \n",
    "* nthread: this is number of parallel threads used to run XGBoost\n",
    "* learning_rate: the step size shrinkage used in update to prevent overfitting. We will set it to 0.01\n",
    "* subsample: the fraction of observations to be randomly samples for each tree. We will set it to 0.85\n",
    "* seed: this ensures we can generate reproducible results. This can be set to any number.\n",
    "* scale_pos_weight: this accounts for the imbalanced class by controling the balance of positive and negative weights. We will set it to a positive number, 2, because we have highly imbalanced data.\n",
    "\n",
    "After finding the best set of the above hyper-parameters that we tuned, we will build these hyper-parameters on the training data set and then evaluate the results on the testing set.\n",
    "\n",
    "The following sources were used to understand these hyper-parameters and bayesian optimization:\n",
    "* Bayesian Optimization Sources:\n",
    "    * https://towardsdatascience.com/hyperparameter-optimization-in-gradient-boosting-packages-with-bayesian-optimization-aaf1b27e7b90\n",
    "* XGBoost Sources:\n",
    "    * https://www.kaggle.com/code/prashant111/a-guide-on-xgboost-hyperparameters-tuning/notebook#A-Guide-on-XGBoost-hyperparameters-tuning\n",
    "    * https://coderzcolumn.com/tutorials/machine-learning/bayes-opt-bayesian-optimization-for-hyperparameters-tuning\n",
    "    * https://www.kaggle.com/code/christianlillelund/house-prices-xgboost-bayesianoptimization/notebook#Submission\n",
    "    * https://www.kaggle.com/code/willkoehrsen/model-tuning-results-random-vs-bayesian-opt#Implementation\n",
    "    * https://www.kaggle.com/code/snehithatiger/classification-using-random-search-xgboost\n",
    "    * https://github.com/dmlc/xgboost/blob/master/demo/guide-python/cross_validation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9967d1ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:18:22.773132Z",
     "iopub.status.busy": "2022-04-22T03:18:22.772901Z",
     "iopub.status.idle": "2022-04-22T03:18:22.828041Z",
     "shell.execute_reply": "2022-04-22T03:18:22.827279Z"
    },
    "papermill": {
     "duration": 0.08463,
     "end_time": "2022-04-22T03:18:22.830060",
     "exception": false,
     "start_time": "2022-04-22T03:18:22.745430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb.set_config(verbosity=0)\n",
    "\n",
    "def xgb_classifier(colsample_bytree, colsample_bylevel, n_estimators, max_depth, reg_alpha,\n",
    "                   reg_lambda, min_child_weight, gamma):\n",
    "    params = {\"base_score\": 0.5,\n",
    "              \"booster\": 'gbtree',\n",
    "              \"colsample_bylevel\": colsample_bylevel,\n",
    "              \"colsample_bytree\": colsample_bytree,\n",
    "              \"objective\" : \"binary:logistic\",\n",
    "              \"eval_metric\" : \"auc\",\n",
    "              \"max_delta_step\": 0,\n",
    "              \"max_depth\" : int(max_depth),\n",
    "              \"reg_alpha\" : reg_alpha,\n",
    "              \"reg_lambda\" : reg_lambda,\n",
    "              \"gamma\": gamma,\n",
    "              \"nthread\" : 4,\n",
    "              \"min_child_weight\" : min_child_weight,\n",
    "              \"learning_rate\" : 0.01,\n",
    "              \"subsample\" : 0.85,\n",
    "              \"seed\" : 27,\n",
    "              \"verbosity\" : 2,\n",
    "              \"n_estimators\": int(n_estimators),\n",
    "              \"tree_method\":'gpu_hist',\n",
    "              \"random_state\": 0,\n",
    "              \"scale_pos_weight\": 2\n",
    "             }\n",
    "    cv_result = xgb.cv(params,\n",
    "                       xgb.DMatrix(train.drop(columns=['SK_ID_CURR','TARGET']), train['TARGET']),\n",
    "                       1000,\n",
    "                       early_stopping_rounds=20,\n",
    "                       stratified=True,\n",
    "                       nfold=3)\n",
    "    return cv_result['test-auc-mean'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a25ca8d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:18:22.885294Z",
     "iopub.status.busy": "2022-04-22T03:18:22.885039Z",
     "iopub.status.idle": "2022-04-22T03:45:05.550897Z",
     "shell.execute_reply": "2022-04-22T03:45:05.549094Z"
    },
    "papermill": {
     "duration": 1602.775071,
     "end_time": "2022-04-22T03:45:05.631668",
     "exception": false,
     "start_time": "2022-04-22T03:18:22.856597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | colsam... |   gamma   | max_depth | min_ch... | n_esti... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "[03:18:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:18:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:18:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7664  \u001b[0m | \u001b[0m 0.8279  \u001b[0m | \u001b[0m 0.7242  \u001b[0m | \u001b[0m 0.07336 \u001b[0m | \u001b[0m 2.467   \u001b[0m | \u001b[0m 7.568   \u001b[0m | \u001b[0m 117.5   \u001b[0m | \u001b[0m 0.2092  \u001b[0m | \u001b[0m 0.8725  \u001b[0m |\n",
      "[03:20:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:20:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:20:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.7733  \u001b[0m | \u001b[95m 0.1319  \u001b[0m | \u001b[95m 0.3725  \u001b[0m | \u001b[95m 0.0295  \u001b[0m | \u001b[95m 3.134   \u001b[0m | \u001b[95m 7.41    \u001b[0m | \u001b[95m 770.7   \u001b[0m | \u001b[95m 0.797   \u001b[0m | \u001b[95m 0.3294  \u001b[0m |\n",
      "[03:22:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:22:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:22:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7324  \u001b[0m | \u001b[0m 0.09971 \u001b[0m | \u001b[0m 0.6311  \u001b[0m | \u001b[0m 0.03626 \u001b[0m | \u001b[0m 3.637   \u001b[0m | \u001b[0m 6.994   \u001b[0m | \u001b[0m 769.3   \u001b[0m | \u001b[0m 0.3898  \u001b[0m | \u001b[0m 0.1598  \u001b[0m |\n",
      "[03:23:00] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:23:01] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:23:02] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.7802  \u001b[0m | \u001b[95m 0.2539  \u001b[0m | \u001b[95m 0.8193  \u001b[0m | \u001b[95m 0.05943 \u001b[0m | \u001b[95m 4.571   \u001b[0m | \u001b[95m 4.759   \u001b[0m | \u001b[95m 1.888e+0\u001b[0m | \u001b[95m 0.1273  \u001b[0m | \u001b[95m 0.009401\u001b[0m |\n",
      "[03:25:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:25:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:25:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.781   \u001b[0m | \u001b[95m 0.6842  \u001b[0m | \u001b[95m 0.8222  \u001b[0m | \u001b[95m 0.01402 \u001b[0m | \u001b[95m 4.034   \u001b[0m | \u001b[95m 24.39   \u001b[0m | \u001b[95m 888.2   \u001b[0m | \u001b[95m 0.9191  \u001b[0m | \u001b[95m 0.339   \u001b[0m |\n",
      "[03:27:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:27:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:27:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.7847  \u001b[0m | \u001b[95m 0.5826  \u001b[0m | \u001b[95m 0.6181  \u001b[0m | \u001b[95m 0.04704 \u001b[0m | \u001b[95m 5.474   \u001b[0m | \u001b[95m 29.26   \u001b[0m | \u001b[95m 1.088e+0\u001b[0m | \u001b[95m 0.6512  \u001b[0m | \u001b[95m 0.4875  \u001b[0m |\n",
      "[03:30:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:30:27] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:30:27] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.7848  \u001b[0m | \u001b[95m 0.8378  \u001b[0m | \u001b[95m 0.8598  \u001b[0m | \u001b[95m 0.09978 \u001b[0m | \u001b[95m 5.496   \u001b[0m | \u001b[95m 2.033   \u001b[0m | \u001b[95m 506.1   \u001b[0m | \u001b[95m 0.007592\u001b[0m | \u001b[95m 0.3348  \u001b[0m |\n",
      "[03:33:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:33:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:33:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.766   \u001b[0m | \u001b[0m 0.6435  \u001b[0m | \u001b[0m 0.2682  \u001b[0m | \u001b[0m 0.042   \u001b[0m | \u001b[0m 2.673   \u001b[0m | \u001b[0m 13.67   \u001b[0m | \u001b[0m 1.234e+0\u001b[0m | \u001b[0m 0.277   \u001b[0m | \u001b[0m 0.03077 \u001b[0m |\n",
      "[03:35:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:35:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:35:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7838  \u001b[0m | \u001b[0m 0.1756  \u001b[0m | \u001b[0m 0.6886  \u001b[0m | \u001b[0m 0.07034 \u001b[0m | \u001b[0m 5.624   \u001b[0m | \u001b[0m 11.41   \u001b[0m | \u001b[0m 1.997e+0\u001b[0m | \u001b[0m 0.4788  \u001b[0m | \u001b[0m 0.5549  \u001b[0m |\n",
      "[03:37:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:37:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:37:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m 0.7851  \u001b[0m | \u001b[95m 0.734   \u001b[0m | \u001b[95m 0.7765  \u001b[0m | \u001b[95m 0.07087 \u001b[0m | \u001b[95m 5.314   \u001b[0m | \u001b[95m 13.38   \u001b[0m | \u001b[95m 779.5   \u001b[0m | \u001b[95m 0.8643  \u001b[0m | \u001b[95m 0.0167  \u001b[0m |\n",
      "[03:40:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:40:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:40:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7831  \u001b[0m | \u001b[0m 0.08289 \u001b[0m | \u001b[0m 0.8488  \u001b[0m | \u001b[0m 0.02601 \u001b[0m | \u001b[0m 5.052   \u001b[0m | \u001b[0m 24.73   \u001b[0m | \u001b[0m 888.0   \u001b[0m | \u001b[0m 0.4506  \u001b[0m | \u001b[0m 0.1459  \u001b[0m |\n",
      "[03:42:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:42:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:42:59] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7809  \u001b[0m | \u001b[0m 0.9426  \u001b[0m | \u001b[0m 0.3207  \u001b[0m | \u001b[0m 0.02723 \u001b[0m | \u001b[0m 4.854   \u001b[0m | \u001b[0m 1.515   \u001b[0m | \u001b[0m 505.3   \u001b[0m | \u001b[0m 0.1383  \u001b[0m | \u001b[0m 0.355   \u001b[0m |\n",
      "=========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "xgbBO = BayesianOptimization(xgb_classifier, {  'colsample_bytree':(0, 1),\n",
    "                                                'colsample_bylevel': (0,1),\n",
    "                                                'max_depth': (2, 6),\n",
    "                                                'reg_alpha': (0.0, 1.0),\n",
    "                                                'reg_lambda': (0.0, 1.0),\n",
    "                                                'min_child_weight': (0, 30),\n",
    "                                                'n_estimators': (100, 2000),\n",
    "                                                'gamma': (0.0, 0.1)\n",
    "                                                })\n",
    "\n",
    "xgbBO.maximize(n_iter=10, init_points=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd665160",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:45:05.796793Z",
     "iopub.status.busy": "2022-04-22T03:45:05.796132Z",
     "iopub.status.idle": "2022-04-22T03:45:05.818902Z",
     "shell.execute_reply": "2022-04-22T03:45:05.807803Z"
    },
    "papermill": {
     "duration": 0.107049,
     "end_time": "2022-04-22T03:45:05.822040",
     "exception": false,
     "start_time": "2022-04-22T03:45:05.714991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bylevel': 0.7340040345842987,\n",
       " 'colsample_bytree': 0.7764728602209735,\n",
       " 'gamma': 0.07087099958722323,\n",
       " 'max_depth': 5.3139635424804466,\n",
       " 'min_child_weight': 13.384729804665435,\n",
       " 'n_estimators': 779.5130010546751,\n",
       " 'reg_alpha': 0.8643051625067838,\n",
       " 'reg_lambda': 0.016702462769826898}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = np.array([i['target'] for i in xgbBO.res])\n",
    "xgbBO.res[result.argmax()]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52cc3f02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:45:06.008980Z",
     "iopub.status.busy": "2022-04-22T03:45:06.008586Z",
     "iopub.status.idle": "2022-04-22T03:45:06.017630Z",
     "shell.execute_reply": "2022-04-22T03:45:06.016750Z"
    },
    "papermill": {
     "duration": 0.106267,
     "end_time": "2022-04-22T03:45:06.020086",
     "exception": false,
     "start_time": "2022-04-22T03:45:05.913819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76643033, 0.77330533, 0.732362  , 0.78021933, 0.78096233,\n",
       "       0.78466367, 0.78483533, 0.76604533, 0.783836  , 0.78510933,\n",
       "       0.78307567, 0.78088767])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298273b0",
   "metadata": {
    "papermill": {
     "duration": 0.045488,
     "end_time": "2022-04-22T03:45:06.115658",
     "exception": false,
     "start_time": "2022-04-22T03:45:06.070170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Build XGBoost Model using Best Hyperparameters from Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bec103c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:45:06.206320Z",
     "iopub.status.busy": "2022-04-22T03:45:06.205561Z",
     "iopub.status.idle": "2022-04-22T03:45:06.213384Z",
     "shell.execute_reply": "2022-04-22T03:45:06.212635Z"
    },
    "papermill": {
     "duration": 0.054958,
     "end_time": "2022-04-22T03:45:06.215120",
     "exception": false,
     "start_time": "2022-04-22T03:45:06.160162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "colsample_bytree = xgbBO.max[\"params\"][\"colsample_bytree\"]\n",
    "colsample_bylevel = xgbBO.max[\"params\"][\"colsample_bylevel\"]\n",
    "max_depth = int(xgbBO.max[\"params\"][\"max_depth\"])\n",
    "reg_alpha = xgbBO.max[\"params\"][\"reg_alpha\"]\n",
    "reg_lambda = xgbBO.max[\"params\"][\"reg_lambda\"]\n",
    "min_child_weight = xgbBO.max[\"params\"][\"min_child_weight\"]\n",
    "n_estimators = xgbBO.max[\"params\"][\"n_estimators\"]\n",
    "gamma = xgbBO.max[\"params\"][\"gamma\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfad9b1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:45:06.317053Z",
     "iopub.status.busy": "2022-04-22T03:45:06.316368Z",
     "iopub.status.idle": "2022-04-22T03:46:04.223261Z",
     "shell.execute_reply": "2022-04-22T03:46:04.222567Z"
    },
    "papermill": {
     "duration": 58.000673,
     "end_time": "2022-04-22T03:46:04.266149",
     "exception": false,
     "start_time": "2022-04-22T03:45:06.265476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:45:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"is_unbalance\", \"nthreads\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "              colsample_bylevel=0.7340040345842987, colsample_bynode=1,\n",
       "              colsample_bytree=0.7764728602209735, enable_categorical=False,\n",
       "              eval_metric='auc', gamma=0.07087099958722323, gpu_id=0,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              is_unbalance=True, learning_rate=0.01, max_delta_step=0,\n",
       "              max_depth=5, min_child_weight=13.384729804665435, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=779, n_jobs=2, nthreads=4,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=27,\n",
       "              reg_alpha=0.8643051625067838, reg_lambda=0.016702462769826898,\n",
       "              scale_pos_weight=1, seed=27, subsample=0.85,\n",
       "              tree_method='gpu_hist', ...)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(booster= 'gbtree',\n",
    "    objective= \"binary:logistic\",\n",
    "    eval_metric = \"auc\", \n",
    "    is_unbalance= True,\n",
    "    nthreads = 4,\n",
    "    learning_rate = 0.01,\n",
    "    subsample = 0.85,\n",
    "    seed = 27,\n",
    "    verbosity = 2,\n",
    "    tree_method='gpu_hist',\n",
    "    gamma= gamma,\n",
    "    max_depth= max_depth,\n",
    "    min_child_weight= min_child_weight,\n",
    "    n_estimators= int(n_estimators),\n",
    "    reg_alpha= reg_alpha,\n",
    "    reg_lambda= reg_lambda,\n",
    "    colsample_bytree = colsample_bytree,\n",
    "    colsample_bylevel = colsample_bylevel) \n",
    "\n",
    "clf.fit(train.drop(columns=['SK_ID_CURR','TARGET']), train['TARGET'], eval_metric= 'auc',verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02fc17ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:46:04.357855Z",
     "iopub.status.busy": "2022-04-22T03:46:04.357145Z",
     "iopub.status.idle": "2022-04-22T03:46:04.505046Z",
     "shell.execute_reply": "2022-04-22T03:46:04.504176Z"
    },
    "papermill": {
     "duration": 0.196327,
     "end_time": "2022-04-22T03:46:04.507543",
     "exception": false,
     "start_time": "2022-04-22T03:46:04.311216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9560156d",
   "metadata": {
    "papermill": {
     "duration": 0.043503,
     "end_time": "2022-04-22T03:46:04.597149",
     "exception": false,
     "start_time": "2022-04-22T03:46:04.553646",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluate XGBoost Performance on Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "483aaa23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:46:04.687149Z",
     "iopub.status.busy": "2022-04-22T03:46:04.686892Z",
     "iopub.status.idle": "2022-04-22T03:46:12.315758Z",
     "shell.execute_reply": "2022-04-22T03:46:12.314963Z"
    },
    "papermill": {
     "duration": 7.675939,
     "end_time": "2022-04-22T03:46:12.317924",
     "exception": false,
     "start_time": "2022-04-22T03:46:04.641985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('/kaggle/input/msba-6420-predictive-analytics-project/Alldata_v3/test.csv')\n",
    "test = test.rename(columns = lambda x: re.sub('[^A-Za-z0-9_]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33f2436a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:46:12.411826Z",
     "iopub.status.busy": "2022-04-22T03:46:12.411547Z",
     "iopub.status.idle": "2022-04-22T03:46:14.357885Z",
     "shell.execute_reply": "2022-04-22T03:46:14.357083Z"
    },
    "papermill": {
     "duration": 1.99635,
     "end_time": "2022-04-22T03:46:14.360358",
     "exception": false,
     "start_time": "2022-04-22T03:46:12.364008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = clf.predict_proba(test.drop(columns=['SK_ID_CURR']))\n",
    "result = pd.DataFrame({'SK_ID_CURR':test['SK_ID_CURR'],\n",
    "              'TARGET':pd.DataFrame(prediction)[1]})\n",
    "\n",
    "result.to_csv(\"Result_XGB.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f021da95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:46:14.453643Z",
     "iopub.status.busy": "2022-04-22T03:46:14.453406Z",
     "iopub.status.idle": "2022-04-22T03:46:14.588005Z",
     "shell.execute_reply": "2022-04-22T03:46:14.587097Z"
    },
    "papermill": {
     "duration": 0.183357,
     "end_time": "2022-04-22T03:46:14.590010",
     "exception": false,
     "start_time": "2022-04-22T03:46:14.406653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e875644f",
   "metadata": {
    "papermill": {
     "duration": 0.046292,
     "end_time": "2022-04-22T03:46:14.682603",
     "exception": false,
     "start_time": "2022-04-22T03:46:14.636311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Selection: Find Top Features from XGBoost Model\n",
    "\n",
    "Now we will find the best features from the XGBoost model with the best hyper-parameters. When calculating the importance of the features, we will use the metric 'weight', which shows the number of times the feature is used to split data.\n",
    "\n",
    "After finding the most important features, we will re-run the model on the most important features to improve our model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "383e7b6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:46:14.778258Z",
     "iopub.status.busy": "2022-04-22T03:46:14.777548Z",
     "iopub.status.idle": "2022-04-22T03:46:49.324687Z",
     "shell.execute_reply": "2022-04-22T03:46:49.323888Z"
    },
    "papermill": {
     "duration": 34.598997,
     "end_time": "2022-04-22T03:46:49.327305",
     "exception": false,
     "start_time": "2022-04-22T03:46:14.728308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/msba-6420-predictive-analytics-project/Alldata_v3/train.csv')\n",
    "train = train.rename(columns = lambda x: re.sub('[^A-Za-z0-9_]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e41107b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:46:49.422310Z",
     "iopub.status.busy": "2022-04-22T03:46:49.422086Z",
     "iopub.status.idle": "2022-04-22T03:46:49.556743Z",
     "shell.execute_reply": "2022-04-22T03:46:49.555935Z"
    },
    "papermill": {
     "duration": 0.183863,
     "end_time": "2022-04-22T03:46:49.558450",
     "exception": false,
     "start_time": "2022-04-22T03:46:49.374587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e1f743b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:46:49.654838Z",
     "iopub.status.busy": "2022-04-22T03:46:49.654568Z",
     "iopub.status.idle": "2022-04-22T03:46:49.660166Z",
     "shell.execute_reply": "2022-04-22T03:46:49.659420Z"
    },
    "papermill": {
     "duration": 0.056504,
     "end_time": "2022-04-22T03:46:49.661981",
     "exception": false,
     "start_time": "2022-04-22T03:46:49.605477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(booster= 'gbtree',\n",
    "    objective= \"binary:logistic\",\n",
    "    eval_metric = \"auc\", \n",
    "    is_unbalance= True,\n",
    "    nthreads = 4,\n",
    "    learning_rate = 0.01,\n",
    "    subsample = 0.85,\n",
    "    seed = 27,\n",
    "    verbosity = 2,\n",
    "    tree_method='gpu_hist',\n",
    "    gamma= gamma,\n",
    "    max_depth= max_depth,\n",
    "    min_child_weight= min_child_weight,\n",
    "    n_estimators= int(n_estimators),\n",
    "    reg_alpha= reg_alpha,\n",
    "    reg_lambda= reg_lambda,\n",
    "    colsample_bytree = colsample_bytree,\n",
    "    colsample_bylevel = colsample_bylevel) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09fd5a0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:46:49.779657Z",
     "iopub.status.busy": "2022-04-22T03:46:49.779211Z",
     "iopub.status.idle": "2022-04-22T03:47:47.533320Z",
     "shell.execute_reply": "2022-04-22T03:47:47.532548Z"
    },
    "papermill": {
     "duration": 57.87574,
     "end_time": "2022-04-22T03:47:47.582856",
     "exception": false,
     "start_time": "2022-04-22T03:46:49.707116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:46:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"is_unbalance\", \"nthreads\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "              colsample_bylevel=0.7340040345842987, colsample_bynode=1,\n",
       "              colsample_bytree=0.7764728602209735, enable_categorical=False,\n",
       "              eval_metric='auc', gamma=0.07087099958722323, gpu_id=0,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              is_unbalance=True, learning_rate=0.01, max_delta_step=0,\n",
       "              max_depth=5, min_child_weight=13.384729804665435, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=779, n_jobs=2, nthreads=4,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=27,\n",
       "              reg_alpha=0.8643051625067838, reg_lambda=0.016702462769826898,\n",
       "              scale_pos_weight=1, seed=27, subsample=0.85,\n",
       "              tree_method='gpu_hist', ...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train.drop(columns=['SK_ID_CURR','TARGET']), train['TARGET'], eval_metric= 'auc',verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5db589af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:47:47.678819Z",
     "iopub.status.busy": "2022-04-22T03:47:47.678558Z",
     "iopub.status.idle": "2022-04-22T03:47:47.685431Z",
     "shell.execute_reply": "2022-04-22T03:47:47.684724Z"
    },
    "papermill": {
     "duration": 0.057489,
     "end_time": "2022-04-22T03:47:47.687314",
     "exception": false,
     "start_time": "2022-04-22T03:47:47.629825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "importance = clf.get_booster().get_score(importance_type='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4f8e3a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:47:47.783000Z",
     "iopub.status.busy": "2022-04-22T03:47:47.782642Z",
     "iopub.status.idle": "2022-04-22T03:47:47.786633Z",
     "shell.execute_reply": "2022-04-22T03:47:47.785963Z"
    },
    "papermill": {
     "duration": 0.05339,
     "end_time": "2022-04-22T03:47:47.788479",
     "exception": false,
     "start_time": "2022-04-22T03:47:47.735089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keys = list(importance.keys())\n",
    "values = list(importance.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5db808f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:47:47.908065Z",
     "iopub.status.busy": "2022-04-22T03:47:47.907729Z",
     "iopub.status.idle": "2022-04-22T03:47:47.919534Z",
     "shell.execute_reply": "2022-04-22T03:47:47.918821Z"
    },
    "papermill": {
     "duration": 0.087587,
     "end_time": "2022-04-22T03:47:47.922238",
     "exception": false,
     "start_time": "2022-04-22T03:47:47.834651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "important_features = pd.DataFrame({'features': keys, 'importance': values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e90b0915",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:47:48.076745Z",
     "iopub.status.busy": "2022-04-22T03:47:48.076337Z",
     "iopub.status.idle": "2022-04-22T03:47:48.085095Z",
     "shell.execute_reply": "2022-04-22T03:47:48.084370Z"
    },
    "papermill": {
     "duration": 0.087212,
     "end_time": "2022-04-22T03:47:48.087608",
     "exception": false,
     "start_time": "2022-04-22T03:47:48.000396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "most_important = important_features.sort_values(by='importance',ascending=False).reset_index(drop=True)[:400]['features'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0303e84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:47:48.240915Z",
     "iopub.status.busy": "2022-04-22T03:47:48.240500Z",
     "iopub.status.idle": "2022-04-22T03:47:48.562144Z",
     "shell.execute_reply": "2022-04-22T03:47:48.561433Z"
    },
    "papermill": {
     "duration": 0.400581,
     "end_time": "2022-04-22T03:47:48.565063",
     "exception": false,
     "start_time": "2022-04-22T03:47:48.164482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_important_features = train.filter(most_important)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a28a0e",
   "metadata": {
    "papermill": {
     "duration": 0.075469,
     "end_time": "2022-04-22T03:47:48.717758",
     "exception": false,
     "start_time": "2022-04-22T03:47:48.642289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Re-run XGBoost Model on Best Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92fa5a10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:47:48.879701Z",
     "iopub.status.busy": "2022-04-22T03:47:48.879280Z",
     "iopub.status.idle": "2022-04-22T03:48:11.257454Z",
     "shell.execute_reply": "2022-04-22T03:48:11.256620Z"
    },
    "papermill": {
     "duration": 22.456313,
     "end_time": "2022-04-22T03:48:11.259608",
     "exception": false,
     "start_time": "2022-04-22T03:47:48.803295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:47:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"is_unbalance\", \"nthreads\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "              colsample_bylevel=0.7340040345842987, colsample_bynode=1,\n",
       "              colsample_bytree=0.7764728602209735, enable_categorical=False,\n",
       "              eval_metric='auc', gamma=0.07087099958722323, gpu_id=0,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              is_unbalance=True, learning_rate=0.01, max_delta_step=0,\n",
       "              max_depth=5, min_child_weight=13.384729804665435, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=779, n_jobs=2, nthreads=4,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=27,\n",
       "              reg_alpha=0.8643051625067838, reg_lambda=0.016702462769826898,\n",
       "              scale_pos_weight=1, seed=27, subsample=0.85,\n",
       "              tree_method='gpu_hist', ...)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(booster= 'gbtree',\n",
    "    objective= \"binary:logistic\",\n",
    "    eval_metric = \"auc\", \n",
    "    is_unbalance= True,\n",
    "    nthreads = 4,\n",
    "    learning_rate = 0.01,\n",
    "    subsample = 0.85,\n",
    "    seed = 27,\n",
    "    verbosity = 2,\n",
    "    tree_method='gpu_hist',\n",
    "    gamma= gamma,\n",
    "    max_depth= max_depth,\n",
    "    min_child_weight= min_child_weight,\n",
    "    n_estimators= int(n_estimators),\n",
    "    reg_alpha= reg_alpha,\n",
    "    reg_lambda= reg_lambda,\n",
    "    colsample_bytree = colsample_bytree,\n",
    "    colsample_bylevel = colsample_bylevel) \n",
    "\n",
    "clf.fit(train_important_features, train['TARGET'], eval_metric= 'auc',verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0f8163a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:48:11.356360Z",
     "iopub.status.busy": "2022-04-22T03:48:11.355628Z",
     "iopub.status.idle": "2022-04-22T03:48:11.493286Z",
     "shell.execute_reply": "2022-04-22T03:48:11.492572Z"
    },
    "papermill": {
     "duration": 0.187588,
     "end_time": "2022-04-22T03:48:11.495116",
     "exception": false,
     "start_time": "2022-04-22T03:48:11.307528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_important_features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e9feda",
   "metadata": {
    "papermill": {
     "duration": 0.047487,
     "end_time": "2022-04-22T03:48:11.591556",
     "exception": false,
     "start_time": "2022-04-22T03:48:11.544069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluate XGBoost Performance on Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a82f43e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:48:11.689410Z",
     "iopub.status.busy": "2022-04-22T03:48:11.688908Z",
     "iopub.status.idle": "2022-04-22T03:48:16.928046Z",
     "shell.execute_reply": "2022-04-22T03:48:16.927244Z"
    },
    "papermill": {
     "duration": 5.290523,
     "end_time": "2022-04-22T03:48:16.930138",
     "exception": false,
     "start_time": "2022-04-22T03:48:11.639615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('/kaggle/input/msba-6420-predictive-analytics-project/Alldata_v3/test.csv')\n",
    "test = test.rename(columns = lambda x: re.sub('[^A-Za-z0-9_]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0f54f84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T03:48:17.029481Z",
     "iopub.status.busy": "2022-04-22T03:48:17.029218Z",
     "iopub.status.idle": "2022-04-22T03:48:18.819061Z",
     "shell.execute_reply": "2022-04-22T03:48:18.818323Z"
    },
    "papermill": {
     "duration": 1.843364,
     "end_time": "2022-04-22T03:48:18.821126",
     "exception": false,
     "start_time": "2022-04-22T03:48:16.977762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = clf.predict_proba(test.filter(most_important))\n",
    "result = pd.DataFrame({'SK_ID_CURR':test['SK_ID_CURR'],\n",
    "              'TARGET':pd.DataFrame(prediction)[1]})\n",
    "\n",
    "result.to_csv(\"Result_XGB_top400.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff10075",
   "metadata": {
    "papermill": {
     "duration": 0.049009,
     "end_time": "2022-04-22T03:48:18.919472",
     "exception": false,
     "start_time": "2022-04-22T03:48:18.870463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1852.207111,
   "end_time": "2022-04-22T03:48:20.291041",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-22T03:17:28.083930",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
