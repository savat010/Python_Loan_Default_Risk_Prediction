{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 3.3 Model Building - LightGBM\n\nLightGBM is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages:\n* Faster training speed and higher efficiency.\n* Lower memory usage.\n* Better accuracy.\n* Support of parallel, distributed, and GPU learning.\n* Capable of handling large-scale data.","metadata":{}},{"cell_type":"markdown","source":"## Installing Dependecies for LGBM with GPU [[1]](https://www.kaggle.com/code/abhishek/running-lightgbm-on-gpu/notebook)","metadata":{}},{"cell_type":"code","source":"# !pip uninstall -y lightgbm\n# !apt-get install -y libboost-all-dev\n# !git clone --recursive https://github.com/Microsoft/LightGBM","metadata":{"execution":{"iopub.status.busy":"2022-04-22T07:27:55.014140Z","iopub.status.idle":"2022-04-22T07:27:55.014997Z","shell.execute_reply.started":"2022-04-22T07:27:55.014621Z","shell.execute_reply":"2022-04-22T07:27:55.014680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%bash\n# cd LightGBM\n# rm -r build\n# mkdir build\n# cd build\n# cmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..\n# make -j$(nproc)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T07:27:55.016370Z","iopub.status.idle":"2022-04-22T07:27:55.017259Z","shell.execute_reply.started":"2022-04-22T07:27:55.016940Z","shell.execute_reply":"2022-04-22T07:27:55.016968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !cd LightGBM/python-package/;python setup.py install --precompile","metadata":{"execution":{"iopub.status.busy":"2022-04-22T07:27:55.019102Z","iopub.status.idle":"2022-04-22T07:27:55.019867Z","shell.execute_reply.started":"2022-04-22T07:27:55.019483Z","shell.execute_reply":"2022-04-22T07:27:55.019508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n# !rm -r LightGBM","metadata":{"execution":{"iopub.status.busy":"2022-04-22T07:27:55.021337Z","iopub.status.idle":"2022-04-22T07:27:55.021980Z","shell.execute_reply.started":"2022-04-22T07:27:55.021714Z","shell.execute_reply":"2022-04-22T07:27:55.021739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport os\nimport gc\nimport psutil\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import KFold\n\nimport lightgbm as lgb\nfrom bayes_opt import BayesianOptimization","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:07:03.249350Z","iopub.execute_input":"2022-04-22T15:07:03.249675Z","iopub.status.idle":"2022-04-22T15:07:06.190464Z","shell.execute_reply.started":"2022-04-22T15:07:03.249571Z","shell.execute_reply":"2022-04-22T15:07:06.189672Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"## Importing aggregated training dataset\n\n[Aggregated Dataset](https://www.kaggle.com/datasets/manishcjain/msba-6420-predictive-analytics-project)","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/msba-6420-predictive-analytics-project/Alldata_v3/train.csv\",low_memory=False)\ntrain = train.rename(columns = lambda x: re.sub('[^A-Za-z0-9_]+', '', x))\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:07:06.192285Z","iopub.execute_input":"2022-04-22T15:07:06.192550Z","iopub.status.idle":"2022-04-22T15:08:17.209863Z","shell.execute_reply.started":"2022-04-22T15:07:06.192514Z","shell.execute_reply":"2022-04-22T15:08:17.209088Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   SK_ID_CURR  TARGET  CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n0      100002     1.0            0             0                0   \n1      100003     0.0            1             0                1   \n2      100004     0.0            0             1                0   \n3      100006     0.0            1             0                0   \n4      100007     0.0            0             0                0   \n\n   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n0             0          202500.0    406597.5      24700.5         351000.0   \n1             0          270000.0   1293502.5      35698.5        1129500.0   \n2             0           67500.0    135000.0       6750.0         135000.0   \n3             0          135000.0    312682.5      29686.5         297000.0   \n4             0          121500.0    513000.0      21865.5         513000.0   \n\n   ...  INS_AMT_INSTALMENT_MEAN  INS_AMT_INSTALMENT_SUM  INS_AMT_PAYMENT_MIN  \\\n0  ...             11559.247105              219625.695             9251.775   \n1  ...             64754.586000             1618864.650             6662.970   \n2  ...              7096.155000               21288.465             5357.250   \n3  ...             62947.088438             1007153.415             2482.920   \n4  ...             12666.444545              835985.340                0.180   \n\n   INS_AMT_PAYMENT_MAX  INS_AMT_PAYMENT_MEAN  INS_AMT_PAYMENT_SUM  \\\n0            53093.745          11559.247105           219625.695   \n1           560835.360          64754.586000          1618864.650   \n2            10573.965           7096.155000            21288.465   \n3           691786.890          62947.088438          1007153.415   \n4            22678.785          12214.060227           806127.975   \n\n   INS_DAYS_ENTRY_PAYMENT_MIN  INS_DAYS_ENTRY_PAYMENT_MAX  \\\n0                      -587.0                       -49.0   \n1                     -2324.0                      -544.0   \n2                      -795.0                      -727.0   \n3                      -575.0                       -12.0   \n4                     -2318.0                       -14.0   \n\n   INS_DAYS_ENTRY_PAYMENT_MEAN  INS_DAYS_ENTRY_PAYMENT_SUM  \n0                  -315.421053                     -5993.0  \n1                 -1385.320000                    -34633.0  \n2                  -761.666667                     -2285.0  \n3                  -271.625000                     -4346.0  \n4                 -1032.242424                    -68128.0  \n\n[5 rows x 904 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SK_ID_CURR</th>\n      <th>TARGET</th>\n      <th>CODE_GENDER</th>\n      <th>FLAG_OWN_CAR</th>\n      <th>FLAG_OWN_REALTY</th>\n      <th>CNT_CHILDREN</th>\n      <th>AMT_INCOME_TOTAL</th>\n      <th>AMT_CREDIT</th>\n      <th>AMT_ANNUITY</th>\n      <th>AMT_GOODS_PRICE</th>\n      <th>...</th>\n      <th>INS_AMT_INSTALMENT_MEAN</th>\n      <th>INS_AMT_INSTALMENT_SUM</th>\n      <th>INS_AMT_PAYMENT_MIN</th>\n      <th>INS_AMT_PAYMENT_MAX</th>\n      <th>INS_AMT_PAYMENT_MEAN</th>\n      <th>INS_AMT_PAYMENT_SUM</th>\n      <th>INS_DAYS_ENTRY_PAYMENT_MIN</th>\n      <th>INS_DAYS_ENTRY_PAYMENT_MAX</th>\n      <th>INS_DAYS_ENTRY_PAYMENT_MEAN</th>\n      <th>INS_DAYS_ENTRY_PAYMENT_SUM</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100002</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>202500.0</td>\n      <td>406597.5</td>\n      <td>24700.5</td>\n      <td>351000.0</td>\n      <td>...</td>\n      <td>11559.247105</td>\n      <td>219625.695</td>\n      <td>9251.775</td>\n      <td>53093.745</td>\n      <td>11559.247105</td>\n      <td>219625.695</td>\n      <td>-587.0</td>\n      <td>-49.0</td>\n      <td>-315.421053</td>\n      <td>-5993.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100003</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>270000.0</td>\n      <td>1293502.5</td>\n      <td>35698.5</td>\n      <td>1129500.0</td>\n      <td>...</td>\n      <td>64754.586000</td>\n      <td>1618864.650</td>\n      <td>6662.970</td>\n      <td>560835.360</td>\n      <td>64754.586000</td>\n      <td>1618864.650</td>\n      <td>-2324.0</td>\n      <td>-544.0</td>\n      <td>-1385.320000</td>\n      <td>-34633.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100004</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>67500.0</td>\n      <td>135000.0</td>\n      <td>6750.0</td>\n      <td>135000.0</td>\n      <td>...</td>\n      <td>7096.155000</td>\n      <td>21288.465</td>\n      <td>5357.250</td>\n      <td>10573.965</td>\n      <td>7096.155000</td>\n      <td>21288.465</td>\n      <td>-795.0</td>\n      <td>-727.0</td>\n      <td>-761.666667</td>\n      <td>-2285.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100006</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>135000.0</td>\n      <td>312682.5</td>\n      <td>29686.5</td>\n      <td>297000.0</td>\n      <td>...</td>\n      <td>62947.088438</td>\n      <td>1007153.415</td>\n      <td>2482.920</td>\n      <td>691786.890</td>\n      <td>62947.088438</td>\n      <td>1007153.415</td>\n      <td>-575.0</td>\n      <td>-12.0</td>\n      <td>-271.625000</td>\n      <td>-4346.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100007</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>121500.0</td>\n      <td>513000.0</td>\n      <td>21865.5</td>\n      <td>513000.0</td>\n      <td>...</td>\n      <td>12666.444545</td>\n      <td>835985.340</td>\n      <td>0.180</td>\n      <td>22678.785</td>\n      <td>12214.060227</td>\n      <td>806127.975</td>\n      <td>-2318.0</td>\n      <td>-14.0</td>\n      <td>-1032.242424</td>\n      <td>-68128.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 904 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Using Bayesian Optimization for Hyperparameter tuning LGBM Classifier\n**Bayesian Optimization**[[2]](https://github.com/fmfn/BayesianOptimization)\n> Bayesian optimization works by constructing a posterior distribution of functions (gaussian process) that best describes the function you want to optimize. As the number of observations grows, the posterior distribution improves, and the algorithm becomes more certain of which regions in parameter space are worth exploring and which are not.\n\n**HyperParameters for LightGBM**[[3]](https://www.kaggle.com/code/sz8416/simple-bayesian-optimization-for-lightgbm) [[4]](https://www.kaggle.com/code/hikmetsezen/base-model-with-0-804-auc-on-home-credit) [[5]](https://lightgbm.readthedocs.io/en/latest/Parameters.html)\n* **n_estimators** - Number of boosting iterations\n* **learning_rate** - Shrinkage rate of the gradient\n* **max_depth** - limit the max depth for tree model\n* **num_leaves** - max number of leaves in one tree\n* **colsample_bytree** - Size of the subset of features on each iteration (tree) as a % of total size \n* **bagging_fraction** - Randomly select part of data without resampling\n* **reg_alpha** -L1 regularization\n* **lambda_l2** - L2 regularization\n* **min_split_gain** - the minimal gain to perform split\n* **min_child_weight** - minimal sum hessian in one leaf.\n* **min_child_samples** - minimal number of data in one leaf\n* **scale_pos_weight** - weight of labels with positive class","metadata":{}},{"cell_type":"code","source":"def LGB_CV(n_estimators,learning_rate, max_depth, num_leaves, colsample_bytree,bagging_fraction,reg_alpha,lambda_l2,min_split_gain,min_child_weight,min_child_samples):\n    params = {'application':'binary',\n              'early_stopping_round':40,\n              'metric':'auc',\n              'device':'gpu',\n              'gpu_platform_id':0,\n              'gpu_device_id':0,\n              'max_bin':150\n             }\n    params[\"n_estimators\"] = int(n_estimators)\n    params[\"learning_rate\"] = learning_rate\n    params[\"num_leaves\"] = int(round(num_leaves))\n    params['colsample_bytree'] = max(min(colsample_bytree, 1), 0)\n    params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n    params['max_depth'] = int(round(max_depth))\n    params['reg_alpha'] = max(reg_alpha, 0)\n    params['lambda_l2'] = max(lambda_l2, 0)\n    params['min_split_gain'] = min_split_gain\n    params['min_child_weight'] = min_child_weight\n    params['min_child_samples'] = int(round(min_child_samples))\n    cv_result = lgb.cv(params, lgb.Dataset(data=train.drop(columns=['TARGET','SK_ID_CURR']), label=train['TARGET']), nfold=5, seed=6, stratified=True,metrics=['auc'],verbose_eval=False)\n    \n    return max(cv_result['auc-mean'])","metadata":{"execution":{"iopub.status.busy":"2022-04-22T08:02:07.829479Z","iopub.execute_input":"2022-04-22T08:02:07.829798Z","iopub.status.idle":"2022-04-22T08:02:07.839133Z","shell.execute_reply.started":"2022-04-22T08:02:07.829761Z","shell.execute_reply":"2022-04-22T08:02:07.838509Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"LightGBM_BO = BayesianOptimization(LGB_CV,{\n    'num_leaves': (10, 30),\n    'n_estimators':(3000,10000),\n    'learning_rate':(0.009,0.2),\n    'colsample_bytree': (0.1, 0.9),\n    'bagging_fraction': (0.5, 1),\n    'max_depth': (5, 13),\n    'reg_alpha': (0, 10),\n    'lambda_l2': (0, 10),\n    'min_split_gain': (0.001, 0.3),\n    'min_child_weight': (1, 50),\n    'min_child_samples':(50,200)\n},random_state=0, verbose=200)\n\nLightGBM_BO.maximize(init_points=1, n_iter=20)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-04-22T08:02:07.840129Z","iopub.execute_input":"2022-04-22T08:02:07.840670Z","iopub.status.idle":"2022-04-22T12:42:25.181970Z","shell.execute_reply.started":"2022-04-22T08:02:07.840630Z","shell.execute_reply":"2022-04-22T12:42:25.181207Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"|   iter    |  target   | baggin... | colsam... | lambda_l2 | learni... | max_depth | min_ch... | min_ch... | min_sp... | n_esti... | num_le... | reg_alpha |\n-------------------------------------------------------------------------------------------------------------------------------------------------------------\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.207553 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.206304 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.206365 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.207669 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205572 secs. 1 sparse feature groups\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7913  \u001b[0m | \u001b[0m 0.7744  \u001b[0m | \u001b[0m 0.6722  \u001b[0m | \u001b[0m 6.028   \u001b[0m | \u001b[0m 0.1131  \u001b[0m | \u001b[0m 8.389   \u001b[0m | \u001b[0m 146.9   \u001b[0m | \u001b[0m 22.44   \u001b[0m | \u001b[0m 0.2676  \u001b[0m | \u001b[0m 9.746e+0\u001b[0m | \u001b[0m 17.67   \u001b[0m | \u001b[0m 7.917   \u001b[0m |\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.206297 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205112 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204929 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.403752 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205013 secs. 1 sparse feature groups\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7868  \u001b[0m | \u001b[0m 0.6958  \u001b[0m | \u001b[0m 0.3903  \u001b[0m | \u001b[0m 4.828   \u001b[0m | \u001b[0m 0.1948  \u001b[0m | \u001b[0m 8.308   \u001b[0m | \u001b[0m 149.9   \u001b[0m | \u001b[0m 32.56   \u001b[0m | \u001b[0m 0.007257\u001b[0m | \u001b[0m 3.5e+03 \u001b[0m | \u001b[0m 26.2    \u001b[0m | \u001b[0m 3.252   \u001b[0m |\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.222904 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205287 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204270 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204886 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.208749 secs. 1 sparse feature groups\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n| \u001b[95m 3       \u001b[0m | \u001b[95m 0.7939  \u001b[0m | \u001b[95m 0.5912  \u001b[0m | \u001b[95m 0.2249  \u001b[0m | \u001b[95m 7.248   \u001b[0m | \u001b[95m 0.01009 \u001b[0m | \u001b[95m 12.23   \u001b[0m | \u001b[95m 147.9   \u001b[0m | \u001b[95m 18.4    \u001b[0m | \u001b[95m 0.1525  \u001b[0m | \u001b[95m 9.751e+0\u001b[0m | \u001b[95m 20.69   \u001b[0m | \u001b[95m 1.648   \u001b[0m |\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.207048 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.316750 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204699 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.223090 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.209279 secs. 1 sparse feature groups\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7938  \u001b[0m | \u001b[0m 0.5341  \u001b[0m | \u001b[0m 0.452   \u001b[0m | \u001b[0m 0.8513  \u001b[0m | \u001b[0m 0.02654 \u001b[0m | \u001b[0m 9.733   \u001b[0m | \u001b[0m 141.6   \u001b[0m | \u001b[0m 2.663   \u001b[0m | \u001b[0m 0.101   \u001b[0m | \u001b[0m 9.755e+0\u001b[0m | \u001b[0m 14.66   \u001b[0m | \u001b[0m 8.778   \u001b[0m |\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205419 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.217633 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.206677 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.209053 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205854 secs. 1 sparse feature groups\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7922  \u001b[0m | \u001b[0m 0.5873  \u001b[0m | \u001b[0m 0.1759  \u001b[0m | \u001b[0m 7.632   \u001b[0m | \u001b[0m 0.07701 \u001b[0m | \u001b[0m 11.96   \u001b[0m | \u001b[0m 146.3   \u001b[0m | \u001b[0m 5.031   \u001b[0m | \u001b[0m 0.09931 \u001b[0m | \u001b[0m 9.77e+03\u001b[0m | \u001b[0m 24.1    \u001b[0m | \u001b[0m 6.17    \u001b[0m |\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.206876 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.210145 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205549 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204806 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.317168 secs. 1 sparse feature groups\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7891  \u001b[0m | \u001b[0m 0.8879  \u001b[0m | \u001b[0m 0.895   \u001b[0m | \u001b[0m 2.011   \u001b[0m | \u001b[0m 0.1399  \u001b[0m | \u001b[0m 11.67   \u001b[0m | \u001b[0m 162.3   \u001b[0m | \u001b[0m 42.64   \u001b[0m | \u001b[0m 0.1744  \u001b[0m | \u001b[0m 9.222e+0\u001b[0m | \u001b[0m 22.62   \u001b[0m | \u001b[0m 0.4751  \u001b[0m |\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.281355 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205392 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.206961 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.207079 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.207686 secs. 1 sparse feature groups\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7897  \u001b[0m | \u001b[0m 0.9613  \u001b[0m | \u001b[0m 0.8728  \u001b[0m | \u001b[0m 0.4488  \u001b[0m | \u001b[0m 0.1063  \u001b[0m | \u001b[0m 7.496   \u001b[0m | \u001b[0m 132.5   \u001b[0m | \u001b[0m 13.32   \u001b[0m | \u001b[0m 0.2328  \u001b[0m | \u001b[0m 9.753e+0\u001b[0m | \u001b[0m 19.63   \u001b[0m | \u001b[0m 1.023   \u001b[0m |\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.203904 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204597 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204196 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204501 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.206001 secs. 1 sparse feature groups\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7928  \u001b[0m | \u001b[0m 0.6035  \u001b[0m | \u001b[0m 0.3914  \u001b[0m | \u001b[0m 2.033   \u001b[0m | \u001b[0m 0.05995 \u001b[0m | \u001b[0m 9.031   \u001b[0m | \u001b[0m 134.5   \u001b[0m | \u001b[0m 2.543   \u001b[0m | \u001b[0m 0.05865 \u001b[0m | \u001b[0m 9.757e+0\u001b[0m | \u001b[0m 19.37   \u001b[0m | \u001b[0m 8.311   \u001b[0m |\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204469 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204869 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205699 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.206524 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.217856 secs. 1 sparse feature groups\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7938  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 6.228   \u001b[0m | \u001b[0m 0.009   \u001b[0m | \u001b[0m 13.0    \u001b[0m | \u001b[0m 153.0   \u001b[0m | \u001b[0m 6.538   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 9.752e+0\u001b[0m | \u001b[0m 18.84   \u001b[0m | \u001b[0m 2.741   \u001b[0m |\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205783 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204695 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.337720 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.226278 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.210658 secs. 1 sparse feature groups\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7893  \u001b[0m | \u001b[0m 0.7354  \u001b[0m | \u001b[0m 0.8293  \u001b[0m | \u001b[0m 6.452   \u001b[0m | \u001b[0m 0.1573  \u001b[0m | \u001b[0m 6.978   \u001b[0m | \u001b[0m 160.6   \u001b[0m | \u001b[0m 16.0    \u001b[0m | \u001b[0m 0.0671  \u001b[0m | \u001b[0m 9.763e+0\u001b[0m | \u001b[0m 15.63   \u001b[0m | \u001b[0m 3.828   \u001b[0m |\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204783 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.241329 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205408 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204618 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204377 secs. 1 sparse feature groups\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7931  \u001b[0m | \u001b[0m 0.8823  \u001b[0m | \u001b[0m 0.3935  \u001b[0m | \u001b[0m 1.269   \u001b[0m | \u001b[0m 0.04206 \u001b[0m | \u001b[0m 5.536   \u001b[0m | \u001b[0m 149.3   \u001b[0m | \u001b[0m 7.293   \u001b[0m | \u001b[0m 0.2336  \u001b[0m | \u001b[0m 9.753e+0\u001b[0m | \u001b[0m 29.19   \u001b[0m | \u001b[0m 8.106   \u001b[0m |\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.221741 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.221233 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.233949 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205544 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205392 secs. 1 sparse feature groups\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7932  \u001b[0m | \u001b[0m 0.6327  \u001b[0m | \u001b[0m 0.2698  \u001b[0m | \u001b[0m 6.026   \u001b[0m | \u001b[0m 0.04569 \u001b[0m | \u001b[0m 9.672   \u001b[0m | \u001b[0m 147.3   \u001b[0m | \u001b[0m 13.37   \u001b[0m | \u001b[0m 0.07172 \u001b[0m | \u001b[0m 9.748e+0\u001b[0m | \u001b[0m 25.03   \u001b[0m | \u001b[0m 3.331   \u001b[0m |\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72696\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 881\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204334 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72696\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 881\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.206092 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72696\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 881\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.206063 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72696\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 881\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.222050 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72696\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 881\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205332 secs. 1 sparse feature groups\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7932  \u001b[0m | \u001b[0m 0.6098  \u001b[0m | \u001b[0m 0.3262  \u001b[0m | \u001b[0m 6.206   \u001b[0m | \u001b[0m 0.01943 \u001b[0m | \u001b[0m 10.51   \u001b[0m | \u001b[0m 171.0   \u001b[0m | \u001b[0m 8.587   \u001b[0m | \u001b[0m 0.02364 \u001b[0m | \u001b[0m 9.732e+0\u001b[0m | \u001b[0m 23.02   \u001b[0m | \u001b[0m 0.6908  \u001b[0m |\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204038 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205580 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.212175 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205727 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.260484 secs. 1 sparse feature groups\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7932  \u001b[0m | \u001b[0m 0.8219  \u001b[0m | \u001b[0m 0.3587  \u001b[0m | \u001b[0m 5.015   \u001b[0m | \u001b[0m 0.05493 \u001b[0m | \u001b[0m 5.471   \u001b[0m | \u001b[0m 149.9   \u001b[0m | \u001b[0m 1.22    \u001b[0m | \u001b[0m 0.02002 \u001b[0m | \u001b[0m 9.733e+0\u001b[0m | \u001b[0m 19.61   \u001b[0m | \u001b[0m 8.408   \u001b[0m |\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72696\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 881\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204196 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72696\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 881\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205577 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72696\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 881\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.206119 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72696\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 881\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.216688 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72696\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 881\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.219678 secs. 1 sparse feature groups\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7934  \u001b[0m | \u001b[0m 0.743   \u001b[0m | \u001b[0m 0.4824  \u001b[0m | \u001b[0m 5.909   \u001b[0m | \u001b[0m 0.02585 \u001b[0m | \u001b[0m 12.66   \u001b[0m | \u001b[0m 174.6   \u001b[0m | \u001b[0m 25.22   \u001b[0m | \u001b[0m 0.1734  \u001b[0m | \u001b[0m 9.723e+0\u001b[0m | \u001b[0m 28.3    \u001b[0m | \u001b[0m 0.5582  \u001b[0m |\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72694\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 880\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204732 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72694\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 880\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.206051 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72694\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 880\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.231623 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72694\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 880\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.210843 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72694\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 880\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205220 secs. 1 sparse feature groups\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7909  \u001b[0m | \u001b[0m 0.6638  \u001b[0m | \u001b[0m 0.5686  \u001b[0m | \u001b[0m 1.889   \u001b[0m | \u001b[0m 0.09193 \u001b[0m | \u001b[0m 10.41   \u001b[0m | \u001b[0m 183.4   \u001b[0m | \u001b[0m 9.67    \u001b[0m | \u001b[0m 0.2252  \u001b[0m | \u001b[0m 9.708e+0\u001b[0m | \u001b[0m 26.59   \u001b[0m | \u001b[0m 7.036   \u001b[0m |\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.301728 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.207410 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.206879 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.207067 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.211003 secs. 1 sparse feature groups\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7935  \u001b[0m | \u001b[0m 0.5558  \u001b[0m | \u001b[0m 0.4707  \u001b[0m | \u001b[0m 7.963   \u001b[0m | \u001b[0m 0.0222  \u001b[0m | \u001b[0m 12.7    \u001b[0m | \u001b[0m 152.1   \u001b[0m | \u001b[0m 14.17   \u001b[0m | \u001b[0m 0.2293  \u001b[0m | \u001b[0m 9.717e+0\u001b[0m | \u001b[0m 17.48   \u001b[0m | \u001b[0m 2.893   \u001b[0m |\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204255 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204189 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.218622 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205251 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.221631 secs. 1 sparse feature groups\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7904  \u001b[0m | \u001b[0m 0.6309  \u001b[0m | \u001b[0m 0.451   \u001b[0m | \u001b[0m 4.392   \u001b[0m | \u001b[0m 0.1255  \u001b[0m | \u001b[0m 9.879   \u001b[0m | \u001b[0m 158.9   \u001b[0m | \u001b[0m 2.34    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 9.722e+0\u001b[0m | \u001b[0m 28.24   \u001b[0m | \u001b[0m 7.655   \u001b[0m |\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204989 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205085 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.406515 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205626 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205331 secs. 1 sparse feature groups\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7926  \u001b[0m | \u001b[0m 0.7779  \u001b[0m | \u001b[0m 0.8453  \u001b[0m | \u001b[0m 0.618   \u001b[0m | \u001b[0m 0.05177 \u001b[0m | \u001b[0m 10.1    \u001b[0m | \u001b[0m 140.6   \u001b[0m | \u001b[0m 4.267   \u001b[0m | \u001b[0m 0.2545  \u001b[0m | \u001b[0m 9.739e+0\u001b[0m | \u001b[0m 16.06   \u001b[0m | \u001b[0m 8.863   \u001b[0m |\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.325556 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204797 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205695 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.207494 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.207700 secs. 1 sparse feature groups\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7914  \u001b[0m | \u001b[0m 0.5535  \u001b[0m | \u001b[0m 0.6962  \u001b[0m | \u001b[0m 9.302   \u001b[0m | \u001b[0m 0.1063  \u001b[0m | \u001b[0m 9.937   \u001b[0m | \u001b[0m 151.7   \u001b[0m | \u001b[0m 4.27    \u001b[0m | \u001b[0m 0.2425  \u001b[0m | \u001b[0m 9.73e+03\u001b[0m | \u001b[0m 19.46   \u001b[0m | \u001b[0m 7.396   \u001b[0m |\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204067 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204714 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.204977 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.232341 secs. 1 sparse feature groups\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 72698\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 432 dense feature groups (101.35 MB) transferred to GPU in 0.205797 secs. 1 sparse feature groups\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.9589  \u001b[0m | \u001b[0m 0.521   \u001b[0m | \u001b[0m 8.192   \u001b[0m | \u001b[0m 0.08623 \u001b[0m | \u001b[0m 6.368   \u001b[0m | \u001b[0m 165.5   \u001b[0m | \u001b[0m 21.96   \u001b[0m | \u001b[0m 0.285   \u001b[0m | \u001b[0m 9.732e+0\u001b[0m | \u001b[0m 20.07   \u001b[0m | \u001b[0m 4.583   \u001b[0m |\n=============================================================================================================================================================\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 1. Building a Model with the best parameters - No handling for Imbalanced data","metadata":{}},{"cell_type":"code","source":"clf1 = lgb.LGBMClassifier(objective='binary',\n                         metric='auc',\n                         device='gpu',\n                         gpu_platform_id=0,\n                         gpu_device_id=0,\n                         max_bin=150,\n                         bagging_fraction= LightGBM_BO.max['params']['bagging_fraction'],\n                         colsample_bytree= LightGBM_BO.max['params']['colsample_bytree'],\n                         lambda_l2= LightGBM_BO.max['params']['lambda_l2'],\n                         learning_rate= LightGBM_BO.max['params']['learning_rate'],\n                         max_depth= int(round(LightGBM_BO.max['params']['max_depth'])),\n                         min_child_weight= LightGBM_BO.max['params']['min_child_weight'],\n                         min_split_gain= LightGBM_BO.max['params']['min_split_gain'],\n                         n_estimators= int(round(LightGBM_BO.max['params']['n_estimators'])),\n                         num_leaves= int(round(LightGBM_BO.max['params']['num_leaves'])),\n                         reg_alpha= LightGBM_BO.max['params']['reg_alpha'],\n                         min_child_samples = int(round(LightGBM_BO.max['params']['min_child_samples'])))\nclf1","metadata":{"execution":{"iopub.status.busy":"2022-04-22T12:48:50.376521Z","iopub.execute_input":"2022-04-22T12:48:50.377228Z","iopub.status.idle":"2022-04-22T12:48:50.390842Z","shell.execute_reply.started":"2022-04-22T12:48:50.377190Z","shell.execute_reply":"2022-04-22T12:48:50.389984Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"LGBMClassifier(bagging_fraction=0.5912384186379205,\n               colsample_bytree=0.22489950447691787, device='gpu',\n               gpu_device_id=0, gpu_platform_id=0, lambda_l2=7.2476570775749085,\n               learning_rate=0.010091730086664408, max_bin=150, max_depth=12,\n               metric='auc', min_child_samples=148,\n               min_child_weight=18.396999797852718,\n               min_split_gain=0.15249740640007858, n_estimators=9751,\n               num_leaves=21, objective='binary', reg_alpha=1.6477598520053405)"},"metadata":{}}]},{"cell_type":"code","source":"clf1.fit(train.drop(columns=['TARGET','SK_ID_CURR']),train['TARGET'], eval_metric= 'roc_auc',verbose=200)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T12:49:37.118456Z","iopub.execute_input":"2022-04-22T12:49:37.119197Z","iopub.status.idle":"2022-04-22T13:10:23.154699Z","shell.execute_reply.started":"2022-04-22T12:49:37.119156Z","shell.execute_reply":"2022-04-22T13:10:23.153948Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] bagging_fraction is set=0.5912384186379205, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5912384186379205\n[LightGBM] [Warning] lambda_l2 is set=7.2476570775749085, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.2476570775749085\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"LGBMClassifier(bagging_fraction=0.5912384186379205,\n               colsample_bytree=0.22489950447691787, device='gpu',\n               gpu_device_id=0, gpu_platform_id=0, lambda_l2=7.2476570775749085,\n               learning_rate=0.010091730086664408, max_bin=150, max_depth=12,\n               metric='auc', min_child_samples=148,\n               min_child_weight=18.396999797852718,\n               min_split_gain=0.15249740640007858, n_estimators=9751,\n               num_leaves=21, objective='binary', reg_alpha=1.6477598520053405)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Tree-based Feature Importance","metadata":{}},{"cell_type":"code","source":"lgb.plot_importance(booster=clf1,max_num_features = 30,figsize=(15,15))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T13:11:08.407438Z","iopub.execute_input":"2022-04-22T13:11:08.407706Z","iopub.status.idle":"2022-04-22T13:11:09.080162Z","shell.execute_reply.started":"2022-04-22T13:11:08.407678Z","shell.execute_reply":"2022-04-22T13:11:09.079448Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:title={'center':'Feature importance'}, xlabel='Feature importance', ylabel='Features'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1080x1080 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAABIUAAANsCAYAAADFoBhpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOzdd5hV1fn28e9NURE1iIiCaBBBxJmBUYglETLYULGEn0blFRXRqIm9k2gsiVGwRE00ISZGjQUriiWCER27IiiKYFAJk9hAQFGHPvi8f+w945nDNNoUzv25rrk4e62113r2PluQh7XWVkRgZmZmZmZmZma5pVlDB2BmZmZmZmZmZvXPSSEzMzMzMzMzsxzkpJCZmZmZmZmZWQ5yUsjMzMzMzMzMLAc5KWRmZmZmZmZmloOcFDIzMzMzMzMzy0FOCpmZmZmZrQZJv5L0t4aOw8zMbHUpIho6BjMzMzPLMZJKgK2AFRnFO0bEp2vY50kR8cyaRdf0SLoc6BoRQxo6FjMzazo8U8jMzMzMGsohEbFJxs9qJ4TWBkktGnL81dVU4zYzs4bnpJCZmZmZNRqSvifpNkmfSfpE0pWSmqd1O0h6VtJ8SfMk3SOpTVp3F7Ad8LikUkkXSiqS9HFW/yWS9k0/Xy7pIUl3S/oaGFrT+FXEermku9PPnSWFpBMkfSTpS0mnSvqBpHckLZB0c8a5QyW9LOlmSV9J+rekfTLqO0p6TNIXkj6U9LOscTPjPhX4FXBUeu1vp+1OkPSepG8k/UfSKRl9FEn6WNJ5kj5Pr/eEjPpWkq6X9N80vpcktUrr9pD0SnpNb0sqWo2v2szMGgEnhczMzMysMbkDKAO6ArsA+wMnpXUCrgY6Aj2AbYHLASLiWOB/fDf76Jo6jncY8BDQBrinlvHrYnegG3AUcCNwMbAvkAccKenHWW1nAu2Ay4AxktqmdfcBH6fXegRwlaS9q4n7NuAq4P702nulbT4HDgY2A04AbpC0a0YfWwPfA7YBTgRukbR5Wncd0Bv4IdAWuBD4VtI2wJPAlWn5+cDDkrZchXtkZmaNhJNCZmZmZtZQHk1nmyyQ9KikrYCDgLMjYmFEfA7cABwNEBEfRsS/ImJpRMwFfg/8uPru6+TViHg0Ir4lSZ5UO34d/TYilkTE08BCYHREfB4RnwAvkiSayn0O3BgRyyPifmAGMFDStsCPgIvSvqYAfwOOqyruiFhcVSAR8WREzIzE88DTQN+MJsuB36Tj/xMoBbpLagYMA86KiE8iYkVEvBIRS4EhwD8j4p/p2P8CJqX3zczMmhivPzYzMzOzhvKTzE2hJe0GtAQ+k1Re3Az4KK3fCriJJLGxaVr35RrG8FHG5+/XNH4dzcn4vLiK400yjj+Jym99+S/JzKCOwBcR8U1WXZ9q4q6SpANJZiDtSHIdGwNTM5rMj4iyjONFaXztgI1IZjFl+z7wU0mHZJS1BJ6rLR4zM2t8nBQyMzMzs8biI2Ap0C4rWVHuKiCAgoj4QtJPgJsz6rNfq7uQJBECQLo3UPYyp8xzaht/bdtGkjISQ9sBjwGfAm0lbZqRGNoO+CTj3OxrrXQsaUPgYZLZRWMjYrmkR0mW4NVmHrAE2AF4O6vuI+CuiPjZSmeZmVmT4+VjZmZmZtYoRMRnJEucrpe0maRm6ebS5UvENiVZ4vRVurfNBVldzAG6ZBy/D2wkaaCklsAlwIZrMP7a1h44U1JLST8l2SfpnxHxEfAKcLWkjST1JNnz5+4a+poDdE6XfgFsQHKtc4GydNbQ/nUJKl1K93fg9+mG180l7Zkmmu4GDpE0IC3fKN20utOqX76ZmTU0J4XMzMzMrDE5jiShMZ1kadhDQIe07gpgV+Arks2Ox2SdezVwSbpH0fkR8RXwC5L9eD4hmTn0MTWrafy17XWSTannAb8DjoiI+WndYKAzyayhR4DLMpfaVeHB9Nf5kt5MZxidCTxAch3/j2QWUl2dT7LU7A3gC2Ak0CxNWB1G8razuSQzhy7Af68wM2uSVHkZs5mZmZmZrWuShgInRcReDR2LmZnlLmf0zczMzMzMzMxykJNCZmZmZmZmZmY5yMvHzMzMzMzMzMxykGcKmZmZmZmZmZnloBYNHYCZ2brUpk2b6Nq1a0OHYVajhQsX0rp164YOw6xGfk6tKfBzak2Fn1WrT5MnT54XEVtWVeekkJmt17baaismTZrU0GGY1ai4uJiioqKGDsOsRn5OrSnwc2pNhZ9Vq0+S/ltdnZePmZmZmZmZmZnlICeFzMzMzMzMzMxykJNCZmZmZmZmZmY5yEkhMzMzMzMzM7Mc5KSQmZmZmZmZmVkOclLIzMzMzMzMzCwHOSlkZmZmZmZmZpaDnBQyMzMzMzMzM8tBTgqZmZmZmZmZmeUgJ4XMzMzMzMzMzHKQk0JmZmZmZmZmZjnISSEzMzMzMzMzsxzkpJCZmZmZmZmZWQ5yUsjMzMzMzMzMLAc5KWRmZmZmZmZmloOcFDIzMzMzMzMzy0FOCpmZmZmZmZmZ5SAnhczMzMzMzMzMcpCTQmZmZmZmZmZmOchJITMzMzMzMzOzHOSkkJmZmZmZmZlZDnJSyMzMzMzMzMyalI8++oj+/fuz8847k5eXx0033QTABRdcwE477UTPnj0ZNGgQCxYsAGDixIkUFhZSWFhIr169eOSRRyr6WrBgAUcccQQ77bQTPXr04NVXX22IS2oQioiGjsHMqiBpBTAVaAG8BxwfEYsktQA+A26LiOGS9gN+A/wwIkJSc2AScBqwP3AZ0C0iPkz7PRu4AfhBREySVAJ8A6xIh34hIs6UdAewH9AlIpZKapf2ewhwV9p2O+Cr9GdeROxbxXV0TuOfAWyQ9nFiRCxP67Ov52Lgp+npBek9APg70Bb4GTA3Y4iiiFhQ3X3crkvXaHbkTdVVmzUK5xWUcf3UFg0dhlmN/JxaU+Dn1JoKP6trpmTEQD777DM+++wzdt11V7755ht69+7No48+yscff8zee+9NixYtuOiiiwAYOXIkixYtYoMNNqBFixZ89tln9OrVi08//ZQWLVpw/PHH07dvX0466SSWLVvGokWLaNOmTcNe5FokaXJE9KmqzjOFzBqvxRFRGBH5wDLg1LR8P+B94KeSFBH/Av4LnJjWnwFMiohX0uOpwNEZ/f4UmJY1Vv90rMKIODOjfAUwLLNhREwtbws8BlyQHq+UEMowM21fAHQCjsyoy76e32X0vzgjrj+k7W/IKCusKSFkZmZmZmbrpw4dOrDrrrsCsOmmm9KjRw8++eQT9t9/f1q0SBJue+yxBx9//DEAG2+8cUX5kiVLkATAV199xQsvvMCJJyZ/ndpggw3Wq4RQbZwUMmsaXgS6pp8HAzcB/wP2TMvOAX4pKQ84Hbgo49xHgcMAJO1AOqunjuPeCJyTzuZZYxGxApgIbJNRXNX1mJmZmZmZ1UlJSQlvvfUWu+++e6Xyv//97xx44IEVx6+//jp5eXkUFBQwatQoWrRowaxZs9hyyy054YQT2GWXXTjppJNYuHBhfV9Cg/F8NbNGLk3IHAiMk7QRsC9wCtCGJKHySkR8JulG4FXgzIj4IqOLr4GPJOWTJIfuB07IGua5dLkawJ0RcUP6+X/AS8CxwONr4Vo2AnYHzso4Xul6aunmHElD0s9fRkT/KsY5GTgZoF27Lbm0oGxNQzdbp7ZqlUwjN2vM/JxaU+Dn1JoKP6trpri4uOLz4sWLOeusszjppJN48803K8rvvvtuFixYwDbbbFOp/S233MJ///tffvWrX9G6dWtmzZrF5MmTGTp0KEOHDuWPf/wjP//5zxk2rNKCifWWk0JmjVcrSVPSzy8CtwGHAs9FxGJJDwO/lnR2OgPnFmBERNxRRV/3kSwhGwDsw8pJof4RUd3soauBscCTa3AtO6TXsj3wZES8k5YfXMP1VOeGiLiupsEi4lbgVkj2FPJ6bWvsvK+ANQV+Tq0p8HNqTYWf1TVTckwRAMuXL+fggw/m1FNP5dxzz62ov+OOO5g2bRoTJkxg4403rrKPO++8k7Zt29KzZ0+uvvpqfvGLXwDQvHlzRowYQVFR0bq+jEbBT6FZ47U43VengqTBwF7p5tAAWwB7A/+KiG8lVbdz/BPAtSR7DX1dvn62LiLigzShc2RtbWswMyIK082qX5Z0aEQ8RjIzqMrrWYOxKmnVsjkzRgxcW92ZrRPFxcUV/3Nj1lj5ObWmwM+pNRV+VtdcRHDiiSfSo0ePSgmhcePGcc011/D8889XSgjNmjWLbbfdlhYtWvDf//6Xf//733Tu3Jl27dqx7bbbMmPGDLp3786ECRPYeeedG+KSGoSTQmZNhKTNgL7AthGxNC07gSSxUmMSJX1r2UUkGzqvjt+xZjOFyuOYJ2k4yf5Hxazm9ZiZmZmZWW57+eWXueuuuygoKKCwsBCAq666ijPPPJOlS5ey3377Aclm06NGjeKll15ixIgRtGzZkmbNmvGnP/2Jdu3aAfDHP/6RY445hmXLltGlSxduv/32hrqseuekkFnTMQh4tjyBkhoLXCNpw6zylUTEfTVUZ+4p9E5EHJd17jRJbwK7rk7gWR4FLifZHHt1ridzTyGAn0REyVqIy8zMzMzMmoi99tqLiJUXShx00EFVtj/22GM59thjq6wrLCxk0qRJazW+psJJIbNGKiI2yTq+E7gzq+wLYMsazrm8mr6LMj53rqbN0Kzj/6utTTX9lAD5GccB9KqmbV2u5/LaxjQzMzMzM7Pa+ZX0ZmZmZmZmZmY5yDOFzGytkFQA3JVVvDQidm+IeMzMzMzMzKxmTgqZ2VoREVOBwoaOw8zMzMzMzOrGy8fMzMzMzMzMzHKQk0JmZmZmZmZmZjnISSEzMzMzMzMzsxzkpJCZmZmZmZmZWQ5yUsjMzMzMzMzMLAc5KWRmZmZmZmZmloOcFDIzMzMzMzMzy0FOCpmZmZmZmZmZ5SAnhczMzMzMzMzMcpCTQmZmZmZmZmZmOchJITMzMzMzMzOzHOSkkJmZmZmZmZlZDnJSyMzMzMzMzMwsBzkpZGZmZmbWwIYNG0b79u3Jz8+vKLvgggvYaaed6NmzJ4MGDWLBggUAlJSU0KpVKwoLCyksLOTUU0+tOKeoqIju3btX1H3++ef1fSlmZtaEtGjoAMzM1qXFy1fQefiTDR2GWY3OKyhjqJ9Ta+T8nK47JSMGMnToUE4//XSOO+64ivL99tuPq6++mhYtWnDRRRdx9dVXM3LkSAB22GEHpkyZUmV/99xzD3369KmP0M3MrInzTKFGTNJPJIWkndLjzpIWS5oiabqkUZKaVVdeTZ/NJP1B0ruSpkp6Q9L2ad0mkv4iaaakyZKKJe2e1nWSNFbSB2n9TZI2SOuKJH2Vjv9vSddljDdU0ty0rvxnZ0mFkl6VNE3SO5KOquE+PJKe92HGOFMk/VDSBpJuTOs+SGPsVMt9XZGe/66kByVtnJaXZrUbKunmjOOT0+v7t6SJkvbKqCuWNCnjuI+k4iruT/nPvjXEt7Wk+zK+h39K2jH9nt/Nanu5pPMzjluk93tEVrtq40uPd0vbfCDpTUlPSirIGOOTrPjbVBN7tc9CWt9O0nJJp6bHt2Q8t4sz+j9C0h2SjkjbrfL3bGZm1pT069ePtm3bVirbf//9adEi+TfcPfbYg48//rghQjMzs/WYk0KN22DgpfTXcjMjohDoCewM/KSW8mxHAR2BnhFRAAwCFqR1fwO+ALpFRG/gBKCdJAFjgEcjohuwI7AJ8LuMfl9Mx98FOFjSjzLq7o+Iwoyf6cAi4LiIyAMOAG6sLtEQEYPSvk8qHyf9eQW4CtgU6J7G9igwJo25OovT8/OBZcCpNbQFQNLBwCnAXhGxU3rOvZK2zmjWXtKB1XTxYtY9eKaacQQ8AhRHxA7p9/BLYKvaYkztB7wP/LSKe1BlfJK2Ah4AfhUR3SJiV+BqYIeMZjdkxb+ghhhqehZ+CrxG+kxHxGlp24NIn+H056GsPlfnezYzM1tv/P3vf+fAA7/7Y3zWrFnssssu/PjHP+bFF1+s1PaEE06gsLCQ3/72t0REfYdqZmZNiJePNVKSNgH2AvoDjwOXZdZHRJmkV4CuwJvVlFelA/BZRHybtv84HW8HYHfgmIy6WcAsSfsASyLi9rR8haRz0rrsuBZLmgJsU9P1RcT7GZ8/lfQ5sCXfJahqlc7wOQHYPiJWpH3dLmkYsDcwoQ7dvEiSSKvNRcAFETEvHedNSXcCpwG/TttcC1wMPFXXa6hCf2B5RIwqL4iItyGZKVaH8wcDNwE/B/YEXsmoqy6+04E70yRb+ZgvrU7wmap5FgYD55Ek1DqVP381WZ3vWdLJwMkA7dptyaUFZWt6OWbr1FatkqU5Zo2Zn9N1p7i4GIDZs2ezcOHCiuNyd999NwsWLGCbbbahuLiYZcuWce+99/K9732PGTNmcPjhh3P77bfTunVrTjvtNLbccksWLVrEZZddxqJFixgwYED9X1QDKS0tXen+mTVGflatsXBSqPE6DBgXEe9Lmi+pNzC/vDL9i/I+wKWZJ1VXnuEB4CVJfUn+Mn13RLwF5AFTyv/SnSUPmJxZEBFfS/ofWcknSZsD3YAXMoqPylxqBewZEYszztkN2ACYWU3M1ekK/C8ivs4qn5TGXGNSSFIL4EBgXFrUKk1ilGsLPJZ+XukepOMcn3H8KjBIUn/gm6y2fbP6Pjwiqrre/CrGybRDVj9bA9el17MRsC/JjKY2JAmYzKRQdfHlAXfWMCbAOZKGpJ+/jIj+tbRf6VmQtC3QISImSnqAZNba9bX1w2p8zxFxK3ArwHZdusb1U/1bnTVu5xWU4efUGjs/p+tOyTFFya8lJbRu3ZqioqKKujvuuINp06YxYcIENt5445XOLSoqYvTo0Wy11VYr7SP0+eefM2nSpEr9re+Ki4tz6nqt6fKzao2Fl481XoOB+9LP9/HdErLypMDLwJMR8VQt5ZWkMzO6kyxJ+haYkM4EWlN9Jb0NfAKMj4jZGXXZy8cyE0IdgLuAE8pnKNWD8uTPJOB/wG1p+eLMOKk+sVaTK4FLqijPXj62qgmwcjOzYhyVUXcw8Fx6fx8GfiKpeR3jqyDpdUnvSbopozhz+VhtCaHqnoWjSJKSUPmZNjMzsyqMGzeOa665hscee6xSQmju3LmsWJH8O95//vMfPvjgA7p06UJZWRnz5s0DYPny5TzxxBOV3mZmZmaWzf/c0whJakuyLKZAUgDNgQBu4bu9g7JVV76SiFhKsoToKUlzSPYfuhHoJal5FbOFpgNHZMW4GbAd8CGwG0nS42Alm1a/JumBiJhSy3VuBjwJXBwRr9Ul9iwzge0kbRoRmTNfegNP1HDe4rreqwzT036fzRpnWmajiHhW0pXAHqvYf7lpZN3rVTAY2EtSSXq8Bclz9K9a4psG7AqMTdvsnm7wfPBqxlHdszAY2FrSMWm7jpK6RcQHtfS3ut8zAK1aNmfGiIGrcRlm9ae4uLhipoBZY+XndN0aPHgwxcXFzJs3j06dOnHFFVdw9dVXs3TpUvbbbz8g2Wx61KhRvPDCC1x66aW0bNmSZs2aMWrUKNq2bcvChQsZMGAAy5cvZ8WKFey777787Gc/a+ArMzOzxsxJocbpCOCuiDilvEDS88C2a9qxpF2B2ek+Ps1I9tN5JyJmKnk71RWSfh0Rke5hkwf8Exgh6biI+Ec6++R64I6IWJS5129EzFLy5quLqGEmiJI3lz0C/KOKTYXrJCIWpvv6/F7SqeleR8cBG1M5ebM2XAOMlHRARMyXVAgMJdmHKduVJDN4/rMa4zwLXCXp5HQJFJJ6At8DPqrupDTB1hfYNk36IekEku/gX1nNs+O7BXhd0viMfYVWnp++ijKfhXTvqU0iomJ/IUlXpPH9ppZ+6vN7NjMzaxCjR49eqezEE0+ssu3hhx/O4YcfvlJ569atmTy5plXoZmZmlXn5WOM0mCRhkulhkiVfa6o98LiSV5u/A5QB5a9dP4nkLVcfpvV3AJ9H8tqKQSRvtPqA5O1WS4BfVTPGKKBfxsbIR6ny68x/CBwJ9AOGZpQXrsb1/DKN5f00tp8Cg2Itv2ojIh4D/g68IunfwF+BIRHxWRVt/wnMzSrum3UPqpwNlHGv91XySvppJG8Cm11V+wyDgGfLE0KpscAhkjasKb50eddRwNVKXvn+Ckli8uaM087Jir9zLfGUG0XyPVf3TNd1CVm9fM9mZmZmZma5RP47lZmtz7p37x4zZsxo6DDMauTNJq0p8HNqTYGfU2sq/KxafZI0OSL6VFXnmUJmZmZmZmZmZjnIewqtpyQVkLzVK9PSiKhqD5xGQ9IjwPZZxRdFxPhV7GcLqn4l/T4RMX9141tbGnt8tZE0ABiZVTwrIgY1RDxmZmZmZma26pwUWk9FxFSgsKHjWFVrK6mQJlYK10Zf60Jjj682aZJulRJ1ZmZmZmZm1rh4+ZiZmZmZmZmZWQ5yUsjMzMzMzMzMLAc5KWRmZmZmZmZmloOcFDIzMzMzMzMzy0FOCpmZmZmZmZmZ5SAnhczMzMzMzMzMcpCTQmZmZmZmZmZmOchJITMzMzMzMzOzHOSkkJmZmZmZmZlZDnJSyMzMzMzMzMwsBzkpZGZmZmZmZmaWg5wUMjMzMzMzMzPLQU4KmZmZmZllGTZsGO3btyc/P7+i7MEHHyQvL49mzZoxadKkivJ77rmHwsLCip9mzZoxZcoUAC6++GK23XZbNtlkk/q+BDMzs1o5KWRmZmZmlmXo0KGMGzeuUll+fj5jxoyhX79+lcqPOeYYpkyZwpQpU7jrrrvYfvvtKSwsBOCQQw5h4sSJ9RW2mZnZKmnR0AGY5QpJpRFR7T8TSmoD/L+I+NNq9n82cGtELFq9CFdprCLg/Ig4WNKhwM4RMWI1+vlVRFyVcfxKRPxw7UUKi5evoPPwJ9dml2Zr3XkFZQz1c2qNXK48pyUjBgLQr18/SkpKKtX16NGj1vNHjx7N0UcfXXG8xx57rNX4zMzM1ibPFDJrPNoAv1iD888GNl4rkayCiHhsdRJCqV9l9bVWE0JmZmb17f7772fw4MENHYaZmVmdeKaQWT2TtAkwFtgcaAlcEhFjgRHADpKmAP+KiAskXQAcCWwIPBIRl0lqDTwAdAKaA78FtgI6As9JmhcR/asZ+8/AD4BWwEMRcVlaXpL2eSCwmGTG0oeS7gCWAH2AzYBzI+KJrD6HAn0i4nRJWwGjgC5p9c8j4hVJjwLbAhsBN0XErZJGAK3S650WEceUz6aSJOCaNJ4AroyI+9MZSpcD84B8YDIwJCIiK6aTgZMB2rXbkksLymr6Sswa3FatklkYZo1ZrjynxcXFFZ9nz57NwoULK5UBLFiwgMmTJ1NaWlqpfPr06UQE8+bNW+mcFStWrFRma19paanvszUJflatsXBSyKz+LQEGRcTXktoBr0l6DBgO5EdEIYCk/YFuwG6AgMck9QO2BD6NiIFpu+9FxFeSzgX6R8S8Gsa+OCK+kNQcmCCpZ0S8k9Z9FREFko4DbgQOTss7pzHsQJJ06lpD/38Ano+IQekY5cvlhqXjtgLekPRwRAyXdHr59Wb5P6AQ6AW0S895Ia3bBcgDPgVeBn4EvJR5ckTcCtwKsF2XrnH9VP9WZ43beQVl+Dm1xi5XntOSY4q++1xSQuvWrSkqKqrUpk2bNvTu3Zs+ffpUKh87diwnnXTSSu0BmjdvXmW5rV3FxcW+z9Yk+Fm1xsLLx8zqn4CrJL0DPANsQzLTJ9v+6c9bwJvATiRJoqnAfpJGSuobEV+twthHSnoz7TMP2DmjbnTGr3tmlD8QEd9GxAfAf9I4qrM38GeAiFiREduZkt4GXiOZMdStljj3AkanfcwBnieZ4QQwMSI+johvgSkkSSszM7MG9e233/LAAw9U2k/IzMyssVv//7nHrPE5hmS2T++IWJ4u3dqoinYCro6Iv6xUIe0KHARcKWlCRPymtkElbQ+cD/wgIr5Ml4Zljht1+FzVcW3jFgH7AntGxCJJxVR9vXW1NOPzCmr5faxVy+bMSDcNNWusiouLK81OMGuMcu05HTx4MMXFxcybN49OnTpxxRVX0LZtW8444wzmzp3LwIEDKSwsZPz48QC88MILbLvttnTp0qVSPxdeeCH33nsvixYtolOnTpx00klcfvnlDXBFZmZmK3NSyKz+fQ/4PE0I9Qe+n5Z/A2ya0W488FtJ90REqaRtgOUk/91+ERF3S1oAnJR1fnXLxzYDFgJfpXv/HAgUZ9QfRbKv0VHAqxnlP5V0J7A9yV5BM4DqXqUyAfg5cGPG8rHvAV+mCaGdss5dLqllRCzP6udF4JR03LZAP+ACap6lZGZmttaMHj26yvJBgwZVWV5UVMRrr722Uvk111zDNddcs1ZjMzMzW1ucFDKrf/cAj0uaCkwC/g0QEfMlvSzpXeCpdKPpHsCryb7LlAJDgK7AtZK+JUkS/Tzt91ZgnKRPq9poOiLelvRWOt5HJPvxZNo8XdK2FMh8bcr/gIkkSaVTI2JJGk9VzgJulXQiySyenwPjgFMlvUeSUMr8P+ZbgXckvRkRx2SUP0KyhO1tkplJF0bE7DSpZGZmZmZmZmuBsl7aY2Y5KF3C1id7k+p0idkTEfFQQ8S1NnTv3j1mzJjR0GGY1cibTVpT4OfUmgI/p9ZU+Fm1+iRpckT0qarOG02bmZmZmZmZmeUgLx8zWw9Jeh3YMKv42IiYWlX7iOhcTfnQtRuZmZmZmZmZNRZOCpmthyJi94aOwczMzMzMzBo3Lx8zMzMzMzMzM8tBTgqZmZmZmZmZmeUgJ4XMzMzMzMzMzHKQk0JmZmZmZmZmZjnISSEzMzMzMzMzsxzkpJCZmZmZmZmZWQ5yUsjMzMzMzMzMLAc5KWRmZmZmZmZmloOcFDIzMzMzMzMzy0FOCpmZmZmZmZmZ5SAnhczMzMzMzMzMcpCTQmZmZmZmZmZmOchJITMzMzOzDMOGDaN9+/bk5+dXlD344IPk5eXRrFkzJk2aVKn9O++8w5577kleXh4FBQUsWbIEgPvvv5+ePXuSl5fHRRddVK/XYGZmVhdOCpmZmZmZZRg6dCjjxo2rVJafn8+YMWPo169fpfKysjKGDBnCqFGjmDZtGsXFxbRs2ZL58+dzwQUXMGHCBKZNm8bs2bOZMGFCfV6GmZlZrVo0dABmtm5IWgFMBVoCZcA/gBsi4tuMNo8CW0fEHpLaAxOBPSJidlp/C/AxcBPwV6AnIGABcEBElNYytoAVwOkR8YqkzsATEZEvqQgYC8wCNgKeAO4E7kq72Q74Kv2ZB5xUfm7GOJcDpRFxXXX3YfHyFXQe/mSt98usIZ1XUMZQP6fWyOXKc1oyYiD9+vWjpKSkUnmPHj2qbP/000/Ts2dPevXqBcAWW2wBwH/+8x+6devGlltuCcC+++7Lww8/zD777LPugjczM1tFTgqZrb8WR0QhQJrwuRfYDLgsLWsD9AZKJXWJiP9IGgFcBwyRtCvQN21zPjAnIgrSc7sDy+s49gDgauDHVbR7MSIOltQKeAt4JOO8O0iSQA+lx51X6y6YmZmtQ++//z6SGDBgAHPnzuXoo4/mwgsvpGvXrsyYMYOSkhI6derEo48+yrJlyxo6XDMzs0q8fMwsB0TE58DJwOmSlBb/H/A4cB9wdFp2K7CDpP7ALSQzfJYDHYBPMvqbERFL6zj8ZsCXtcS3GJgCbFPHPs3MzBqFsrIyXnrpJe655x5eeuklHnnkESZMmMDmm2/On//8Z4466ij69u1L586dad68eUOHa2ZmVolnCpnliHQmUHOgPTAHGAz8Jv38MHBVRHwr6efAs8BjEfFCevrfgaclHQFMAO6MiA9qGK6VpCkky8I6AHvXFJukzYFuwAs1tSNJWE3JON6aZGZTdn8nkyTBaNduSy4tKKulW7OGtVWrZGmOWWOWK89pcXExALNnz2bhwoUVx+UWLFjA5MmTKS1NVlB//fXX7Ljjjrz77rtAsszswQcfpHnz5my66aaMHDkSgMcff5yNNtpopf5s7SotLfU9tibBz6o1Fk4KmeUgSVuRJGFeioiQtFxSfkS8GxFTJL0L/Km8fVrWBdgf2Bd4Q9KeEfFeNUNkLh/bE/iHpPwq2vWV9HYay43lexnVYGZ5v2nfl1fVKCJuJZn1xHZdusb1U/1bnTVu5xWU4efUGrtceU5LjilKfi0poXXr1hQVFVWqb9OmDb1796ZPnz4A9OrVi3322YfddtuNDTbYgCuvvJJzzjmHoqIiPv/8c9q3b8+XX37J2WefzQMPPMCOO+5Yz1eUW4qLi1f6zswaIz+r1lis/3+ymxkAaVJnBfA5cDqwOTArXU22GcnMoYvT5t+mPxXSTaXHAGMkfQscBFSXFMo871VJ7YAtq6gu31Noe+A1SQ9ExJTVuLxqtWrZnBkjBq7NLs3WuuLi4oq/iJo1Vrn0nA4ePJji4mLmzZtHp06duOKKK2jbti1nnHEGc+fOZeDAgRQWFjJ+/Hg233xzzj33XH7wgx8giYMOOoiBA5M/d8466yzefvttAC699FInhMzMrNFxUsgsB0jaEhgF3JzODBpM8vawV9P67YFn+C4plH3+j4DpEfGlpA2AnYHiOo69E9AcmA9sXFWbiJiVbnJ9EUlyyszMrMGMHj26yvJBgwZVWT5kyBCGDBlS537MzMwaCyeFzNZf5fv6lL+S/i7g9+lbvL4PvFbeME3KfCVp94h4vYq+dgD+nG5S3Qx4kmQfotrGhuS19MdHxIrv9riu0ijgfEmdI6KkDtdnZmZmZmZma8BJIbP1VERU94qTEqp4y1dE7JrxuSir7h/AP9Z07DTZk59+LiZjtlH6BrJtMo6HVnduRtnldY3JzMzMzMzMKvMr6c3MzMzMzMzMcpBnCpnZapG0Bcnr6bPtExHz6zseMzMzMzMzWzVOCpnZakkTP4UNHYeZmZmZmZmtHi8fMzMzMzMzMzPLQU4KmZmZmZmZmZnlICeFzMzMzMzMzMxykJNCZmZmZmZmZmY5yEkhMzMzMzMzM7Mc5KSQmZmZmZmZmVkOclLIzMzMzMzMzCwHOSlkZmZmZmZmZpaDnBQyMzMzMzMzM8tBTgqZmZmZmZmZmeUgJ4XMzMzMzMzMzHKQk0JmZmZmZmZmZjnISSEzMzMzMzMzsxzkpJCZmZmZWWrYsGG0b9+e/Pz8irIHH3yQvLw8mjVrxqRJkyq1f+edd9hzzz3Jy8ujoKCAJUuWVKo/9NBDK/VlZmbWmLRo6ADMzNalxctX0Hn4kw0dhlmNzisoY6ifU2vk1vfntGTEQACGDh3K6aefznHHHVdRl5+fz5gxYzjllFMqnVNWVsaQIUO466676NWrF/Pnz6dly5YV9WPGjGGTTTapnwswMzNbDZ4ptB6Q9BNJIWmn9LizpMWSpkiaLmmUpGbVlVfTZ3nbtyS9J2mipKFVtJsi6b70c56k9yW1yqh/UtJgSVtJekLS2+nY/6zhejLjLP85Lq0rkfRiFTG8m34ukvRVWvaepMsyyp+oYqw8Sc9KmiHpA0m/VuIeST/PaLe7pHcktUxjmJoR2x/SNndImpVe4/uS/iGpUw1fHRl9TU3vy5WSNspqc6OkT9LvcCNJ/5ZUkFF/gaS/pPV/kPRu2t8bkravw9hT0l8Py6grreK7mJ5e01YZ1z47ja38eIPyczP6Girp5pruQ1b78rE7Snooo3x0+h2cI2mndLy3JO1Q177NzMxq069fP9q2bVuprEePHnTv3n2ltk8//TQ9e/akV69eAGyxxRY0b94cgNLSUn7/+99zySWXrPugzczMVpNnCq0fBgMvpb9elpbNjIhCSS2AZ4GfAG9WUz6mmn5nRsQuAJK6AGMkKSJuT8t6AM2BvpJaR8Q0SWOAi4FLJP0EaBkRoyX9BfhXRNyUntuzlmuaGRGF1dRtKmnbiPgojSHbixFxsKTWwBRJj1fVSZq8egz4eUQ8LWlj4GHgF8C5wKtpUmI+cDPwi4hYLgmgf0TMq6LbCyLiISWNzgaelZQfEctquNb+ETFP0ibArcBfgOPTGJsBg4CPgB9HxHOSzgb+JKkf0BE4FegDHJUe94yIb9OE1MIaxs0cuzvwNDC2ijblz0xz4F/AvuXfjaTLgdKIuK68cXp/1lhEfAockfa5NfCDiOiaHg8HHoqIK9fKYGZmZqvh/fffRxIDBgxg7ty5HH300Vx44YUA/PrXv+a8885j4403buAozczMquekUBOXJhL2AvoDj/NdUgiAiCiT9ArQlSQpVFV5rSLiP5LOBa4Hbk+LBwN3AT2Aw4B7gd8Ab6XJlBHAIWnbDiRJh/L+3lm1K63kAZIEyHVpDKOBY6uIeaGkySTX+HkV/fw/4OWIeDptv0jS6UBxRNwi6TrgGuAN4J2IeKmuAUZEADdIGgQcSNXJluxzSiWdCnwkqW1EfAEUAdOA+9NrfS4ixkkaBhwHDAQuj4gvJXUAPouIb9P+Pq5rvMBmwJe1xLdC0kRgm1Xot1bpbKZ7gU3IuE+SOgNPREQ+ybOzjaQpwCPAz4EVkvaJiP5V9HkycDJAu3ZbcmlB2doM2Wyt26pVsjTHrDFb35/T4uLiis+zZ89m4cKFlcoAFixYwOTJkyktTSbFzpgxg2eeeYZRo0ax4YYbct5559G8eXO+973vMXHiRA477DBee+21KvuydaO0tNT32poEP6vWWDgp1PQdBoyLiPclzZfUm2RmCwDp7Jd9gEszT6quvBZvAjtlHB8F7JeWnQHcmyZWzgdeAH4fER+kbW8B7k+TLs8At6czQaqzQ5oAKHdGRJQvG3uYJDF1HUnS6RiqSApJ2gLYA/gtsGUVY+QBkzMLImKmpE0kbQaMIpmxU0QyEyfTc5JWpJ/vjIgbqrmO8ntWa1IoHf9rSbOAbsDrfJf0GgtcJallRCwnmYU0EfggIu5KT38AeElSX2ACcHdEvFXLkM+ls5q6AEfW1DBd1rY7cFYtfbbK+u7akszIqs5NwJ8j4h+STqumzaEkCaLCNBaRNUMpU0TcSjLriu26dI3rp/q3Omvczisow8+pNXbr+3NackzRd59LSmjdujVFRUWV2rRp04bevXvTp0/yvwWzZ89m0aJFHHZYsgL7jTfe4Ntvv2X58uXMmjWLoUOHUlZWxueff87ll1/uvwDWg+Li4pW+N7PGyM+qNRbeU6jpGwzcl36+Lz2G75IqLwNPRsRTtZTXRcW6IEl9gHkR8T+SBMQuktoCRMTjwALgT+XtI2I8SeLhryRJkrckVZWoKTczIgozfjL3EZoPfCnpaOA9YFHWuX0lvUUyu2RERExbhWuskM64+QvwVETMz6runxFbdQkhyLhnq0AAkjYADgIejYivSZJEA9LYPiVZ/vfnjHg/BroDvwS+BSZI2qeWsfqnM3EKgJvTmWfZyp+ZOSQzkWqb5bU487uj9sTjj0gSX5DMPDMzM2sSBgwYwNSpU1m0aBFlZWU8//zz7Lzzzvz85z/n008/paSkhJdeeokdd9zRCSEzM2uU1t9/7skBaRJmb6BAUpDs7xMks3Kq25Onpr16arMLSRIGkuTTTpJK0uPNgMNJkj6QJCW+zTw5XQ51L3Cvkk2f+5HM+lkd95Nc59Aq6l6MiIPr0Mf0NIYK6d5JpWkSBqq4jlW0C0nSrE4kbQp0Bt4nSQC1Aaam+/RsDCwGyjfMruoeLwWeAp6SNIdkz6hax09nSM0BdiaZgZSpfE+hdsDLkg6NiJpm/qyOWMv9VWjVsjkz0jfKmDVWxcXFlWYpmDVGufKcDh48mOLiYubNm0enTp244ooraNu2LWeccQZz585l4MCBFBYWMn78eDbffHPOPfdcfvCDHyCJgw46iIED/WeOmZk1HU4KNW1HAHdFRMX7USU9D2y7tgdK93e5DvhjuvnxkUBB+RIwSf2BX/NdUij7/L2B19LlZZsCOwD/W4OQHiHZp2g8yebKq+Me4FeS9o2IZ9KNp/9Aso/QGkmXN52RxjiujudsQjK76tF0j6DBwEkRMTqtbw3MkrRxRGTPjkLSrsDsiPg0/Y56AnXau0lSe2B74L/VtUk3pB5OMhNpbSaFXgaOBu4mWQpoZmbWYEaPHl1l+aBBg6osHzJkCEOGDKm2v86dO/Puu++uldjMzMzWNi8fa9oGkyRHMj1M8pf2tWGH9JXf75HsV/OH9M1jfYFPsvYEegHYOd3suCq9gUmS3gFeBf4WEW/UMnbmK+nPzKyMiG8iYmQtb/XKto+kj8t/gEKSPZkukTQDmEqyqXRdXp/+XEZs/8gov1bS2yQzfX5Asjyrthifk/QuyQyd/wGnpHs+HQA8Wd4oIhaSvGXukCp7gfbA42lf7wBldbiW59KlYc8BwyNiTi3tHwU2TvctWlvOAk6TNJW1vIm1mZmZmZmZVU/JS5LMzNZP3bt3jxkzZjR0GGY18maT1hT4ObWmwM+pNRV+Vq0+SZocEdkvTwI8U8jMzMzMzMzMLCd5T6EcJ6mAld/4tDQidl+fx65vkl4HNswqPjYipq7PY2fFcTHw06ziByPid/UZh5mZmZmZmSWcFMpxaWKgMNfGrm8NmehqLEm2NPnjBJCZmZmZmVkj4eVjZmZmZmZmZmY5yEkhMzMzMzMzM7Mc5KSQmZmZmZmZmVkOclLIzMzMzMzMzCwHOSlkZmZmZmZmZpaDnBQyMzMzMzMzM8tBTgqZmZmZmZmZmeUgJ4XMzMzMzMzMzHKQk0JmZmZmZmZmZjnISSEzMzMzMzMzsxzkpJCZmZmZmZmZWQ5yUsjMzMzMzMzMLAc5KWRmZmZmBgwbNoz27duTn59fUfbggw+Sl5dHs2bNmDRpUqX277zzDnvuuSd5eXkUFBSwZMkSAA444AB69epFXl4ep556KitWrKjX6zAzM6srJ4XMzMzMzIChQ4cybty4SmX5+fmMGTOGfv36VSovKytjyJAhjBo1imnTplFcXEzLli0BeOCBB3j77bd59913mTt3Lg8++GC9XYOZmdmqaNHQAVjjIuknwCNAj4j4t6TOwHvADGAD4AXgF8B2VZVHxLdV9JnZR7nfp+NMAQ6IiA8ktQTeBE4HbkrbbQd8lf7Mi4h9q+i/GXAjsDcQwBLgyIiYJel7wB+BHwICXgbOiIivJBUB50fEwRl93QE8EREPSSoGOqT9LQN+FhFT0nYHAr8FNgaWAs9GxHmSLgd+BszNCLEoIhZUEfd+wIj0/i0DLoiIZ9O6EuAboPyfFl+IiDMlPQY8FBH/SNv9FXgfOALYEGgLtAI+Sc/7SUSUVDH2MOCc9H41Ay6OiLGSBFwMHJ/WfQKcHhHT0vNKI2KTjH6GAn0i4vSsa98A+G1EjE7b7UjyHXVLr+tD4AygBzAWmJUR3vkR8UwVMW9E8pxtSPJ710MRcVl2u2yLl6+g8/Ana2tm1qDOKyhjqJ9Ta+TW9+e0ZMRA+vXrR0lJSaXyHj16VNn+6aefpmfPnvTq1QuALbbYoqJus802A5LE0bJly0j+eDUzM2t8nBSybIOBl9Jfy//CPTMiCiW1AJ4FfkKSvKmqfEw1/c6MiMLsQkm/BG4GBgDnA69ExPNAYVp/B2mSpoaYjwI6Aj0j4ltJnYCFad1twLsRcVza3xXA34Cf1ngXvnNMREySdAJwLbCfpPw05oFp4qw5cHLGOTdExHV16HsecEhEfJr2OR7YJqO+f0TMyzrnTOC5NDm0M7A78POIuDa9vqGkSZrqBk3vz8XArmlybBNgy7T6NJIEWq+IWCRpf+AxSXkRsaQO13RDRFwnqRswWdJDQHPgSeDciHg8jaEoY8wXMxNzNVgK7B0RpWkC8SVJT0XEa3U418zMbK16//33kcSAAQOYO3cuRx99NBdeeGFF/YABA5g4cSIHHnggRxxxRANGamZmVj0nhaxCmhzYC+gPPM53SSEAIqJM0itAV5KkUFXlqyQiHpB0oqQLgVOBXVYj9A7AZ+WzlCLi4/R6ugK9SZJG5X4DfChph1Uc41XggvTzhcDvIuLf6XgrgD+vatAR8VbG4TSglaQNI2JpDeeUSLoVuIYkIXR6RJSt4tDtSWbrlKZ9lpZ/Bi4CfhwRi9K6p9Pv9hiSBFudpDO/FgGbAwcDr5YnhNL6YqhIDtW1z8iIs2X6E1W1lXQyaaKuXbstubRgVW+RWf3aqlUyC8OsMVvfn9Pi4mIAZs+ezcKFCyuOyy1YsIDJkydTWpr8UTRjxgyeeeYZRo0axYYbbsh5551H8+bN6d27NwC//OUvWbZsGVdeeSU33HADffr0qc/LyVmlpaUrfXdmjZGfVWssnBSyTIcB4yLifUnzJfUG5pdXStoY2Ae4NPOk6sqz7CBpSsbxGRHxYvr5LJLlZSdHxBerEfcDJLNG+gITgLvThMvOwJQ0aQMkCZw0jjzg61UY4wDg0fRzPnB9DW3PkTQk/fxlRPSvQ/+HA29mJYSek1Qe+50RcUP6+TpgJskMmxfqFH1lbwNzgFmSJgBjIuJxSZsBrSPiP1ntJ5HcrzqTtCvwQUR8ns6CmlxD875Zz8bhETGzmn6bp311BW6JiNerahcRtwK3AmzXpWtcP9W/1Vnjdl5BGX5OrbFb35/TkmOKkl9LSmjdujVFRUWV6tu0aUPv3r0rkjuzZ89m0aJFHHbYYQC88cYbfPvttyudN3v2bCZOnMj555+/ri/BSJJ72d+BWWPkZ9Uai/X3T3ZbHYP5bi+f+9Ljm/kuoRPA2Ih4Kt0naKXyGvqucvlY6gDgM5JkyyqLiI8ldSfZU2hvYIKkuiwPq3KWSVb5PZI2ADYhXdJWB3VdPgaApDxgJLB/VlVVy8cAepLsA7STpGZV7eNUkzQxdgDwA5Jk3g1pAvD3q9JPZpcZn89Jl9rtCBxSx/PrunysfFZWoaQ2wCOS8iPi3VWK1szMbC0YMGAA11xzDYsWLWKDDTbg+eef55xzzqG0tJRvvvmGDh06UFZWxpNPPknfvn0bOlwzM7MqOSlkAEhqS5JQKZAUJPvABHAL1Sd0akr01HXcjiT75OxGMjPmtoh4Z1X7SWfYPAU8JWkOyf5GN5EkECoSJ+mm1IXAdGAjkuVNmdqS7PVT7hiSmSnXkmxY/X8kS716k8y4WSPp/j6PAMdVNzsmq30z4E/AEJLldj8n+Y5WSboUayIwUdK/gNsj4nJJCyV1yZot1Bt4Pv28WNIGEbEsPc6+X+V7Ch0K3JYu05sG/HhVY6wl/gWSniNJKNaYFGrVsjkzRgxcm8ObrXXFxcUVsxTMGqtceE4HDx5McXEx8+bNo1OnTlxxxRW0bduWM844g7lz5zJw4EAKCwsZP348m2++Oeeeey4/+MEPkMRBBx3EwIEDmTNnDoceeihLly7l22+/pX///px66qkNfWlmZmZVclLIyh0B3BURp5QXSHoe2HYdj3sDcFU62+dc4BZJ/dKkRZ2kS5Vmpxs2NyOZSfNORHwo6S3gEpK9hEg/v5nWbQh0lNQjIt6T9H2gF8kb0SpEREj6NTBT0k4kCaIxkl5Kl9o1I1n6NmpVLjyd7fIkMDwiXq7jaaeQLMsqlvQ+8JqkByJibm0nZozbEdg6Isr3hSoE/pt+vhb4g6SfRsRiSfuS7DNV/lw8T5KQ+rukVsCRJHssVRIRj0k6keQtZv8AfilpYEQ8mcbQD1ilpYKStgSWpwmhVsB+JDOszMzM1orRo0dXWT5o0KAqy4cMGcKQIUMqlW211Va88cYbaz02MzOzdcFJISs3mJX/gv0w8Mu11H/2nkJ/J9lHaDvSDYzTfW1+BhwH3LkKfbcH/pomeSCZAXNz+vlE4I+SymfhvJqWERFL071/bk9fd74cOCkivsoeIE2QXE/y2vgTJZ0NjE73UwrgiYzmmXsKQTWvhQdOJ9kb51JJ5fsx7R8Rn6efM/cUeofk7WwXAXukMX0q6UaSTadPqP72rKQlcF2aHFpC8gr58n/C/CPJ7Kmp6dizgcMiYnFafxbwF0lnAgL+UcO+Rr8B7gX+SrLZ9I1pvMvT6zkLaMfKewpdWc3b5joAd6b7CjUDHoiIJ6poZ2ZmZmZmZnWgVZiQYWbW5HTv3j1mzJjR0GGY1cibTVpT4OfUmgI/p9ZU+Fm1+iRpckRU+RrMZvUdjJmZmZmZmZmZNTwvH7O1RlIBcFdW8dKI2L0p9L+uSBrAykvzZkVE1RsUrN2xXwc2zCo+NiKmruuxV5ekLYAJVVTtExHz6zseMzMzMzOz9ZWTQrbWpImGwqba/7oSEeOB8Q00dqNOmFUlTfwUNnQcZmZmZmZm6zsvHzMzMzMzMzMzy0FOCpmZmZmZmZmZ5SAnhczMzMzMzMzMcpCTQmZmZmZmZmZmOchJITMzMzMzMzOzHOSkkJmZmZmZmZlZDnJSyMzMzMzMzMwsBzkpZGZmZmZmZmaWg5wUMjMzMzMzMzPLQU4KmZmZmZmZmZnlICeFzMzMzMzMzMxykJNCZmZmZmZmZmY5yEkhMzMzM1uvDRs2jPbt25Ofn19R9uCDD5KXl0ezZs2YNGlSRfnEiRMpLCyksLCQXr168cgjjwDw0Ucf0b9/f3beeWfy8vK46aab6v06zMzM1jYnhczMzMxsvTZ06FDGjRtXqSw/P58xY8bQr1+/lconTZrElClTGDduHKeccgplZWW0aNGC66+/nunTp/Paa69xyy23MH369Pq8DDMzs7WuRUMHYLlH0k+AR4AeEfFvSZ2B94AZwAbAC8AvgO2qKo+Ib6vosxlwI7A3EMAS4MiImCVpE+B6YF9gAfANcFFEvC6pE3ALsDNJkvQJ4IKIWCapCBgLzAI2Ap6IiPPT8YYC1wKfZITx/4CF6bU1A1oCf4yIUdXch9eBDYG2QKuMvn4CfAn8EfghIOBl4IyI+KqavjLvodI4ToiIGel1nB8RB2fFvRHwF2A6MDLtqmtatxh4B/h7+bkZY92R3ouHqomlGOhA8h0sA34WEVMy6m8EfgpsC+QBd6VV2wFfpT/zgJPScfLT8/YCfg9slrb/fUTcWlUMmRYvX0Hn4U/W1sysQZ1XUMZQP6fWyDXF57RkxEAA+vXrR0lJSaW6Hj16VHnOxhtvXPF5yZIlSAKgQ4cOdOjQAYBNN92UHj168Mknn7Dzzjuvg8jNzMzqh2cKWUMYDLyU/lpuZkQUAj1JEjQ/qaU821FAR6BnRBQAg0gSQAB/A74AukVEb+AEoJ2S/8sbAzwaEd2AHYFNgN9l9PtiOv4uwMGSfpRRd39EFGb8TAc+A/ZMz9kdGC6pY1UBR8TuabtLs/oqAW4D/hMRXSNiB5LE1N+qufZyM9PzewF3Ar+qpt396bg/Ai4GppePDUwCjkmPj6tlvJock8bxJ5IkFFCRvBsEfAT8OCKmZoz9GElCrjAi9s3sTNLWwL3AqRGxE7AXcIqkgWsQo5mZWZVef/118vLyKCgoYNSoUbRoUfnfUUtKSnjrrbfYfffdGyhCMzOztcNJIatX6aydvYATgaOz6yOiDHiFZMZKreUZOgCflc8iioiPI+JLSTuQJGcuyaibFRFPkswqWhIRt6flK4BzgGGSNs7sPCIWA1OAbWq6vohYFhFL08MNWY3/xiR1BXoDv80o/g3QJ72eutiMZLZRTbHOBz4kuXfryqtUvmdFwDTgz1ROCtbmNOCOiHgTICLmARcCw9dOmGZmZt/ZfffdmTZtGm+88QZXX301S5YsqagrLS3l8MMP58Ybb2SzzTaroRczM7PGz8vHrL4dBoyLiPclzZfUG5hfXpkmY/YhmT1DbeUZHgBektQXmADcHRFvkSxPmpImfLLlAZMzCyLia0n/Iyv5JGlzoBvJErZyR6VLmsrtGRGLJW0LPJn2cUFEfFpNzNXZOTvmiFghaUoa88xqztshbbMpsDFJMqxakrYjWUL2Ti3x9E37LbcdyTK7ujgAeDTjeDAwmmRZ3lWSWkbE8jr0k0cy+ynTpLR8JZJOBk4GaNduSy4tKKtjuGYNY6tWydIcs8asKT6nxcXFFZ9nz57NwoULK5UBLFiwgMmTJ1NaWlplH2VlZdx55510796dsrIyfvnLX7L77rvTtm3blfqyhldaWurvxZoEP6vWWDgpZPVtMFD+uo770uOb+S6hEcDYiHgq3SdnpfKqOo2IjyV1J5n9szcwQdJP10K8fSW9TZIQujEiZmfU3R8Rp1cRy0dAz3TZ2KOSHoqIOWshltqUL7VD0lHArSRJmWxHSeoH7AScHhFLqmiT6cUq9hSqzT2SNiBZjlce0wbAQcC5EfFNuqfSAOqeYKqzdK+hWwG269I1rp/q3+qscTuvoAw/p9bYNcXntOSYou8+l5TQunVrioqKKrVp06YNvXv3pk+fPgDMmjWLbbfdlhYtWvDf//6X2bNnc/jhh7PFFltw/PHH86Mf/Ygbb7yx/i7CVklxcfFK37FZY+Rn1RqLpvUnuzVpktqSJGwKJAXQnCTZcwsZCY0s1ZWvJF229RTwlKQ5JPsP3Qj0ktS8itlC04EjsmLcjGQmzIfAbqQJEUnbA69JeiBz0+Ra4vlU0rtAX6DKTZmrMR0olNSsfMlbuhdPYVpXF48Bt1dTd39EnC6pD/C0pMeykl1rwzEks7CuJdkw+/9IEkBtgKnppp0bk2xoXZek0HSSJXVjM8p6kyxFq1Grls2ZMcJbD1njVlxcXOkvr2aNUVN+TgcPHkxxcTHz5s2jU6dOXHHFFbRt25YzzjiDuXPnMnDgQAoLCxk/fjwvvfQSI0aMoGXLljRr1ow//elPtGvXjpdeeom77rqLgoICCgsLAbjqqqs46KCDGvbizMzM1oCTQlafjgDuiohTygskPU/yFqo1ImlXYHaaiGlGsjH1OxExU9Ik4ApJv46ISGcg5QH/BEZIOi4i/iGpOclbyu6IiEXlbxuBZB8iSSOAi6hhL5z0bWbz02Vkm5Psn3TDqlxLRHwo6S3gEpK9hEg/vxkRH9axm72ofplZ+TiTJN0FnAX8clVirIv0Xv8amClpJ5L7dlJEjAaQ1BqYJWnjiFhUS3e3AK9LGhMRUyRtQfLGtN/Ucp6ZmRmjR4+usnzQoEErlR177LEce+yxK5XvtddeRMRaj83MzKwheaNpq0+DSV7Xnulh1k5Coj3weDoz5x2gjGRZGiSvNt8K+DCtvwP4PJL/sxsE/FTSB8D7JK9Rr+6tXaOAfmlSCZJlWFMyfn4I9CBJXrwNPA9cFxFTV+N6TgR2lDRT0kySN6OdWMs5O6RxvA1clV53bUYCJ0jadDVirFW6Qff1JMm0A0j2WiqvW0jyFrpD6tDPZ8AQ4K+S/k2y6fjfI+LxdRG3mZmZmZlZLpD/xcPM1mfdu3ePGTNmNHQYZjXyvgLWFPg5tabAz6k1FX5WrT5JmhwRfaqq80whMzMzMzMzM7Mc5D2FrEmRVADclVW8NCJqfP16Q0vftLVhVvGxq7q0rDFdv6RHgO2zii+KiPH1HYuZmZmZmZmtOieFrElJkyiFDR3HqlpbSZvGdP0RsfLunGZmZmZmZtZkePmYmZmZmZmZmVkOclLIzMzMzMzMzCwHOSlkZmZmZmZmZpaDnBQyMzMzMzMzM8tBTgqZmZmZmZmZmeUgJ4XMzMzMzMzMzHKQk0JmZmZmZmZmZjnISSEzMzMzMzMzsxzkpJCZmZmZmZmZWQ5yUsjMzMzMzMzMLAc5KWRmZmZmZmZmloOcFDIzMzMzMzMzy0FOCpmZmZmZmZmZ5SAnhczMzMxsvTNs2DDat29Pfn5+RdmDDz5IXl4ezZo1Y9KkSRXl//rXv+jduzcFBQX07t2bZ599tqKuqKiI7t27U1hYSGFhIZ9//nm9XoeZmdm61KKhAzAzW5cWL19B5+FPNnQYZjU6r6CMoX5OrZFrSs9pyYiBDB06lNNPP53jjjuuojw/P58xY8ZwyimnVGrfrl07Hn/8cTp27Mi7777LgAED+OSTTyrq77nnHvr06VNv8ZuZmdUXzxSyNSKpNP21s6SQdEZG3c2Shqaf95D0uqQpkt6TdHkNfQ6VNFfSW5I+kDRe0g+z2rSTtFzSqenxzyTdn1G/maSZkrqs5thTMn52run6JN2StpsuaXHGeUdIukPSrPT4bUn7SMqT9L6kVhl9PSlpcB1imi7pZxl1P0nj2ik9vkfSzzPqd5f0jqSWkkokvZjV9xRJ76afiyR9lXXt+6Z1Ien6jPPOl3S5pIsz2q7I+HxmNddyedpX14yys9OyPhllhWnZARll26b3sm16vHl63Lm679PMzHJXv379aNu2baWyHj160L1795Xa7rLLLnTs2BGAvLw8Fi9ezNKlS+slTjMzs4bkpJCtTZ8DZ0naoIq6O4GTI6IQyAceqKWv+yNil4joBowAxkjqkVH/U+A1oDyR8jdg2/IkBvAb4O8R8Z/VHLsw42d6TdcXEaelfR8EzMw476G0yQVp/dnAqIiYBowBLoYksQO0jIjRtcUEFAFXSdoqLR8MvJRxH84FLpC0paRmwM3ALyJieVq/qaRt03Ez72e5F7Ou/Zm0fCnwf5LaZV3778rbAoszzvtDDdcyFTg64/inwLSsNtnXRUR8BPyZ5Hkg/fXWiCipYSwzM7NV8vDDD7Prrruy4YYbVpSdcMIJFBYW8tvf/paIaMDozMzM1i4vH7O1aS7wMnA88NesuvbAZwARsQKYTh1FxHOSbgVOBs5JiwcD5wH3SuoUER+ns4buTWcn7QP0XtOxs9R0fXXxKrBN+vk3wFuSHiJJbhxSlw4i4nNJM4HvS1oI7AX0Bx4HLouIOZKuA64B3gDeiYiXMrp4ADgKuI7kHo4Gjq3D0GXArST3/+K6xFqDR4HDgCsl7QB8BZQnrZAkkkTRfsCLkjaKiCVp9Q3AZElnk1z76VUNIOlkkueFdu225NKCsjUM2Wzd2qpVsjTHrDFrSs9pcXExALNnz2bhwoUVx+UWLFjA5MmTKS0trVQ+a9YsLrnkEq655pqKc0477TS23HJLFi1axGWXXcaiRYsYMGBAPVyFrY7S0tKVvm+zxsjPqjUWTgrZ2jYSeErS37PKbwBmSCoGxgF3ZvxFvy7eBE6BZBkR0CEiJkoqT3JcHxHvSBoPTAAOi4hlqzn2UZL2yjjesw7XVxcHkCREiIhFks4HXgB+HxEf1KUDSV2ALsCHJImVcRHxvqT5knpHxGRgFEniqgjI3gDhYeB2kqTQIcAxVE4K9ZU0JeP48IiYmX6+BXhH0jV1u9xqfQ18JCk/vYb7gRMy6n8IzIqImel3NjCNm4hYLukCku9x/4wZUJVExK0kSSy269I1rp/q3+qscTuvoAw/p9bYNaXntOSYouTXkhJat25NUVFRpfo2bdrQu3fvSvsEffzxx5x88sk88MAD/OhHP6qy388//5xJkyat1J81HsXFxf5+rEnws2qNRdP4k92ajIj4j6TXgf+XVf4bSfcA+6d1g0mSFnWljM9H8d0SsPuAvwPl+93cAhwYEcVrMPb9EVFpBkoyeaX666vFtZKuAjqRkWCKiMclLQD+VIc+yhNVS4FTIuKLdA+im9L6+0iua3JEfCvpL0CfiJif1c984EtJRwPvAYuy6l+MiIOrCiAivpb0D+BMYHEdYq7JfSRLyAaQzOrKTAoNTuvL2x1HmhRKHUgy8ysf+FdtA7Vq2ZwZIwauYbhm61ZxcXHFX2LNGqv1+TldsGABAwcOZMSIEZUSQmVlZSxYsIB27dqxfPlynnjiCfbdd98aejIzM2tavKeQrQtXARdROZFDRMyMiD+TJAF6SdpiFfrchSSJAUnSYKikEuAxoKekbmndt+lPJWs4drYqr68GF0TEjuk52TOMqoy3CuX7HO0eEY+kmy3vDfwtvQ8XAEeqPHtVc7/3kyTPatrDqDo3AicCrVfj3ExPkMxQ+l9EfF1eKKk5cDhwaXpdfwQOkLRpWl9IsqxsD+AcSR3WMA4zM1tPDR48mD333JMZM2bQqVMnbrvtNh555BE6derEq6++ysCBAyuWgd188818+OGH/OY3v6n06vmlS5cyYMAAevbsSWFhIdtssw0/+9nPahnZzMys6fBMIVvrIuLfkqaTLE96A0DSQOCfkezO2A1YASyoS3+SfkyyP0x/STsCm0TENhn1V5Akin5TzfmrPXZVqrq+OroZGCZpQESMX93xU0cAd0VExTt1JT0P9CVZklaTR4AOwHig46oMms5QeoAkMbQ6S+jK+1kk6SLg/ayqfUj2QarYrEHSncAgSXeRbDR9dkT8T9K1JMvgjlndOMzMbP01enTV//YxaNCglcouueQSLrnkkirbT548ea3GZWZm1ph4ppCtK78jWS5V7liSfX2mAHcBx6SbPlfnqPTV5u8DvyLZ2+Y9kuTPI1ltHybjLVVVWN2xy39+WIfrq1WalLoSuHBVzqvG6tyH8ji+iYiRGXsuZeqbde1HVNHmeqBdFeWrJCLui4g3s4pruq6fkcwsKl8y9iegR5o0NDMzMzMzs1Ukv1bTzNZn3bt3jxkzZjR0GGY18maT1hT4ObWmwM+pNRV+Vq0+SZocEdkvIQI8U8jMzMzMzMzMLCd5TyFrMJJOAM7KKn45Ik5bn8euTmOMaXVJuhj4aVbxgxHxu4aIx8zMzMzMzFbmpJA1mIi4Hbg918auTmOMaXWlyR8ngMzMzMzMzBoxLx8zMzMzMzMzM8tBTgqZmZmZmZmZmeUgJ4XMzMzMzMzMzHKQk0JmZmZmZmZmZjnISSEzMzMzMzMzsxzkpJCZmZmZmZmZWQ5yUsjMzMzMzMzMLAc5KWRmZmZmZmZmloOcFDIzMzMzMzMzy0FOCpmZmZmZmZmZ5SAnhczMzMzMzMzMcpCTQmZmZmZmZmZmOchJITMzMzNrkoYNG0b79u3Jz8+vKHvwwQfJy8ujWbNmTJo0qVL7q6++mq5du9K9e3fGjx9fqW7FihXssssuHHzwwfUSu5mZWWPQoqEDMDNblxYvX0Hn4U82dBhmNTqvoIyhfk6tkWtsz2nJiIEMHTqU008/neOOO66iPD8/nzFjxnDKKadUaj99+nTuu+8+pk2bxqeffsq+++7L+++/T/PmzQG46aab6NGjB19//XW9XoeZmVlD8kwhs0ZK0gpJUzJ+hktqLmmypH4Z7Z6WdFRGu9mSPsk43qCa/i+WNE3SO2m73dPyDSTdKOlDSR9IGiupU1rXWdK7Wf1cLun89PMdkmal/b0taZ+MdrtJekHSDElvSfqbpI0lDZU0N+tad64m5u9LejNtM03SqWt+p83MrKnq168fbdu2rVTWo0cPunfvvlLbsWPHcvTRR7Phhhuy/fbb07VrVyZOnAjAxx9/zJNPPslJJ51UL3GbmZk1Fp4pZNZ4LY6IwuxCSb8A/iqpN3AE8G1E3A/cn9ZfDpRGxHXVdSxpT+BgYNeIWCqpHVCePLoK2BToHhErJJ0AjClPGtXBBRHxkKT+wK1AN0lbAQ8CR0fEq2kMR6TjANwfEafXoe/PgD3TmDcB3pX0WER8WsfYzMwsR33yySfsscceFcedOnXik08+AeDss8/mmmuu4Ztvvmmo8MzMzBqEk0JmTUxEvC7pVeBy4P8B+61GNx2AeRGxNO1zHoCkjYETgO0jYkVad7ukYcDewMxVGONVYJv082nAneUJobTfh9Ix69xhRCzLONyQamY7SjoZOBmgXbstubSgbBXCNqt/W7VKluaYNWaN7TktLi4GYPbs2SxcuLDiuNyCBQuYPHkypaWlQJIUeu+99yraffbZZ0ybNo0PPviA5cuX88033zBlyhTmz5+/Ul/WdJSWlvr7sybBz6o1Fk4KmTVerSRNyTi+Op0RBPBL4CPgxoj4cDX6fhq4VNL7wDMkM3WeB7oC/4uI7A0VJgF5rFpS6ADg0fRzPnBnDW2PkrRXxvGeEbG4qoaStgWeTGO9oKpZQhFxK8ksJbbr0jWun+rf6qxxO6+gDD+n1tg1tue05Jii5NeSElq3bk1RUVGl+jZt2tC7d2/69OkDwKuvJv8uUd7u6quvZv/99+exxx5j8uTJDB06lCVLlvD111/zt7/9jbvvvru+LsXWouLi4pWeBbPGyM+qNRbeU8is8VocEYUZP/dn1PUDviJJtqyyiCgFepPMppkL3C9paF1OrUP5tWmy6V5gZB1Duj/rWqtMCAFExEcR0ZMkKXR8ujTNzMysRoceeij33XcfS5cuZdasWXzwwQfstttuXH311Xz88ceUlJRw3333sffeezshZGZmOaPx/HOPmdWJpNbANSTLuW6XdFBE/HNV+0mXhxUDxZKmAseT7PuznaRNIyJzY4XewBPAfGDzrK7aArMyjsv3FDoD+Ht67rT017GrGmcN8X+abnrdF3iounatWjZnxoiBa2tYs3WiuLi4YtaDWWPVGJ/TwYMHU1xczLx58+jUqRNXXHEFbdu25YwzzmDu3LkMHDiQwsJCxo8fT15eHkceeSQ777wzLVq04JZbbql485iZmVmuclLIrOm5FHggIv6dbjp9n6RnI2JJXTuQ1J1kg+oP0qJC4L8RsVDSncDvJZ2abjR9HLAx8GxEhKTPJO0dEc9KakuyTOymKoa5GRgmaUD6eaKkJyPi9TSG/wNeXpULT9+CNj8iFkvaHNgLuGFV+jAzs/XH6NGjqywfNGhQleUXX3wxF198cbX9FRUVeTmHmZnlFCeFzBqv7D2FxgF3AYOAXgAR8Zak8cBFwBWr0PcmwB8ltQHKgA9JN2Ym2a/oOuB9Sd8C/wYGRUT5ErHjgFsk/T49viIiVtprKE0gXQlcGBH7SDoauE5Se+Bb4IX0mmDlPYV+ERGvVBF3D+B6SQEIuC4ipq7CdZuZmZmZmVnKSSGzRioiqpvTvmNWuzOzji+vQ9+TgR9WU7cUOCP9qap+OtC/mrqhWccPAw+nn18lWeqV7Y70p1YR8S+gZ13ampmZmZmZWc280bSZmZmZmZmZWQ7yTCGz9ZikLYAJVVTtExHz6zueupJUQLJULtPSiNi9IeIxMzMzMzNbHzkpZLYeSxM/hQ0dx6pK9wkqbOg4zMzMzMzM1mdePmZmZmZmZmZmloOcFDIzMzMzMzMzy0FOCpmZmZmZmZmZ5SAnhczMzMzMzMzMcpCTQmZmZmZmZmZmOchJITMzMzMzMzOzHOSkkJmZmZmZmZlZDnJSyMzMzMzMzMwsBzkpZGZmZmZmZmaWg5wUMjMzMzMzMzPLQU4KmZmZmZmZmZnlICeFzMzMzMzMzMxykJNCZmZmZtbkDBs2jPbt25Ofn19R9uCDD5KXl0ezZs2YNGlSpfZXX301Xbt2pXv37owfP76ifNy4cXTv3p2uXbsyYsSIeovfzMysMXBSyMzMzMyanKFDhzJu3LhKZfn5+YwZM4Z+/fpVKp8+fTr33Xcf06ZNY9y4cfziF79gxYoVrFixgtNOO42nnnqK6dOnM3r0aKZPn16fl2FmZtagWjR0AGbrmqQVwFSS5/094PiIWCSpNCI2yWg3FOgTEaenxycD56bVXwPnRsRLaV0xsElE9EmP+wDXRUSRpCJgLDArI4zzI+KZrLi2ACakh1sDK4C56fFuQHvgFmBnkgTuE8AFEbGsmuvMHLcZ8Dnw/yLi88xrk3Q58LN0rA2A3wIbAWelXe0MzEjjGQf8O/O+ZFz/+RFR+Z9hv6svAb4BAvgSOC4i/ptR/yiwdUTsIWkAMDKt6gp8AiwG3gH+no5zcHreT4DfAC2BMuDXEfFoVTGUW7x8BZ2HP1lTE7MGd15BGUP9nFoj11ie05IRAwHo168fJSUllep69OhR5Tljx47l6KOPZsMNN2T77bena9euTJw4EYCuXbvSpUsXAI4++mjGjh3LzjvvvO4uwMzMrBHxTCHLBYsjojAi8oFlwKm1nSDpYOAUYK+I2Ck9515JW2c0ay/pwGq6eDEds/znmewGETG/vB4YBdyQcbwcGAM8GhHdgB2BTYDf1RJ6+bg9gTeA06ppd0M6zmHAX4C7M8b+FOifHg+vZbya9E/jKAYuKS+U1AboDXxPUpeIGJ8x9iTgmPT4uMzOJPUCrgMOi4gewKHAdZJ6rkGMZmaWAz755BO23XbbiuNOnTrxySefVFtuZmaWKzxTyHLNi0BdkggXkczKmQcQEW9KupMkyfLrtM21wMXAU+sgzr2BJRFxezr+CknnALMkXRYRi2o6WZKATYEPa2oXER9IWgRsTjKzaF14FTgz4/j/gMeBOcDRwFV17Od84KqImAUQEbMkXQ1cAByb2TCd5XUyQLt2W3JpQdkaXYDZurZVq2QWhllj1lie0+Li4orPs2fPZuHChZXKABYsWMDkyZMpLS0FkqTQe++9V9Hus88+Y9q0aRWfy8vfe+89Pvnkk5X6s6ajtLTU3581CX5WrbFwUshyhqQWwIEkS6IAWkmaktGkLfBY+jkPmJzVxSTg+IzjV4FBkvqTLJXK1Der78MjYuYqhLvS+BHxtaT/kSyxeqea88rH3QJYCPyqpkEk7Qp8EBG1JYSOkrRXxnHXWtpnOgB4NON4MMkSsDnAw9Q9KZRHMlMo0ySqmA0VEbcCtwJs16VrXD/Vv9VZ43ZeQRl+Tq2xayzPackxRd99LimhdevWFBUVVWrTpk0bevfuTZ8+fQB49dVXASraXX311ey///4AvPLKKxXlr776KrvttttK/VnTUVxc7O/PmgQ/q9ZYePmY5YLy5M8k4H/AbWl5+bKy8qVLl65G31eSsTQqQ/bysVVJCK2J8nG3BW4Hrqmm3TmSpgGvU/uSNID7s+5VlXsJZXlO0ickibjRAJK2AroBL0XE+8BySfk19GFmZrbGDj30UO677z6WLl3KrFmz+OCDD9htt934wQ9+wAcffMCsWbNYtmwZ9913H4ceemhDh2tmZlZvGv6fe8zWvcVpImNVTCfZ9+bZjLLewLTMRhHxrKQrgT3WKMKqxz8is0DSZsB21LIkLMNjJDNxqnJDRFwn6VDgNkk7RMSS1Y62av2BBcA9wBUkm3YfSbJUbVaywo3NSGYOXVyH/sq/k7czylb6TrK1atmcGemmpGaNVXFxcaXZD2aNUWN7TgcPHkxxcTHz5s2jU6dOXHHFFbRt25YzzjiDuXPnMnDgQAoLCxk/fjx5eXkceeSR7LzzzrRo0YJbbrmF5s2bA3DzzTczYMAAVqxYwbBhw8jLy2vgKzMzM6s/TgqZVe0aYKSkAyJivqRCYCiwexVtryTZKPo/a3H8CcAIScdFxD8kNQeuB+6obT+hDHsBNc5QiojHJJ1IsizuL2sUcdX9l0k6G5iaJs8GAwdExKsAkrYHnqFuSaHrgAclPRsRJZI6kyyPO6Lm08zMbH00evToKssHDRpUZfnFF1/MxRev/MfNQQcdxEEHHbRWYzMzM2sqnBQyq0KaLNkGeEVSkOwZNCQiPqui7T8lzc0qzt5T6MqIeGgVxg9Jg4A/Sfo1yVLPf1LLHkEZ4wr4CjipDsP9huTNan+NiG/rGmNdRcRnkkaT7P3zfeC1jLpZkr6StHtEvF5LP1MkXQQ8LqklyRvaLoyIKWs7ZjMzMzMzs1ygiGjoGMzM1pnu3bvHjBkzGjoMsxp5s0lrCvycWlPg59SaCj+rVp8kTY6IPlXVeaNpMzMzMzMzM7Mc5OVjZvVA0hYk+wRl2yci5q9iXwOAkVnFsyKi6k0U1iFJrwMbZhUfGxFT6zsWMzMzMzMzWzVOCpnVgzTxU7iW+hoPjF8bfa2piKhq420zMzMzMzNrArx8zMzMzMzMzMwsBzkpZGZmZmZmZmaWg5wUMjMzMzMzMzPLQU4KmZmZmZmZmZnlICeFzMzMzMzMzMxykJNCZmZmZmZmZmY5yEkhMzMzMzMzM7Mc5KSQmZmZmZmZmVkOclLIzMzMzMzMzCwHOSlkZmZmZmZmZpaDnBQyMzMzMzMzM8tBTgqZmZmZmZmZmeUgJ4XMzMzMzMzMzHKQk0JmZmZm1ugNGzaM9u3bk5+fX1H2xRdfsN9++9GtWzf2228/vvzySwC++uorDjnkEHr16kVeXh633357xTkXXngheXl59OjRgzPPPJOIqPdrMTMzayxaNHQAZmuLpJ8AjwA9IuLfkjoD7wEzgA2AF4BfANtVUw5wI7A3EMAS4MiImFXNeCXAN8CKtOiFiDhT0mPAQxHxj7TdX4H3gSOADYG2QCvgk/S8n0RESRX9DwPOSWNpBlwcEWMlCbgYOD6t+wQ4PSKmpeeVRsQmGf0MBfpExOmSLgd+BsxNr/23ETE6bbdjev3d0uv6EDgD6AGMBTLvw/kR8Uw19yWAeyJiSHrcAvgMeD0iDk7juTbj+gH+X0RMT9ufDYwAtoqIr9KyIuA54NCIeDwtewK4LiKKq4qj3OLlK+g8/Mmampg1uPMKyhjq59QauYZ6TktGDARg6NChnH766Rx33HEVdSNGjGCfffZh+PDhjBgxghEjRjBy5EhuueUWdt55Zx5//HHmzp1L9+7dOeaYY5g0aRIvv/wy77zzDgB77bUXzz//PEVFRfV+XWZmZo2Bk0K2PhkMvJT+ellaNjMiCtPExLPAT4A3qynfEOgI9IyIbyV1AhbWMmb/iJiXVXYm8FyaHNoZ2B34eURcC5WTNNV1mo59MbBrRHwlaRNgy7T6NOCHQK+IWCRpf+AxSXkRsaSWeAFuiIjrJHUDJkt6CGgOPAmcm5F0KcoY88WIOLgOfUNyz/IltYqIxcB+VE4AAdxfw/UPBt4A/g+4PaP8Y5J78ngd4zAzs/VIv379KCkpqVQ2duxYiouLATj++OMpKipi5MiRSOKbb74hIigtLaVt27a0aNECSSxZsoRly5YRESxfvpytttqq/i/GzMyskfDyMVsvpEmTvYATgaOz6yOiDHgF6FpDeQfgs4j4Nq37OCK+XNVY0lk/twLXAH8mmcVTtordtCeZrVOa9lmaMWPporTPRWnd0+k1HLOKcX4ALAI2B/4f8Gp5QiitL46Id1cx7nL/BAamnwcDo+tykqQdgE2AS9LzMr0NfCVpv9WMyczM1jNz5syhQ4cOAGy99dbMmTMHgNNPP5333nuPjh07UlBQwE033USzZs3Yc8896d+/Px06dKBDhw4MGDCAHj16NOQlmJmZNSjPFLL1xWHAuIh4X9J8Sb2B+eWVkjYG9gEuzTwpq3wq8JKkvsAE4O6IeKuWcZ+TVL587M6IuCH9fB0wk2SGzQurcT1vA3OAWZImAGMi4nFJmwGtI+I/We0nAXmrMoCkXYEPIuJzSfnA5Bqa95U0JeP48IiYWUP7+4BL0yVePYG/A30z6o+StFfG8Z7prKKj03NfBLpL2ioi5mS0+x3wW+BftVzbycDJAO3abcmlBauakzOrX1u1SpbmmDVmDfWcls8EApg9ezYLFy6sKCsrK6tUv2LFCoqLi3n++edp164d9957L59++iknnXQSf/vb31iwYAEvvfQSo0cn/1Zx/vnns9VWW9GzZ896vCJbl0pLSys9E2aNlZ9VayycFLL1xWDgpvTzfenxzcAOaTIjgLER8VS619BK5QCSupPsKbQ3MEHSTyNiQg3jVrV8DJJESDNgJ0nNymcf1VVErJB0APADkqTVDWmi6/er0k9mlxmfz5F0ArAjcEgdz1+V5WNExDvpfR5MMmsoW3XLxwYDg9Llew8DPyX5Hsv7fUESWQmlqsa/lWS2Ftt16RrXT/Vvdda4nVdQhp9Ta+wa6jktOabou88lJbRu3bpiD6BtttmG7t2706FDBz777DM6duxIUVER1157LcOHD6dv3+TfI2677Ta23HJLpk+fzsCBAznwwAMBeOONN1iyZIn3FFqPFBcX+/u0JsHPqjUW/j9Qa/IktSVJ4hSkmxw3J0mC3EK6d1AVp1VZHhFLgaeApyTNIdlrqKakUFXxNAP+BAwBTgV+nsaySiJ5HcpEYKKkfwG3R8TlkhZK6pI1W6g38Hz6ebGkDSJiWXrcFshMXJXvKXQocFu6ZGsa8ONVjbEWj5HMmCoCtqitsaQCkk2u/5Xspc0GJJtb35zV9Hcky8vq9M/VrVo2Z8aIgbU3NGtAxcXFlf7ia9YYNcbn9NBDD+XOO+9k+PDh3HnnnRx22GEAbLfddkyYMIG+ffsyZ84cZsyYQZcuXZg1axZ//etf+eUvf0lE8Pzzz3P22Wc37EWYmZk1IO8pZOuDI4C7IuL7EdE5IrYlSSZsuyqdSNpVUsf0czOS2T7/XY14TiFZllUMnAtcJGnLmk9ZKZaO6fKucoUZsVwL/EFSq7TtviT7Kd2b1j9PkpAibXMkyZu7KomIx0iWnR2fnvtDSRXZE0n90mVlq+vvwBURMbWO7QcDl6ffYeeI6Ah0lPT9rLifJtkHyXP9zcxyyODBg9lzzz2ZMWMGnTp14rbbbmP48OH861//olu3bjzzzDMMHz4cgF//+te88sorFBQUsM8++zBy5EjatWvHEUccwQ477EBBQQG9evWiV69eHHJIXSfNmpmZrX88U8jWB4OBkVllDwO/XMV+2gN/lbRhejyRlWepZMvcU+gd4HySjaD3AIiITyXdSLLp9AmrEEtL4Lo0SbWE5BXyp6Z1fyRJikxNx54NHJbuyQNwFvAXSWcCAv5Rw75GvyFJCP0VOBi4MY13eXo9ZwHtWHlPoSsj4qGaLiAiPgb+UE119p5CvyDZT+igrHaPpOWvZ5X/Dhhb0/hmZrZ+Kd8HKNuECStP6O3YsSNPP/30SuXNmzfnL3/5y1qPzczMrKlSskLFzGz91L1795gxY0ZDh2FWI+8rYE2Bn1NrCvycWlPhZ9Xqk6TJEdGnqjovHzMzMzMzMzMzy0FePmZWC0mvAxtmFR+7CnvlNGj/64KkLah6A+59ImJ+fcdjZmZmZmZmq85JIbNaRMTuTbn/dSFN/BQ2dBxmZmZmZma2+rx8zMzMzMzMzMwsBzkpZGZmZmZmZmaWg5wUMjMzMzMzMzPLQU4KmZmZmZmZmZnlICeFzMzMzMzMzMxykJNCZmZmZmZmZmY5yEkhMzMzMzMzM7Mc5KSQmZmZmZmZmVkOclLIzMzMzMzMzCwHOSlkZmZmZmZmZpaDnBQyMzMzMzMzM8tBTgqZmZmZmZmZmeUgJ4XMzMzMzMzMzHKQk0JmZmZm1mgNGzaM9u3bk5+fX1H2xRdfsN9++9GtWzf2228/vvzySwC++uorDjnkEHr16kVeXh633347AFOmTGHPPfckLy+Pnj17cv/99zfItZiZmTU2ioiGjsHMbJ3ZrkvXaHbkTQ0dhlmNziso4/qpLRo6DLMa1fdzWjJiIAAvvPACm2yyCccddxzvvvsuABdeeCFt27Zl+PDhjBgxgi+//JKRI0dy1VVX8dVXXzFy5Ejmzp1L9+7dmT17NiUlJUiiW7dufPrpp/Tu3Zv33nuPNm3a1Nv1WP0oLi6mqKioocMwq5WfVatPkiZHRJ+q6jxTyBo9SVtLuk/STEmTJf1T0o6SFkuaImm6pH9Iapm2L5L0VVpX/rNvWrciPZ4m6W1J50lqlnHeE5JOyDhvmaSp6ecR1cQ3VNJcSW9J+kDSeEk/zKi/Q9KsjD5fyTqvPJ6HJG0s6eKMtisyPp9ZzfiXS/ok414Mzqr/iaSQtFN6/Hra9n8Z40+R1FlSiaR2abtOksam1zRT0k2SNqjD93VjGk+Nv79IaiPpFxnHHSU9VFv/ZmaWW/r160fbtm0rlY0dO5bjjz8egOOPP55HH30UAEl88803RASlpaW0bduWFi1asOOOO9KtWzcAOnbsSPv27Zk7d269XoeZmVlj5KSQNWqSBDwCFEfEDhHRG/glsBUwMyIKgQKgE3BkxqkvRkRhxs8zafni9DgP2A84ELgsc8yIuL38POBToH96PLyGUO+PiF0iohswAhgjqUdG/QUZsfww67zyeJYBR0XE7zLGX5xx3h9qGP+GtP1hwF/KE2SpwcBL6a9ExO5p20szxi+MiJLyE9L7PgZ4NL2mHYFNgN/VEANpImgQ8BHw45raAm2AiqRQRHwaEUfUco6ZmRlz5syhQ4cOAGy99dbMmTMHgNNPP5333nuPjh07UlBQwE033USzZpX/d3fixIksW7aMHXbYod7jNjMza2w8V90au/7A8ogYVV4QEW9L6pxxvELSRGCbVek4Ij6XdDLwhqTL11K8RMRzkm4FTgbOqcs5kloArYEv13DsDyQtAjYHPpe0CbAXyX18nKwEWA32BpZExO1pvysknQPMknRZRCyq5rwiYBpwP0kS6jkASVsBo4AuabufA2cCO0iaAvwLuAV4IiLyJb0GnBgR09Lzi4HzgfeAPwL5QEvg8ogYmx1E+r2eDNCu3ZZcWlBWx8s2axhbtUqW5pg1ZvX9nBYXF1d8nj17NgsXLqwoKysrq1S/YsUKiouLef7552nXrh333nsvn376KSeddBJ/+9vfaN26NQDz58/nnHPOYfjw4bzwwgv1di1Wf0pLSys9G2aNlZ9VayycFLLGLh+YXFMDSRsBuwNnZRT3TZMN5Q6PiJnZ50bEfyQ1B9qvhVgzvQmcknF8raRL0s/TIuKY9PNRkvYCOgDvkyRuVpukXYEPIuLztOgwYFxEvC9pvqTeEVHj/UzlkXXfI+JrSf8DugLvVHPeYGA0MBa4SlLLiFgO/AF4PiIGpfd7E2A4kJ/OWiIz0UeSVDoSuExSB6BDREySdBXwbEQMk9QGmCjpmYhYmBXrrcCtkOwp5L1arLHznkLWFNT7nkLHFH33uaSE1q1bV+y/sc0229C9e3c6dOjAZ599RseOHSkqKuLaa69l+PDh9O3bF4DbbruNLbfckt12242vv/6aoqIifv/733PEEZ6Yur7yPi3WVPhZtcbCy8esKSufZTIH+CwiMhMV2cvHVkoIrWPKOs5cPnZMRvn9aVJka2AqcMFqjneOpGnA61Re4jUYuC/9fF96vE6k+w0dRLLk7Os0lgFp9d7AnyGZdRQRX9XS3QNA+f+xHwmU7zW0PzA8/d6LgY2A7dbSJZiZWRNx6KGHcueddwJw5513cthhhwGw3XbbMWHCBCBZYjZjxgy6dOnCsmXLGDRoEMcdd5wTQmZmZhn8z5LW2E3ju+RAtpkRUZhujPyypEMj4rFV6VxSF2AF8DnQo5bmq2IXkqVOdRIRIelx4AySPYlW1Q0RcZ2kQ4HbJO0AbEySjCmQFEBzICRdELW/dnA6Wfdd0mYkCZgPqzlnAMk+QVOTLYnYGFgMPLGqFxMRn6Qzm3oCRwGnlodBMutrRl37atWyOTPSN9iYNVbFxcWVZkWYNUYN9ZwOHjyY4uJi5s2bR6dOnbjiiisYPnw4Rx55JLfddhvf//73eeCBBwD49a9/zdChQykoKCAiGDlyJO3atePuu+/mhRdeYP78+dxxxx0A3HHHHRQWFtb79ZiZmTUmTgpZY/csyTKkk9MlQaSJgu+VN4iIeZKGk2xAXeekkKQtSfa5uTlNyqyVgCX9mGQ/m/6reOpewBrNaIqIxySdCBwPBHBXRFQsY5P0PNAXqG0jhQnACEnHRcQ/0iVf1wN31LCf0GDgpIgYnY7VmmQPoo3T/n4O3JixfOwbYNMaYrgfuBD4XsYssPHAGZLOSL+zXSLirVquxczMmrDRo0dXWV4+IyhTx44defrpp1cqHzJkCEOGDFnrsZmZmTV1Xj5mjVo6o2UQsG/6WvRpwNXA7KymjwIbS+qbHvdV5VfSl896aVX+CnjgGeBp4Iq1EOpRab/vA78imc2SOVPo2qx4Nsg67x2S2UW/XQux/AY4lyRJ80hW3cPUYQlZxn3/qaQPSPY7WkJybStJEz8HAE9m9LGQ5K1nh5Ds99Rf0lSSvYp2joj5JDO83pV0bRXdPgQcTbKUrNxvSTaYfif9DtfG/TIzMzMzM8tJqn0ViZlZ09W9e/eYMaPOq83MGoQ3m7SmwM+pNQV+Tq2p8LNq9UnS5IjoU1WdZwqZmZmZmZmZmeUg7ylkVkeSTqDya+8BXo6I0+pp/IuBn2YVPxgRv6uq/TqMYwAwMqt4VkQMqs84zMzMzMzMbM04KWRWRxFxO3B7A47/Oyq/br6h4hhPsuGzmZmZmZmZNWFePmZmZmZmZmZmloOcFDIzMzMzMzMzy0FOCpmZmZmZmZmZ5SAnhczMzMzMzMzMcpCTQmZmZmZmZmZmOchJITMzMzMzMzOzHOSkkJmZmZmZmZlZDnJSyMzMzMzMzMwsBzkpZGZmZmZmZmaWg5wUMjMzMzMzMzPLQU4KmZmZmZmZmZnlICeFzMzMzMzMzMxykJNCZmZmZtZoDBs2jPbt25Ofn19R9sUXX7DffvvRrVs39ttvP7788ksArr32WgoLCyksLCQ/P5/mzZvzxRdfVNuPmZmZVeakkJmZmZk1GkOHDmXcuHGVykaMGME+++zDBx98wD777MOIESMAuOCCC5gyZQpTpkzh6quv5sc//jFt27atth8zMzOrrEVDB2DWVEhaAUwFWgJlwD+AGyLi24w2jwJbR8QektoDE4E9ImJ2Wn8L8DFwE/BXoCcgYAFwQESU1jJ2C2AWcGxELJDUGXgPmJHR/PcR8Q9JmwDXAvsDXwEBjIqIv6bnPRER+ZI2riKWY4CxaX9bAyuAuenxbsDiquLJiHcK8O+IOFrSCcBZadXOaawrgHHAv4E+EXF6et7JwLlp26+BcyPipbSuGNgkIvqkx32A6yKiqKp7Vm7x8hV0Hv5kTU3MGtx5BWUM9XNqjdy6fk5LRgwEoF+/fpSUlFSqGzt2LMXFxQAcf/zxFBUVMXLkyEptRo8ezeDBgyuOq+rHzMzMKnNSyKzuFkdEIUCa8LkX2Ay4LC1rA/QGSiV1iYj/SBoBXAcMkbQr0Ddtcz4wJyIK0nO7A8vrOPadwGnA79K6meV1Wf4G/AfoFhHfStoSGFZFu7OqiGV2xniXA6URcV35CZKqjUdSD6A50FdS64i4Hbg9rSsB+kfEvPR4aEafBwOnAHtFxLz0fj0qabfypBrQXtKBEfFUDffKzMzWM3PmzKFDhw4AbL311syZM6dS/aJFixg3bhw333xzQ4RnZmbWZDkpZLYaIuLzdFbLG5Iuj4gA/g94HJgDHA1cBdwKHC+pf3p8ekQsl9QB+G9GfzNWGqR6r5LM6qmWpB1IZvT8v/KZTBExFxhZRfM1iaWqeAYDdwE9gMNIkmd1cRH/n707j9Nzuv8//npnIwtSIhJCIkRCJoT4NagymkYpFTuhJWi1Vaq+ttRWFB1bK4gqglC1lBC1lUaHUFuQTSJCMxVE0sSapUh8fn9c5x537tyzZJuZuN/Px2Mec1/nOudcn+uaIzKfnHMuOD2XMIqIV/ISTuemOpcDZwO1JoXSz+Z4gA4dNuS8PovrGYJZ49iodTYLw6wpW93jNDcTCOD9999nwYIF1WWLFy9e6vySJUuWOn7yySfp1asXEydOXKrPwn7s62/+/Pn+edsawWPVmgonhcxWUJoJ1BzoSJYIGgxcmD7fB1ySZuj8HHgSeDAink7NbwYel3QwMAYYGRHT67pmut4AYERe8RZpuVbOScA3gAn5S9tqsUKx1BLPYcBAoFeKpb5Jod7AywVl44Cj846fAw5ISbZPa+ooIm4gS8ixWfct48pJ/qPOmrZT+yzG49SautU9TquOLP/qc1UVbdu2pbw8K9tkk03o2bMnnTt3ZtasWWy88cbV5wCGDRvGiSeeuFRZsX7s66+ystI/b1sjeKxaU+GNps1WAUkbAT2AZyLiDeALSWUAETEemAxcl6ufyrqTzXxZn2zG0da1XKJ1Svy8D2wEPJF37q2I6Jv3NbZIfGdLGi/pvcJzKxBLjfGkfX7mRsTbZAmm7SWtX0dfy+si4JxV3KeZmTVh++23HyNHjgRg5MiRDBo0qPrcxx9/zFNPPbVUmZmZmdWP/1nSbAVJ6k62YfIc4ESy2TkzJEG219BgsqVOAF+mr2ppU+lRwChJXwLfJ9s0uphFEdE3bQr9d7IlVVfXEt4UYDtJzSLiy4i4GLhYUtGNrJczltriGQz0SnsHQfYcDiLbyLouU8j2W3oyr6wf8FpBrE9KugjYqR590rplc6alzUvNmqrKysqlZkmYNUUNNU4HDx5MZWUlc+fOpUuXLlxwwQUMHTqUQw89lBEjRtC1a1fuueee6vr3338/e+65J23btq2zn+OOO261x29mZrYmcVLIbAWkTZuvB66NiJA0mOztYc+l85sD/+CrpFBh+28BUyLiQ0mtyN7KVVnXdSNioaRfkm3AfF0t9d6UNA64SNK5EbFE0tpkbxdbJbEUied64FCgT0S8l/reg2w/oPokhS4DLpW0V0TMk9QXGAL0L1L3IrLn/+/6xGlmZmuOO++8s2j5mDFjipYPGTKEIUOG1LsfMzMz+4qTQmb1l1sylXsl/e3A79Pr3bsCz+cqRsQMSR9L6h8RLxTpawvgj8qmFTUDHibbh6hOEfGqpIlks3LGsuyeQjdHxNXAj8mWhL0paR7Za+TPWJWxFMTza+DdXEIoeRrYRlLniJhVRz8PStoE+JekINsz6IfF2kXEI5L+W98YzczMzMzMbFlOCpnVU0Q0r+FUFbBJkfo75H0uLzh3G3Dbcly7XcHxD/IOW9fQ5hOyV7wXO1cF5PY8qjWWiDh/OeK5oKB8CdAp77hbwflbgVvzjv8I/LGGOMoLjvvVFLOZmZmZmZnVzRtNm5mZmZmZmZmVIM8UMmsiJG1A9sauQgMiYl5Dx2NmZmZmZmZfb04KmTURKfHTt7HjMDMzMzMzs9Lg5WNmZmZmZmZmZiXISSEzMzMzMzMzsxLkpJCZmZmZmZmZWQlyUsjMzMzMzMzMrAQ5KWRmZmZmZmZmVoKcFDIzMzMzMzMzK0FOCpmZmZmZmZmZlSAnhczMzMzMzMzMSpCTQmZmZmZmZmZmJchJITMzMzMzMzOzEuSkkJmZmZmZmZlZCXJSyMzMzMzMzMysBDkpZGZmZmarxbHHHkvHjh0pKyurLvvggw8YOHAgPXr0YODAgXz44YcAjB49mm233Za+ffuy44478swzzwDwn//8hx122IG+ffvSu3dvrr/++ka5FzMzs68jJ4XMzMzMbLUYMmQIjz322FJlFRUVDBgwgOnTpzNgwAAqKioAGDBgABMmTGD8+PHcfPPN/PjHPwagc+fOPPfcc4wfP54XXniBiooK3nvvvQa/FzMzs6+jFo0dgFl9SLoVeCgi7pV0E/D7iJiynH3sD7yxvO1WVE0xSzorIi5ZzdeeHxHtaouplrZDgMcjYrX+jVtSe+CIiLguHW8MXB0RB6/K6yz6Ygndhj68Krs0W+VO7bOYIR6n1sQtzzitqtgHgN12242qqqqlzo0ePZrKykoAjj76aMrLy7n00ktp1+6r/20tWLAASQC0atWquvyzzz7jyy+/XIm7MDMzs3yeKWRNnqTm+ccR8eMVTOzsD2yzkrGsUCK1IOazViaGBjAE2LgBrtMeOCF3EBHvreqEkJmZNT2zZ8+mc+fOAHTq1InZs2dXn7v//vvp1asX++yzDzfffHN1+cyZM9l2223ZdNNNOfPMM9l444b435SZmdnXn5NC1mAk/VDSi5LGS/qTpOaS/ihpnKTXJF2QV7dK0qWSXgEOKeinUtKO6fOekp6T9Iqkv0pql8orJE2RNFHSFZJ2AfYDLk/X36KGGLeU9A9JE1KfW0gqlzRW0oPAlBT35ZJeSv3/NLWVpGslTZP0D6BjYcySKoDWKYY7ludZpfL5ki5O8T0vaaNUvnl6DpMkXZTXT20xnZfuYbKkG1Ldg4EdgTvStVtL6ifpKUkvS/q7pM61xP2T1OcESfdJapPKN5J0fyqfkH4eFcAW6TqXS+omaXKq/7yk3kWeX1tJN6dn86qkQTXFYmZmTZ+k6hlBAAcccACvv/46DzzwAOeee251+aabbsrEiRN58803GTly5FKJJDMzM1txXj5mDULS1sBhwLci4gtJ1wFHAmdHxAcp6TFG0rYRMTE1mxcRO6T2exXpswNwDvDdiFgg6Uzg/yQNBw4AekVESGofER+lpE6tS6eAO4CKiLhf0tpkidNNgR2AsoiYIel44OOI+H+S1gKelfQ4sD3Qk2w20kbAFODm/M4jYqikEyOi7wo8q9uAtsDzEXG2pMuAnwAXAcOAP0bEbZJ+kdfdAbXEdG1EXJiueTuwb1rqdiJwWkSMk9QSuAYYFBH/lXQYcDFwbA3hj4qIG1OfFwHHpfZXA09FxAHpZ90OGJqead9Uv1teP3cDhwK/SUmozimeS4AnI+JYZcvPXpT0j4hYUPAMjweOB+jQYUPO67O4psdt1iRs1DpbmmPWlC3POM0tDwN4//33WbBgQXXZuuuuy3333ccGG2zAvHnzWGeddZaqnzNlyhRGjx7Neuutt1T5BhtswPXXX8/uu+++ordiX2Pz588vOp7MmhqPVWsqnBSyhjIA6Ae8lP5FsDUwBzg0/QLfAuhMlrzIJYXurqPPnVL9Z1OfrYDngI+B/wEjJD0EPFSfACWtA2wSEfcDRMT/UjnAixExI1XdE9g2zaoBWA/oAewG3BkRS4D3JD1Zn+sWUdOzAvg8735eBgamz98CDkqfbwcuTZ9ri2kPSWcAbYD1gdeAvxXE0hMoA55IsTQHZtUSe1lKBrUnS/z8PZV/BzgKIMXysaRv1NLPPcDjwG/IkkO5RN6ewH6STkvHawObAVPzG0fEDcANAJt13zKunOQ/6qxpO7XPYjxOralbnnFadWT5V5+rqmjbti3l5VnZYYcdxvTp0znooIOoqKjg8MMPp7y8nDfffJMtttgCSbzyyitIYr/99uPdd99lgw02oHXr1nz44Ye89dZbXHbZZfTp02c13KWt6SorK6vHmllT5rFqTYX/BmoNRcDIiPh1dYG0OfAE8P8i4kNlmyCvnddmAbUT8EREDF7mhPRNsuTKwcCJZEmJlZEfi4CTIuLv+RUkfX8lr5Hf/1LPKs8XERHp8xKW/m84itQvfoFsFtR1wI4RMVPS+Sz97PNjeS0idq5n17cC+0fEBGUbVpfXN6Z8EfGupHmStiWbNfWzvHgOiohp9e2rdcvmTEsbnpo1VZWVlUv9Em3WFK3IOB08eDCVlZXMnTuXLl26cMEFFzB06FAOPfRQRowYQdeuXbnnnnsAuO+++7jtttto2bIlrVu35u6770YSU6dO5dRTT0USEcFpp53mhJCZmdkq4qSQNZQxwGhJf4iIOZLWJ5vhsYBs1shGwN5A5XL0+TwwXNKWEfGmpLbAJsB7QJuIeETSs8C/U/1PgXVq6iwiPpX0jqT9I+KBtDSseZGqfwd+LunJtLxrK+Bd4Gngp5JGku3dswfwlyLtv5DUMiK+qCGUYs9qnYj4Ty3P4lngcODPZEvNcmqKKZcAmqtsH6aD+Wo2Tv5zmgZsKGnniHguLSfbKiJeqyGOdYBZqd6RZM8ld08/B67KWz5W68+DbKbYGcB6eUsK/w6cJOmktDRw+4h4tZY+zMysEd15551Fy8eMGbNM2ZlnnsmZZ565TPnAgQOZOHHiMuVmZma28rzRtDWI9Oatc4DHJU0kmyH0GfAq8DpZouLZ5ezzv2Rvyroz9fkc0Iss0fBQKnsG+L/U5C7g9LRBcdGNpoEfAb9Mbf8FdCpS5yayvXleSRsj/4kswXo/MD2duy3FU8wNwETVsNF0Dc+qxs2dk5OBX0iaRJYYyykaU0R8BNwITCZLtLyU1+ZW4HpJ48mSYgcDl0qaAIwHdqkljnOBF8h+lq8XxLdHiu9lYJuImEe29G+ypMuL9HUvWaLrnryy3wItyZ7fa+nYzMzMzMzMVoC+WoliZvb107Nnz5g2rd6rzcwahfcVsDWBx6mtCTxObU3hsWoNSdLLEbFjsXOeKWRmZmZmZmZmVoK8p5CVpPTa+m8VFA+LiFsaMIYNyPbaKTQgLa1qsprC8zMzMzMzM7OV46SQlaSI+EUTiGEe0Lex41gRTeH5mZmZmZmZ2crx8jEzMzMzMzMzsxLkpJCZmZmZmZmZWQlyUsjMzMzMzMzMrAQ5KWRmZmZmZmZmVoKcFDIzMzMzMzMzK0FOCpmZmZmZmZmZlSAnhczMzMzMzMzMSpCTQmZmZmZmZmZmJchJITMzMzMzMzOzEuSkkJmZmZmZmZlZCXJSyMzMzMzMzMysBNUrKSRpC0lrpc/lkn4pqf1qjczMzMzMzMzMzFab+s4Uug9YImlL4AZgU+Avqy0qMzMzMzMzMzNbreqbFPoyIhYDBwDXRMTpQOfVF5aZmZmZrcmOPfZYOnbsSFlZWXXZBx98wMCBA+nRowcDBw7kww8/BOCOO+5g2223pU+fPuyyyy5MmDChus2wYcMoKyujd+/eXHXVVQ19G2ZmZl9rLepZ7wtJg4GjgR+ksparJyQzs1Vn0RdL6Db04cYOw6xWp/ZZzBCPU2vi6jtOqyr2AWDIkCGceOKJHHXUUdXnKioqGDBgAEOHDqWiooKKigouvfRSNt98c5566im+8Y1v8Oijj3L88cfzwgsvMHnyZG688UZefPFFWrVqxV577cW+++7Llltuudru08zMrJTUd6bQMcDOwMURMUPS5sDtqy8sK0WSlkgaL+k1SRMknSqpWUGdByQ9nz53lFQlqVPe+eGSfi2pjaQ7JE2SNFnSM5La1XLt+bWcu0rSu/mxSNpI0kMpzimSHpHUJ8U/XtIHkmakz/+ood9ukhalOlMkXS+pWSqfXFD3fEmnpc+SdI6k6ZLekPRPSb3z6lZJui/v+GBJt6bPQyT9Ny/O8ZK2qeXet0r3Nl3SK5LuSfdeLumhgrq3Sjo477iDpC8k/aygXo3xpeO9JL0o6fUU392SNsu7xoy82P9VU+xmZta4dtttN9Zff/2lykaPHs3RRx8NwNFHH80DDzwAwC677MI3vvENAHbaaSfeeecdAKZOnUr//v1p06YNLVq0YPfdd2fUqFENdxNmZmZfc/WaKRQRUySdCWyWjmcAl67OwKwkLYqIvpAlfMj2rVoX+E0qaw/0A+ZL6h4R/5ZUAVwB/FDSDsC3U53TgNkR0Se17Ql8sbwBpUTQAcBMYHfgn+nUhcATETEs1ds2IiYBufhvBR6KiHvruMRbEdFXUgvgSWB/4JU62vwC2AXYLiIWStoTeFBS74j4X6rTT9I2ETGlSPu7I+LEOq6BpLWBh4H/i4i/pbJyYMO62iaHAM8Dg4HrC84VjU9SGXANsF9ETE1l+wHdgLdTtdPr8VzNzKwJmj17Np07ZzsQdOrUidmzZy9TZ8SIEey9994AlJWVcfbZZzNv3jxat27NI488wo477tigMZuZmX2d1SspJOkHZL94twI2l9QXuDAi9luNsVkJi4g5ko4HXpJ0fkQEcCDwN2A2cDhwCdnG50dL2iMdnxgRX0jqDPwnr79pKxhKOfAacDdZciOXFOoMPJ7X/8QV7D/XfnGa9bIldSeFzgR2j4iFqe3jqe2RwIhU50rg7FS2oo4AnsslhNK1KqE6OVSXwcCpwF8kdYmId/LO1RTfmcAluYRQuuaDyxt4GjvHA3TosCHn9Vm8vF2YNaiNWmdLc8yasvqO08rKyurP77//PgsWLKguW7x48VLnlyxZstTxq6++yjXXXMPVV19dXT5o0CB23nlnWrduTbdu3Zg1a9ZSbczyzZ8/3+PD1ggeq9ZU1HdPofOBbwKVABExXlL31RSTGQBpJlBzoCNZImgw2Qyd2WRvxLskIr6U9HOyWTYPRsTTqfnNwONpOdMYYGRETF+BMAYDdwKjgUsktYyIL4DhwN2STgT+AdwSEe+t6L1KagMMAM5LRVtIGp9XpRNwhaR1gbYR8e+CLsYBvfOO7wFOUPbGwEKHSdo173jniFhUpF4Z8HItYX+7IMbNgIfS/WwKdI6IFyXdAxxGlgiqK77eZAno2lwu6Zz0+bWIWCbxFRE3kCUM2az7lnHlpPr+UWfWOE7tsxiPU2vq6jtOq44s/+pzVRVt27alvDwr22STTejZsyedO3dm1qxZbLzxxtXnJk6cyLXXXssTTzzBVlttVd1HeXk5l19+OQBnnXUWXbp0qW5jVqiystLjw9YIHqvWVNR3T6EvIuLjgrIvV3UwZjWRtBHQA3gmIt4g2/y8DLIkJTAZuC5XP5V1By4H1iebcbT1cl6zFfB94IGI+AR4Afhe6v/vqf8bgV7Aq5Lqu6wqXy758yzwcEQ8msrfioi+uS+WXX5VlyVk9/7rIufuzu+7hoRQfYwtiDF/Rs9hZIkfgLvIkmv1jQ8ASRukfYPeyO2nlJyed92VmQllZmYNbL/99mPkyJEAjBw5kkGDBgHw9ttvc+CBB3L77bcvlRACmDNnTnWdUaNGccQRRzRs0GZmZl9j9f1nydckHQE0l9QD+CXgDV5ttUqz0ZYAc4ATgW8AMyRBttfQYLIlSJAlKZdKVEbEfGAUMErSl2QJnqnU3/eA9sCkdM02wCLSbJiI+IBs36O/pE2XdyObwbQ83srto1QfEfGJpAW5PZXyTvUDniqofjtZ0mUyK+Y1sn2UVsRgoJOkXNJmY0k9CmZrFYvvNWAHYEJEzAP6poRQjZuE16V1y+ZMS2/CMWuqKisrl5pdYdYULe84HTx4MJWVlcydO5cuXbpwwQUXMHToUA499FBGjBhB165dueee7N8PLrzwQubNm8cJJ5wAQIsWLRg3bhwABx10EPPmzaNly5YMHz6c9u3br+pbMzMzK1n1TQqdRPbL92dkvwT/HbhodQVllmbdXA9cGxEhaTCwV0Q8l85vTrZs6+wa2n8LmBIRH6YZP9uQlj8uh8HAjyPiztRnW7KkVBtgJ+D5tNHzOsAWfLUR8up2OXC1pEMiYpGk7wK7Aj/Nr5T2VvoDMJRsed3y+gvwa0n7RMTDAJJ2Az6orZGkrYB2EbFJXtkFfLX8r7b4LgPul/R83r5CbVYgdjMza2R33nln0fIxY8YsU3bTTTdx0003Fa0/duzYVRqXmZmZfaXOpFDa0+XhiNiDGn4BN1tFWqelVC2BxWQzSX4vqRvQlexNVkD2BjxJH0vqHxEvFOlrC+CPyqb4NCN7i1Zts3jaSMrfCPk6YC+g+nXqEbFA0jPAD8j2z7lW0uLU/00R8dLy3vAKuoZs1tQkSUuA94FBNSwDGwGcU1BWuKfQCRGxzMy/lHDaF7hK0lVkb2+bCJwMdKglvsHA/QVl95Ft1n1hQflS8UXEJEknA7el/ZPmkiXbfpPXJn9PIYBvRsTntcRjZmZmZmZmRSh7qVMdlaQxwIFF9hUyM2vSevbsGdOmrejL58wahjebtDWBx6mtCTxObU3hsWoNSdLLEbFjsXP1XT42n2xWwhPAglxhRPxyFcRnZmZmZmZmZmYNrL5JoVHpy2yNJWkDstfTFxqQNjVeXdftQ7YULt9nEdF/dV1zeTT1+MzMzMzMzGz1qFdSKCJGru5AzFa33NusGuG6kxrjuvXV1OMzMzMzMzOz1aNeSSFJM4BlNh+KiO6rPCIzMzMzMzMzM1vt6rt8LH9DorWBQ4D1V304ZmZmZmZmZmbWEJrVp1JEzMv7ejcirgL2Wb2hmZmZmZmZmZnZ6lLf5WM75B02I5s5VN9ZRmZmZmZmZmZm1sTUN7FzZd7nxcAM4NBVH46ZmZmZmZmZmTWE+iaFjouIf+cXSNp8NcRjZmZmZmZmZmYNoF57CgH31rPMzMzMzMzMzMzWALXOFJLUC+gNrCfpwLxT65K9hczMzMzMzMzMzNZAdS0f6wnsC7QHfpBX/inwk9UUk5mZmZmZmZmZrWa1JoUiYjQwWtLOEfFcA8VkZmZmZmZmZmarWX03mn5V0i/IlpJVLxuLiGNXS1RmZmZmZmZmZrZa1Xej6duBTsD3gKeALmRLyMzMzMzMzMzMbA1U36TQlhFxLrAgIkYC+wD9V19YZmZmZramOvbYY+nYsSNlZWXVZR988AEDBw6kR48eDBw4kA8//BCAO+64g2233ZY+ffqwyy67MGHChOo2f/jDH+jduzdlZWUMHjyY//3vfw1+L2ZmZl9n9U0KfZG+fySpDFgP6Lh6QjIzMzOzNdmQIUN47LHHliqrqKhgwIABTJ8+nQEDBlBRUQHA5ptvzlNPPcWkSZM499xzOf744wF49913ufrqqxk3bhyTJ09myZIl3HXXXQ1+L2ZmZl9n9d1T6AZJ3wDOBR4E2gHnrbaozFaSpP2B+4GtI+J1Sd2AGcDFEXFOqtMBmAX8KX0/JDXvA0xKn2+OiKtruMZRwBlAAIuBOyLiCkm3ArsDHwMC/i8ixqQ2lUBnYFHq5s2IOFjS+WRv9Psv0DZd/5yImJLX7jRgOLAWsD7QGng39bN/RFQVifFY4JQUYzPg7IgYnesvIsalet2AhyKiTFI58E/gJxFxUzrfF3gVOD0irij2PFK9FulZjoiIoTXVS3XLgc8j4l/p+GfAwoi4rbZ2y2vRF0voNvThVdml2Sp3ap/FDPE4tSauvuO0qmIfdtttN6qqqpYqHz16NJWVlQAcffTRlJeXc+mll7LLLrtU19lpp5145513qo8XL17MokWLaNmyJQsXLmTjjTdeJfdiZmZmmXolhXK/GJLtJ9R99YVjtsoMBp5J33+TymaQLX08Jx0fArwGEBEXAxcDSJofEX1r61zS3sCvgD0j4j1JawFH5VU5PSLulbQHcAPQI+/ckblkTIE/5BIukg4DnpTUJyL+m6sQEf3T+SHAjhFxYi0xdgHOBnaIiI8ltQM2rO2+8kwGDgVy/+0PBibUXL3aQOAN4BBJv46IqKVuOTAf+BdARFxfz9jMzGwNNHv2bDp37gxAp06dmD179jJ1RowYwd577w3AJptswmmnncZmm21G69at2XPPPdlzzz0bNGYzM7Ovu3olhSRtBFwCbBwRe0vaBtg5Ikas1ujMVkBKfuwK7AH8ja+SQguBqZJ2TEmZw4B7gBX5Z8dfk820eQ8gIj4DbixS7zlgk+XtPCLulrQPcAQwbAXig2yJ56dkiRciYn7ucz38B1g3/bc/B9gLeKQe7QaTxftzYGdSwkfSXmR/hjQH5gLHAT8Dlkj6IXASMCDF9xBwW0R8M7XtBvwtIvpI6gf8nmy24lxgSETMKgxC0vHA8QAdOmzIeX0W1/O2zRrHRq2zWRhmTVl9x2luNtD777/PggULqo8XL15c/RlgyZIlSx2/+uqrXHPNNVx99dVUVlby6aefMnLkSP785z/Trl07zj//fM4++2wGDhy4Cu/Kvm7mz5+/1Lgya6o8Vq2pqO/ysVuBW8hmHUA2E+BuwEkha4oGAY9FxBuS5qVEwrx07i7gcEmzgSXAe6xYUqgMeLke9fYCHigou0NSbvnYExFxeg1tXwF6rUBsOROA2cAMSWOAURHxt+Vofy/ZbKpXUyyf1VZZ0trAd4GfAu3JEkT/krQhWcJst4iYIWn9iPhA0vXA/LzZUQMA0nK/VpI2j4gZZMm7uyW1BK4BBkXEf9NsqouBYwtjiYgbyGZosVn3LePKSfX9o86scZzaZzEep9bU1XecVh1Znn2vqqJt27aUl2fHm2yyCT179qRz587MmjWLjTfeuPrcxIkTufbaa3niiSfYaqutAPjrX//K9ttvz/777w/Ae++9x/PPP1/dxqyYyspKjxFbI3isWlNR342mO0TEPcCXABGxmOwXarOmaDBZ8of0fXDeucfIljgdTpbYXF0ul/QG8Bfg0oJzR0ZE3/RVU0IIsv2IVlhELCFLSh1Mlsj9Q9q7CLI9hpZpUnB8D1lSaDBwZz0uuS/wz4hYBNwH7C+pObAT8HRK8BARH9Sjr3vIkkGk73cDPcmScU9IGk+2DLBLPfoyM7MmYL/99mPkyJEAjBw5kkGDBgHw9ttvc+CBB3L77bdXJ4QANttsM55//nkWLlxIRDBmzBi23nrrRondzMzs66q+/yy5QNIGpF8aJe1EtomuWZMiaX3gO0AfSUG2XCnINmgmIj6X9DJwKrANsN8KXuo1oB/wZA3nc3sKnQTcnOour+2BYnsP1Vva0+dF4EVJT5DN+DufbObUN/Kqrk+2HCu/7fuSviBLop0M7ELtBgO7SqpKxxuQ/SxWxN3AXyWNSrcxXVIf4LWI2Hl5OmrdsjnTKvZZwTDMGkZlZWX17Aqzpmp5xungwYOprKxk7ty5dOnShQsuuIChQ4dy6KGHMmLECLp27co999wDwIUXXsi8efM44YQTAGjRogXjxo2jf//+HHzwweywww60aNGC7bffvvrNZGZmZrZq1Dcp9H9kbx3bQtKzZJvVHrzaojJbcQcDt0fET3MFkp4CNs2rcyXwVFrCtKLX+R3ZbKB9UvKkFXBU3qbsOdcCx0r6XkT8vb6dSzoI2JMsebVCJG0MdIqIV1JRX7K9ggAqgR9K+kdKHB1N9saxQucBHSNiSW3PStK6wLeBTdP+Skg6hixRdCZwXW45WG75GNl+R+sW6y8i3pK0hOyNh7kZXdOADSXtHBHPpeVkW0XEa/V5HmZm1nDuvLP4BNMxY8YsU3bTTTdx002F//vMXHDBBVxwwQWrNDYzMzP7Sq1JIUmbRcTbEfGKpN3Jlm8ImBYRXzRIhGbLZzDLLte6j2xjaABSEmGlEgkR8UjahPkfyrIlQTYjqLBeSLqI7NX1uaRQ/p5CcyPiu+nzKWnT5bZkb//6Tv6bx1ZAS+CKlBz6H9nr7n+Wzt1Atl/RhDSjahx5zygv/n/V81oHAE/mEkLJaOAysk2njwdGSWpGtnH1QLJNwO+VNIhso+lCdwOXA5unWD6XdDBwtaT1yP78uoqV/FmamZmZmZmVKtX2xmhJr0TEDunzfRFxUINFZma2CvTs2TOmTZvW2GGY1cqbTdqawOPU1gQep7am8Fi1hiTp5YjYsdi5ujaazl8v0n3VhWRmZmZmZmZmZo2prj2FoobPZiVB0tlkb+DK99eIuLgx4qmJpBeAtQqKfxQRk1bDtYYD3yooHhYRt6zqa5mZmZmZmdnqU1dSaDtJn5DNGGqdPpOOIyKKbhJr9nWRkj9NKgFUTET0b8Br/aKhrmVmZmZmZmarT61JoYho3lCBmJmZmZmZmZlZw6lrTyEzMzMzMzMzM/saclLIzMzMzMzMzKwEOSlkZmZmZmZmZlaCnBQyMzMzMzMzMytBTgqZmZmZmZmZmZUgJ4XMzMzMzMzMzEqQk0JmZmZmZmZmZiXISSEzMzMzMzMzsxLkpJCZmZmZmZmZWQlyUsjMzMzMzMzMrAQ5KWRmZmZmZmZmVoKcFDIzMzOzlXLsscfSsWNHysrKqss++OADBg4cSI8ePRg4cCAffvghAK+//jo777wza621FldccUV1/WnTptG3b9/qr3XXXZerrrqqoW/FzMyspDgpZGZmZmYrZciQITz22GNLlVVUVDBgwACmT5/OgAEDqKioAGD99dfn6quv5rTTTluqfs+ePRk/fjzjx4/n5Zdfpk2bNhxwwAENdg9mZmalqEVjB2BfL5KWAJPIxtYM4EcR8ZGkbsBUYFpe9d9HxG2S2gGXA3sCHwMBXB8RN6Z2D0VEWep/V+D3wLp5fdyQzp0PnAF0i4g5qWx+RLSrZ7xTgaMjYqGkLsBwYBuy5OlDwOkR8bmkcmB0ur+1gLsi4gJJQ4AdI+LEvP4rgdMiYpykqnR+bpE4fgVUABulWMakU52AJcB/0/E3gQ9y9ySpN3ANsEmK8zbgooiIFM/NQN+ImJjqTwb2jYiqGp5HFfAp2c/gQ+CoiPhPwbPKuSsiKvLvsUh/+wP3A1tHxOuSXkjPbH2gNfBuqro/UAnsCPwVqIiIvxc8n57ApdQwjordD8CiL5bQbejDNZ02axJO7bOYIR6n1sTVNE6rKvZht912o6qqaqny0aNHU1lZCcDRRx9NeXk5l156KR07dqRjx448/HDNY37MmDFsscUWdO3adVXegpmZmRXwTCFb1RZFRN+UxPkA+EXeubfSudxX7hf5m8gSED0iYgdgL7KkwVIkdQL+AvwsInoBuwI/lbRPXrW5wKkrGO/nwM8kCRgFPBARPYCtgHbAxXntxkZEX7Ikxg8l7bAc1yxmMPAScGBEzMs9I+B64A95z+zzXANJrYEHyRIoPYHtgF2AE/L6fQc4ezlj2SMitiVL0pyTV76o4OdXUc/7eiZ9JyL6p/s6D7g7r6+qvDZ3AocX9HN4Koeax5GZmTUhs2fPpnPnzgB06tSJ2bNn17vtXXfdxeDBg1dXaGZmZpY4KWSr03NkM1hqJGkLstkv50TElwAR8d+IuLRI9V8At0bEK6neXLKZQUPz6twMHCZpmaRSPYwFtgS+A/wvIm5J11kCnAIcK6lNfoOIWAC8nNqtkPQM2pElYJbnb8BHAM9GxOMploXAiSz9PB4CekvquQKh1fnzq02aAbYrcBzLJnlqcy+wj6RWqZ9uwMZkPx8zM1sDSSL7N5e6ff755zz44IMccsghqzkqMzMz8/IxWy0kNQcGACPyireQND7v+CTgG8CEXEKoDr2BkQVl41J5znyyxNDJwG+WI94WwN7AY6m/l/PPR8Qnkt6mIPkjaQNgJ+C3wP+r7/UKHA7cRZb06Clpo4iozz+nFovzLUntJOWW130JXAacBRy9nHHtBTyQd9y64Of3u4i4u5b2g4DHIuINSfMk9YuIl2upD0BEfCDpRbKfx2iy53NPWhIHRcZRRCyVMJJ0PHA8QIcOG3Jen8V1XdasUW3UOluaY9aU1TROc0vE3n//fRYsWFB9vO6663LfffexwQYbMG/ePNZZZ53qcwBVVVW0bt16qTKAZ555hs0335ypU6cyderU1XQ39nU1f/78ZcaUWVPksWpNhZNCtqrlEgebkO398kTeubfS0qFqkvYrOD4bOAToGBEbr2AMVwPjJV1RZ82lEx1jyZJYP6tHu29LepUs6VIREa9J2rGGulFHX4OBAyLiS0n3kd3/tfWIob7+ApwtafN61v9nmmk1Hzg3r3xR4c+vDoOBYenzXem4zqRQkltClksKHZd3bplxVCjtM3UDwGbdt4wrJ/mPOmvaTu2zGI9Ta+pqGqdVR5Zn36uqaNu2LeXl2fFhhx3G9OnTOeigg6ioqODwww+vPgdZMqldu3ZLlQFcf/31nHDCCcuUm9VHZWWlx46tETxWranw30BtVVsUEX3TMqu/ky35urqW+lOA7SQ1i4gvI+Ji4GJJ82uo248sUZDTD3gtv1La2PovLL2fUa3x5hdImgIcXFC2LrAZ8CbZcrexEbFvQV/zyGY+5VufbJ+joiT1AXoAT6RZMK3INrCuT1JoCrBbQX/dgflpZhMAEbFY0pXAmfXoE2AP4CPgDuAC4P/q2S4/jvXJluH1kRRAcyAknR4RdSXJIPsZ/yHt1dSmPjOMatK6ZXOmVexTd0WzRlRZWVn9i7VZU1XbOB08eDCVlZXMnTuXLl26cMEFFzB06FAOPfRQRowYQdeuXbnnnnuAbEbRjjvuyCeffEKzZs246qqrmDJlCuuuuy4LFizgiSee4E9/+lMD3pmZmVnpclLIVov0Bq9fAg9Iuq6Wem9KGgdcJOnciFgiaW2g2MYDw4EXJI2KiPFp6dalwIVF6v6ebOPmFRnjY4AKSUelt6M1B64k289oYS17IrwEXCupU0S8n2YOrQXMrOVag4HzI+J3uQJJMyR1zb31qxZ3AGdJ+m5E/CNtPH012XKxQreS7b+0Th19AtWJpF8BkyRdFBEf1KddnoOB2yPip7kCSU8B3waersf150v6J9lSwDvrqm9mZo3rzjuL/1E9ZsyYZco6derEO++8U7R+27ZtmTdv3iqNzczMzGrmjaZttYmIV4GJfLV58haSxud9/TKV/xjYAMgliJ4gS2AU9jcL+CFwo6TXgX8BN0fE34rUnUv2KvS1ViDuAA4ADpE0HXgD+B/Zvjy1tZtNtpfRI2lJ2lXA4IL9kiZKeid9/Z5sadT9BV3dTz02Zo6IRWT79pwjaRrZ6+Jfosgso/TWsquBjnX1m9dmFllCJjfjqnXBzy//7WMP593XX8l+5oX3dR/Lt5H2nWRvVCv8TaOmcWRmZmZmZmbLQfVbyWFmtmbq2bNnTJs2rbHDMKuV9xWwNYHHqa0JPE5tTeGxag1J0ssRUXQPXM8UMjMzMzMzMzMrQd5TyL720t5Dy25qAAMioiQ3LpD0AssurftRRExqjHjMzMzMzMys4TkpZF97KfHTt7HjaEoion9jx2BmZmZmZmaNy8vHzMzMzMzMzMxKkJNCZmZmZmZmZmYlyEkhMzMzMzMzM7MS5KSQmZmZmZmZmVkJclLIzMzMzMzMzKwEOSlkZmZmZmZmZlaCnBQyMzMzMzMzMytBTgqZmZmZmZmZmZUgJ4XMzMzMzMzMzEqQk0JmZmZmZmZmZiXISSEzMzMzMzMzsxLkpJCZmZmZmZmZWQlyUsjMzMzMzMzMrAQ5KWRmZmZmK+XYY4+lY8eOlJWVVZd98MEHDBw4kB49ejBw4EA+/PBDAF5//XV23nln1lprLa644oql+vnoo484+OCD6dWrF1tvvTXPPfdcg96HmZlZqWnR2AGYma1Oi75YQrehDzd2GGa1OrXPYoZ4nFoTV9M4rarYhyFDhnDiiSdy1FFHVZdXVFQwYMAAhg4dSkVFBRUVFVx66aWsv/76XH311TzwwAPL9HXyySez1157ce+99/L555+zcOHC1XlLZmZmJc8zhcwagKQlksZLek3SBEmnSmpWUOcBSc+nzx0lVUnqlHd+uKRfS2oj6Q5JkyRNlvSMpHa1XHt++t5N0iJJr0qaKulFSUPqiHuIpP+m2KdI+kkqP1/SaQV1qyR1KLjfCZJekbRLXgyTi1znVkkHp8/7phgnpGv+tD7XNDOzxrPbbrux/vrrL1U2evRojj76aACOPvro6iRQx44d+X//7//RsmXLpep//PHHPP300xx33HEAtGrVivbt26/22M3MzEqZZwqZNYxFEdEXsoQP8BdgXeA3qaw90A+YL6l7RPxbUgVwBfBDSTsA3051TgNmR0Sf1LYn8EU943grIrZP7boDoyQpIm6ppc3dEXFiivs1SQ8u5/1+D/gdsHtdjSS1BG4AvhkR70haC+hWj+uZmVkTM3v2bDp37gxAp06dmD17dq31Z8yYwYYbbsgxxxzDhAkT6NevH8OGDaNt27YNEa6ZmVlJclLIrIFFxBxJxwMvSTo/IgI4EPgbMBs4HLiELDlytKQ90vGJEfGFpM7Af/L6m7aCcfxb0v8BVwK1JYXy434L6Lqcl1oX+LCeddch+3NpXrrmZ8By3196vscDdOiwIef1Wby8XZg1qI1aZ0tzzJqymsZpZWUlAO+//z4LFiyoPl68eHH1Z4AlS5YsdVxVVUXr1q2ry6ZNm8bLL7/MkCFDGDJkCNdccw0///nPOfbYY1fTHdnX0fz585caZ2ZNlceqNRVOCpk1gpSQaQ50JEsEDQYuTJ/vAy6JiC8l/Rx4EngwIp5OzW8GHk/LrcYAIyNi+gqG8grQqz4V08yi7sCb9ajeWtJ4YG2gM/Cd+lwjIj5IM5H+I2kM8BBwZ0R8maqcIumHeU02rqGfG8iSamzWfcu4cpL/qLOm7dQ+i/E4taaupnFadWR59r2qirZt21Jenh1vsskm9OzZk86dOzNr1iw23njj6nOQJZPatWtXXdarVy9+97vfccIJJwDQvHlzKioqlmpjVpfKykqPGVsjeKxaU+G/gZo1MkkbAT2AZyIiJH0hqSwiJkfE+LQHz3W5+qmsO7An8F2yGUc7R8TUFbl8PeocJmlX4DPgpylxEzXUzZXnLx/bGbhNUlkNbZbuIOLHkvqQ3dtpwEBgSDr9h4ioflWNpKq6+mvdsjnTKvapz6XNGk1lZWX1L9ZmTdXyjtP99tuPkSNHMnToUEaOHMmgQYNqrd+pUyc23XRTpk2bRs+ePRkzZgzbbLPNSkZtZmZmtXFSyKwRpKTOEmAOcCLwDWCGJMiWWw0Gzk7Vv0xf1SJiPjCKbE+gL4HvAyuSFNq+Hu3ujogTC8rmkc0AyrcO8FFh44h4Lm0GvWF9g4qIScAkSbcDM/gqKWRmZk3Q4MGDqaysZO7cuXTp0oULLriAoUOHcuihhzJixAi6du3KPffcA2TLzHbccUc++eQTmjVrxlVXXcWUKVNYd911ueaaazjyyCP5/PPP6d69O7fcUufqZjMzM1sJTgqZNTBJGwLXA9emmUGDgb0i4rl0fnPgH3yVFCps/y1gSkR8KKkVsA1QuQJxdCPbyPqaFbiNp4E7JFVExKeSDgQmRMSSItfpBTQnSyS1qSOmdsCOEVGZivqSt3+SmZk1TXfeeWfR8jFjxixT1qlTJ955552i9fv27cu4ceNWaWxmZmZWMyeFzBpGbo+dlsBi4Hbg9ykx0xV4PlcxImZI+lhS/4h4oUhfWwB/VDatqBnwMNk+RPWxhaRXyfb6+RS4OiJuXd6biYiJkq4FnklLyeYAP86rkrtfyJaoHR0RS9JMqJ6S8n8bOCXvs4AzJP0JWAQswLOEzMzMzMzMVgsnhcwaQEQ0r+FUFbBJkfo75H0uLzh3G3Dbcly7XfpeBbSub7vU5lbg1hrO/Qn4Uw3nit5viqFlkVN/zfv8/Rranl+krFuxumZmZmZmZla3Zo0dgJmZmZmZmZmZNTzPFDL7GpC0Adnr6QsNiIh59Wh/DHByQfGzEfGLVRGfmZmZmZmZNT1OCpl9DaTET9+VaH8L4Fe8mJmZmZmZlRAvHzMzMzMzMzMzK0FOCpmZmZmZmZmZlSAnhczMzMzMzMzMSpCTQmZmZmZmZmZmJchJITMzMzMzMzOzEuSkkJmZmZmZmZlZCXJSyMzMzMzMzMysBDkpZGZmZmZmZmZWgpwUMjMzMzMzMzMrQU4KmZmZmZmZmZmVICeFzMzMzMzMzMxKkJNCZmZmZmZmZmYlyEkhMzMzM6u3Y489lo4dO1JWVlZd9sEHHzBw4EB69OjBwIED+fDDDwGICH75y1+y5ZZbsu222/LKK69Ut9lrr71o3749++67b4Pfg5mZmWWcFDIzMzOzehsyZAiPPfbYUmUVFRUMGDCA6dOnM2DAACoqKgB49NFHmT59OtOnT+eGG27g5z//eXWb008/ndtvv71BYzczM7OltWjsAKy0SNofuB/YOiJel9QNmApMA1oBTwMnAJsVK4+IL4v02Qy4CvgOEMD/gEMjYoakdsCVwHeBj4BPgTMj4gVJXYDhwDZkCdKHgNMj4nNJ5cBoYAawNvBQRJyWrjcEuBx4Ny+MIyJiiqTHgJ2AZyKixn/6lHQ/sDnQDtgwXYd07+OAy4B90/1MAX4REe/U0t8SYBIgYAlwYkT8Kz3fhyKirNg9ASOB3N/INwM+Tl9zgR/n2uZd53xgfkRcUUMctwK7pz4E/F9EjMk7/yugAtiI7M+f3LlOKe7/puNvAh9ERLvUrjdwDbAJ2c/qNuCiiIianknOoi+W0G3ow3VVM2tUp/ZZzBCPU2viTu2zmHJgt912o6qqaqlzo0ePprKyEoCjjz6a8vJyLr30UkaPHs1RRx2FJHbaaSc++ugjZs2aRefOnRkwYEB1GzMzM2scnilkDW0w8Ez6nvNWRPQFtiVL0OxfR3mhw4CNgW0jog9wAFkCCOAm4AOgR0T0A44BOkgSMAp4ICJ6AFuRJWguzut3bLr+9sC+kr6Vd+7uiOib9zUllV8O/KiuhxARB6S+f5y7Tvr6F3AJsA7QM8X2ADAqxVyTRan9dsCvgd/VUG+pewLWzV0beJAsKdY3Ir5b1z3U4vTU36+A6wvODQZeAg6MiHl5174e+EPec/g810BS6xRbRUT0BLYDdiFLoJmZWRMwe/ZsOnfuDECnTp2YPXs2AO+++y6bbrppdb0uXbrw7rvvFu3DzMzMGp5nClmDSbN2dgX2AP4G/Cb/fEQslvQvYEvglRrKi+kMzMrNIsrNqJG0BdAfODLv3AxghqQBwP8i4pZUvkTSKelcYVyLJI0nm6VSq4gYk2bkrBBJbcgSV5tHxJLU5y2SjiWbCTWmtvbJusCHdcRZ73taCc/l959+Hu3IkjlnA7fUs58jgGcj4nGAiFgo6USgkmym1zIkHQ8cD9Chw4ac12fxCt6CWcPYqHU2C8OsKduoNdUze95//30WLFhQfbx48eKlZv0sWbKEyspK5s2bx6uvvsrixdn4/vDDD3n55ZeZP38+AOPHj2fevHmeMWSrzPz58z2ebI3gsWpNhZNC1pAGAY9FxBuS5knqB8zLnUwJkQHAefmNairPcw/wjKRvkyVN/hwRrwK9gfG55EqB3sDL+QUR8YmktylIPkn6BtCDbAlbzmGSds073jkiFtUQ3/LYEng7Ij4pKB+XYq4pKdQ6JXnWJkuSfae2i9RwT8VskfrN6QQUXTpWxF5ks5xyDgfuAsYCPSVtFBGz69FPsZ/VW5LaSVq3yLMiIm4AbgDYrPuWceUk/1FnTdupfRbjcWpN3al9FnNoeTkAVVVVtG3blvJ0vMkmm9CzZ086d+7MrFmz2HjjjSkvL2fbbbelQ4cO1fUWLFjAfvvtVz2rCOAf//hH9XmzlVVZWenxZGsEj1VrKrx8zBrSYLKkAOl7bglZLvHwLPBwRDxaR/lS0sygnmTLpr4ExqSZQCvr25ImkO0d9PeIeD/vXOHysVWREFoZueVjvciSMbfVsNystnsq5q38+2TZ5WDFXC7pDeAvwKV55YOBu9KsrfuAQ+rRl5mZrQH2228/Ro4cCcDIkSMZNGhQdfltt91GRPD888+z3nrrLZUQMjMzs8blf5a0BiFpfbLZK30kBdCcbBPl4Xy1d1ChmsqXERGfAY8Cj0qaTbb/0FXAdpKaF5ktNAU4uCDGdck2W36TbKPjsRGxr6TNgecl3RMR4+sTz0p4C9hM0joR8WleeT+yjaHrFBHPSepAtoF1oYa4p9Mj4l5JJwE3A/0k9SGbmfREylW1Itvw+tp69DcF2C2/QFJ3sg2vl5klVKh1y+ZMq9hnOW/BrGFVVlZSdWR5Y4dhVqvcMofBgwdTWVnJ3Llz6dKlCxdccAFDhw7l0EMPZcSIEXTt2pV77rkHgO9///s88sgjbLnllrRp04Zbbvlq5fC3v/1tXn/9debPn0+XLl0YMWIE3/ve9xrj1szMzEqWk0LWUA4Gbo+In+YKJD0FbFpzk/qRtAPwfkS8l95Eti0wMS0xGgdcIOnciIj0Nq7ewCNAhaSjIuI2Sc3J3lJ2a9qzprr/9BazCuBMlt4ge5WLiAWSRgK/l/SztNfRUUAb4Mn69CGpF1nSbV5qV+w6DXFP1wLHSvoe2RvJzo+I6g2wJc2Q1DUi/lNHP3cAZ0n6bkT8I208fTXZG9rMzKyB3XnnnUXLx4xZdoWzJIYPL7r9G2PHjl2lcZmZmdny8/IxayiDyV5Fn+8+siVfK6sj8DdJk4GJwGK+moHyY7LXn7+Zzt8KzEmvMj8AOETSdOANslfZn1XDNa4HdktJJcj2FBqf97ULgKSxwF+BAZLeSQmR5fXrFMsbKbZDgAPqeP1661wswN3A0TXspVTbPa1SKd6LgDPI9hMq/Pnfn8rr6mcR2X5U50iaBkwie4NZfWYZmZmZmZmZWQ1U+++ZZmZrtp49e8a0adMaOwyzWnmzSVsTeJzamsDj1NYUHqvWkCS9HBE7FjvnmUJmZmZmZmZmZiXIewrZGiNtVnx7QfFnEdG/MeKpL0n3A5sXFJ8ZEX9fzn42oPgr6QdExLwVjW9FSBoOfKugeFhE3FKsvpmZmZmZmTU9TgrZGiMiJgF9GzuO5RURB6yifubRRO4/In7R2DGYmZmZmZnZyvHyMTMzMzMzMzOzEuSkkJmZmZmZmZlZCXJSyMzMzMzMzMysBDkpZGZmZmZmZmZWgpwUMjMzMzMzMzMrQU4KmZmZmZmZmZmVICeFzMzMzMzMzMxKkJNCZmZmZmZmZmYlyEkhMzMzMzMzM7MS5KSQmZmZmZmZmVkJclLIzMzMzMzMzKwEOSlkZmZmZmZmZlaCnBQyMzMzs1oNGzaMY445ht69e3PVVVcBMGHCBHbeeWf69OnDD37wAz755BMAnnjiCfr160efPn3o168fTz75ZCNGbmZmZrVxUsjMzMzMajR58mRuvPFG/vjHPzJhwgQeeugh3nzzTX784x9TUVHBpEmTOOCAA7j88ssB6NChA3/729+YNGkSI0eO5Ec/+lEj34GZmZnVpEVjB2Bmy0fS/sD9wNYR8bqkbsAM4OKIOCfV6QDMAv6Uvh+SmvcBJqXPN0fE1bVcZzzwekQcnld2KzAQ6B4Rn6XrjIuIbnlx/DIirkn1r03nb5VUCZwWEePSuW7AQxFRJqkcOA24Dzg5XW4bYBqwBJgObAdsFxGLUvuHgT9HxJ21Pa9FXyyh29CHa6ti1uhO7bOYIR6n1kRd3m8h/fv3Z+2116ZFixbsvvvujBo1ijfeeIPddtsNgIEDB/K9732P3/72t2y//fbVbXv37s2iRYv47LPPWGuttRrrFszMzKwGnilktuYZDDyTvufMAPbJOz4EeA0gIi6OiL4R0RdYlPtcR0Joa6A58G1JbQtOLwGOraHpHOBkSa2W54ZyIuKWvFjfA/ZIx4cAo4CzU3z7Ay3rSgiZmdnKKysrY+zYsXz88ccsXLiQRx55hJkzZ9K7d29Gjx4NwF//+ldmzpy5TNv77ruPHXbYwQkhMzOzJsozhczWIJLaAbsCewB/A36TTi0EpkraMc3EOQy4B9h4BS81GLgd2BoYBPwl79xVwCmSbizS7r/As8DRQLHzK+NC4FVJ9wIVwA9qqijpeOB4gA4dNuS8PotXcShmq9ZGrbPZQmZN0ezZsxk0aBCnnnoqbdu2pVu3bsyaNYuf/exnXHzxxZxxxhl861vfolmzZlRWVla3mzFjBueccw6XXXbZUuVmq9P8+fM93myN4LFqTYWTQmZrlkHAYxHxhqR5kvoB89K5u4DDJc0mm83zHiueFDqMbJlYL+Aklk4KvU02U+lHZImpQpcCj0q6eQWvXVRELJR0GvA08PuImF5L3RuAGwA2675lXDnJf9RZ03Zqn8V4nFpTVXVkOeXl5eyzzz6Ul5dz1lln0aVLF4466iiOOuooAN544w1ee+01ysvLAXjnnXc4/vjjueeee/jWt77ViNFbqamsrKweh2ZNmceqNRVePma2ZhlMlvwhfc9fQvYYWSLncODuFb2ApB2BuRHxNjAG2F7S+gXVfgecTpE/QyLi38ALwBGFp4pcrlhZjSLib8BHwHXL087MzFbOnDlzAHj77bcZNWoURxxxRHXZl19+yUUXXcTPfvYzAD766CP22WcfKioqnBAyMzNr4vzPkmZriJSY+Q7QR1KQ7fkTwHCAiPhc0svAqWSbNO+3gpcaDPSSVJWO1wUOIm85WERMTxtRH1pDH5cA9wJP5ZXNA76Rd7w+MHcF4vsyfdVL65bNmVaxT90VzRpRZWUlVUeWN3YYZjU66KCDmDlzJuuttx7Dhw+nffv2DBs2jOHDhwNw4IEHcswxxwBw7bXX8uabb3LhhRdy4YUXAvD444/TsWPHRovfzMzMinNSyGzNcTBwe0T8NFcg6Slg07w6VwJPRcQHkpb7ApKakSV6+kTEe6lsD+Bclt0j6GKg6OuS0lvRppDt+/NSKq4EfijpHxERZPsO/XO5gzQzswY3duzYZZY6nHzyyZx88snL1D3nnHM455xzGjA6MzMzW1FePma25hhM9ir6fPcBv84dRMRrETFyJa7xbeDdXEIoeRrYRlLn/IoR8RrwSi19XQx0yTu+AfgUmCBpAtAOuGIlYjUzMzMzM7OV4JlCZmuIiNijSNnVQNFXy0fErcCtBWXt6rjGU8BOBWVLgE7pcEjBuQPzPlcBZXnHE8hLPEfE58CJNVy3kmwmUX5ZtxrqFi03MzMzMzOz5eOZQmZmZmZmZmZmJcgzhcxKlKSzgUMKiv8aERc3RjxmZmZmZmbWsJwUMitRKfnjBJCZmZmZmVmJ8vIxMzMzMzMzM7MS5KSQmZmZmZmZmVkJclLIzMzMzMzMzKwEOSlkZmZmZmZmZlaCnBQyMzMzMzMzMytBTgqZmZmZmZmZmZUgJ4XMzMzMzMzMzEqQk0JmZmZmZmZmZiXISSEzMzMzMzMzsxLkpJCZmZmZmZmZWQlyUsjMzMzMzMzMrAQ5KWRmZmZmZmZmVoKcFDIzMzMzMzMzK0FOCpmZmZkZw4YNo6ysjN69e3PVVVdVl19zzTX06tWLIUOGcMYZZwDw+eefc8wxx9CnTx+22247KisrGydoMzMzWyktVmfnkvYH7ge2jojXJXUDpgLTgFbA08AJwGbFyiPiyyJ95vp4HVgb+BS4LiJuLag3Hng9Ig6X1DvFsV1ELErnHwb+DDwJjAA2BVoCVRHx/RrupxvwUESU1XD+AaBTROyUV9YT+BPQHlgLGAvcB1yaqmwJvAssAiZGxFFF+i0HRgMzUh93RcQFqfy0iNg3r+6tKcZ7JbUCLgP2BQKYAvwiIt5JdQP4fUScmo5PA9pFxPmSzgd+Avw3L5TyiPiohnv/JnAFsBGwEHgZ+CVwKLBjRJyYV7cyxT0uHfcFXgX2jojH8urVGF86/iFwBtAcWAy8lPr9KF2jc3quAG9GxME1xJ5/r22BScA5ETElr85SMUq6GGgREWem812BfwI7ALsCvyVLurYEhkXEn+px7ZxyoG/q7ycRcVNBDKdHxBXpZ7078DHwJdnP9rn8MVBwreOB/0uHn6TPbwAvAjtFxPup3nDgHeA5vhp3OadFxD8kLUnPqSXZs78N+EOx/2aXh6T2wBERcV063hi4uqafXX0s+mIJ3YY+vDJhma12p/ZZzBCPU2skVRX7MHnyZG688UZefPFFWrVqxV577cW+++7LzJkzGT16NBMmTOC5555jm222AeDGG28EYNKkScyZM4e9996bl156iWbN/O+NZmZma5LV/X/uwcAz6XvOWxHRF9gW2AbYv47yYt6KiO0jYmvgcOBXko7JnZS0NVmi4NuS2kbEa8Ao4Ox0fn+gZUTcCVwIPBER20XENsDQFbnR9MtsP2A9Sd3zTl1N9sty3xTvNRHx93TcFxgHHJmOl0kI5Rmb6u8I/FDSDvUI6xJgHaBnRPQAHgBGSVI6/xlwoKQONbTPxZ37+qhYJUkbAX8FzoyInhGxPfBYunZ9FBsntcYnaS/gFLIkTW+yZMy/yJJSOUfmxV5XUiF3rz2Au4EnJW1YS4wXAfunsQYwDDgXWADcAPwgIrYDtgcq63ntwuc8mSyplh/DhIK2p6dxMZQs+ViUpH2BnwK7RkQv4GfAX8j+DKggS+iRxtW3c8ekcZf39Y9Uvigd9wYGAnsDv6njPnOx1JaMbk+WKAYgIt5bmYSQmZnVz9SpU+nfvz9t2rShRYsW7L777owaNYo//vGPDB06lLXWWguAjh07AjBlyhS+853vVJe1b9+ecePGNVr8ZmZmtmJWW1JIUjuyGRPHkSVulhIRi8l+id+yPuU1iYh/k814+GVe8WDgduBxYFAquxA4JM22qAB+kco7k82KyPU3sT7XLeJA4G/AXSx9v4X9T1rB/nPtF5DNwqn1+UhqAxwDnBIRS1LbW8gSLd9J1RaTJTBOWZmYyJ7lyIh4Li/OeyNidl0NU4LqEGAIMFDS2nmna4vvbLJZK++m6y2JiJsjYtqK30Z17HeTjZ0jaooxzTg7BRgu6fvAOhFxB1kirAUwL/X12UrE9B9gbUkbpRj2Ah6toe7T1D4mziRLIM1Ncb0CjCT72d0AbCFpD2A4cGJEfFHfICNiDnA8cGJewnEpkoZIelDSk8AYSe0kjZH0iqRJknL/nVakWMZLulxSN0mTUx9rS7ol1X81xWtmZqtAWVkZY8eOZd68eSxcuJBHHnmEmTNn8sYbbzB27Fj69+/PySefzEsvvQTAdtttx4MPPsjixYuZMWMGL7/8MjNnzmzkuzAzM7PltTqXjw0CHouINyTNk9SP9IsyVCctBgDn5TeqqbwOrwC98o4PI5u90As4CfhLRCxMy4+eJluSND3VHQ7cLelE4B/ALRHx3nJcO2cwWeJpNtnysEtS+R/IZp38iyzRcEtNM27qQ9IGwE5ky5M2JJsNNT6vymbAQ2QJgrcj4pOCLsYBvYEx6Xg4MFHSZUUud0paogXwYUTU9Et4GVmCoSaHSdo17zg/ebELMCMi3kpLvvYhe345NcXXm+znXps7JOWWjz0REafXUT9f/pgqGmNEPCLpOLJ73xUgIj6Q9CDwH0ljyH4Wd9axrKq253wvWULq1RTTZzX08QOy5Vw16U2WTMw3Djg6Ir6U9HOypZQPRsTTeXUKx9dBEfFWYecR8W9JzYGOZP8NFLMDsG16Ri2AAyLikzQT7Pn03IYCZWn2U27JZs4vsktFH0m9gMclbRUR/yu8UFoqdzxAhw4bcl6fxTWEZNY0bNQ6W0Jm1hhy+wENGjSInXfemdatW9OtWzdmzZrFxx9/zKRJk6ioqODVV19lv/324y9/+QtbbLEFTzzxBL169WKjjTaiV69eTJ061XsLWaObP3++x6GtETxWralYnUmhwWRLaiCbPTMYuJY0C4Bsj5vREfFo+sVvmfLluFb17ARJOwJzI+JtSe8CN0taPyI+iIi/SfoIuC5XPyL+npZ77UW2BOZVSWUR8V/qKS2f6gE8ExEh6YvUx+SIuEXS31P/g4CfStouImr65b4m35b0KtneMRUR8VraU2hsLLunUL2lX8pvI5tptajg9B8i4ooizZbX3bHsnkI5g8nGB+n7UeQlheqIL9dfH7KZYesAZ6WZPpAtH1vRuez5M15qi3E40Dp/NlBE/DjF9F3gNLIE5ZBarlXbc76HbDlbL+BOsgRVvsslnUO2J9FxddxTjSJifJqRc13BqaXG10p6IiI+SJ8FXCJpN7IxvQlLL/0rZlfgmhTv65L+A2wFLDO7LyJuIJsBxWbdt4wrJ63W7dPMVtqpfRbjcWqNperIcgDKy8u5/PLLATjrrLPo0qUL8+fP56STTmKPPfZAEm3atKGsrIwNN9yQAQMGVPexyy67cOCBB1bvOWTWWCorKykvL2/sMMzq5LFqTcVq+RuopPXJlij1UbZZcHOyZM9wvto7qFBN5fWxPdnm05D9At9LUlU6Xhc4CLgxHX+ZvqqlX1T/AvxF0kPAbiw9W6UuhwLfAGak1TPrpjjOTv2/B9xMlqCaTDazpnDWRl2W95fzt4DNJK0TEZ/mlfcjm72S7yqyWSi3LGdMOa+lfkcvT6M0s+QgYJCks8kSBRsUiblYfK+RzTz5Z1qS11fStUDrFbyHQtsD4+oR4zLjCaqXCU6SdDvZRs1DViSIiHhf0hdkiaWTWTYpdHoUbChdgylkP6Mn88r6kT3HnKL3Uh8psboEmFNLtQV5n48km+nWLyK+SP+9rl201Upq3bI50yr2WR1dm60ylZWV1b+YmzWWOXPm0LFjR95++21GjRrF888/T7NmzfjnP//JHnvswcyZM/n888/p0KEDCxcuJCJo27YtTzzxBC1atHBCyMzMbA20uvYUOhi4PSK6RkS3iNiU7BfjTVf1hdIsoyuAayQ1I0vQ9EnX7UY2O6dwA+P89t9JS9aQtA6wBfD2coYxGNgr75r9SPsKSdpLUsv0uROwAdnbxlartPfQSOD3KbGBpKOANiydGMglxe5hxWeaXAscLal/rkDSgWkGVW0GkL1xbdP07LqSJeMOqEd8vwOukNQlr2yVJIQkHQTsSTYzp14x5rVtl2Zw5fQl2xtoZZxHton3kpXo4zLg0rT8MPcmsyEsOzNouSnbkPt64NqIiHo2Ww+YkxJCewBdU/mn1LxB+ViyZBKStiJbKrnSe0iZmVnmoIMOYptttuEHP/gBw4cPp3379hx77LH8+9//pqysjN/+9reMHDkSScyZM4cddtiBrbfemksvvZTbb7+9scM3MzOzFbC65qoP5qtXrufcB/x6FfW/RVpKlXsl/dURcauk3YF3C/YEehrYRlLniJhVpK9+wLWSFpMlyW6KiJdquXZPSe/kHQ8j+4X2+VxBRMyQ9HFKkuwJDJOU2/fk9Eiv/m4AvyZLmL0h6UvgdbJ9XIr94n4lcGJBWf5eNwD7R0RVYcOImC3pcLIkTUey2SZPk72BrDaDgfsLyu4Dfk72ivMa40v7+WwIPJqSXh+Rva3r73lt8vcUmhsR360llty9tk39fCci/itpeWKEbCbRGZL+RLbcbQF1zxJa5jnnn4yIf9XRvpg/SboqfZ4ZETtL2gT4V5q99ynwwxr+m8hXuKfQRWlmUutUnnsl/e3A75cjvjuAv0maRLa30esAETFP0rNpRt2jZLMLc64D/pjaLAaGrMAyTDMzq8HYsWOXKWvVqhV//vOfgaWXOnTr1o1p05yXNzMzW9Op/v+wb2a25unZs2f4Fxdr6ryvgK0JPE5tTeBxamsKj1VrSJJejogdi51bba+kNzMzMzMzMzOzpqvJvuok741S+T6LiP7F6n8dri3peyy77G5GRBTdv6ahNfX46pI2ij6koPivEXHx1/naDWlNHyNmZmZmZmalpMkmhXJvlCqla0fE31l6T5wmpanHV5eUgGmUJExjXrshreljxMzMzMzMrJR4+ZiZmZmZmZmZWQlyUsjMzMzMzMzMrAQ5KWRmZmZmZmZmVoKcFDIzMzMzMzMzK0FOCpmZmZmZmZmZlSAnhczMzMzMzMzMSpCTQmZmZmZmZmZmJchJITMzMzMzMzOzEuSkkJmZmZmZmZlZCXJSyMzMzMzMzMysBDkpZGZmZmZmZmZWgpwUMjMzMzMzMzMrQU4KmZmZmZmZmZmVICeFzMzMzErIsGHDKCsro3fv3lx11VUAnH/++WyyySb07duXvn378sgjjwDw4osvVpcdd9xx3H///Y0YuZmZma1qLRo7ADOz1WnRF0voNvThxg7DrFan9lnMEI9TW82qKvZh8uTJ3Hjjjbz44ou0atWKvfbai3333ReAU045hdNOO22pNmVlZYwbN44WLVpw33338dOf/pQf/OAHtGjhv0KamZl9HXimkDUoSfPT926SQtJJeeeulTQk7/g0Sa9LGi/pJUlHpfJWkq6S9Kak6ZJGS+qS1y4k/TnvuIWk/0p6KB0PScfj8762KRJrn7zzH0iakT7/I53vLelJSdNSHOdKUi33XvS6ec/iory6HSR9IenadHy+pHdTm8mS9ssrP63ItfaXNFHSVEmT0vHa6Xn2yat3uqQ/pRgWFcSWe95VqY9JkqZIukjS2rXcZ35fUyTdJqllkZ9HRTo+O++aS/I+/zL//pQ5Jz3rNyT9U1LvmuIwM7NlTZ06lf79+9OmTRtatGjB7rvvzqhRo2qsn6sH8Pnnn1PL/+bMzMxsDeSkkDWmOcDJkloVnpD0M2Ag8M2I6AsMAHJ/E70EWAfoGRE9gAeAUXkJmQVAmaTW6Xgg8G7BJe6OiL55X1MKY4iISbnzwIPA6en4u6nvB4GKiOgJbAfsApxQxz3XdN0ZwD559Q4BXito+4cUyyHAzZKK/vcraTvgCmBQRGwN7JeOtwJ+BVyXEiybAD8DhqambxXEdltet3tERB/gm0B34E913OdbKdY+QBfg0LxzA4E3gEMkKSIuznvOi/Kuf3VBn78ge8bbRcRWwO+AB2tLUJmZ2dLKysoYO3Ys8+bNY+HChTzyyCPMnDkTgGuvvZZtt92WY489lg8//LC6zQsvvEDv3r059thjuf766z1LyMzM7GvE/1e3xvRf4FngaODGgnNnAeUR8QlA+j5SUhvgGGDziFiSzt0i6VjgO8CY1P4RsiTLvcBg4E7g26sw9iOAZyPi8RTDQkknApXA8BXobyEwVdKOETEOOAy4B9i4sGJETJW0GOhQQ1+nAZdExIxUf4ak35EltX6UntVRZM/n/Ij4UNJ69QkyIuanhN1MSetHxAd11F8i6UVgk7ziwcAw4OfAzsC/6nNt4Exg94hYmPp+XNK/gCOBEfkVJR0PHA/QocOGnNdncT0vYdY4NmqdLSEzW50qKysBGDRoEDvvvDOtW7emW7duzJo1iz322IMRI0YgiZtvvpkjjjiCM888s7rt8OHDmTp1KmeddRZt27alVatl/j3HrEmYP39+9Vg3a8o8Vq2pcFLIGtulwKOSbs4VSFoXWCci/l2k/pbA27lkUZ5xQG++SgrdBZyXloxtC9zM0kmhwyTtmne8c0QsWo64ewMv5xdExFuS2klat0h8NV437/NdwOGSZgNLgPcokhSS1B/4kiypVlNsVxSUjSObaQPZbKEXgekRcXtenS0kjc87PikixhZ2HhGfSJoB9ABeqCGGXKxrA/2Bk/OOvwv8FGhPliCqMymUxkTbImMi93MvjPEG4AaAzbpvGVdO8h911rSd2mcxHqe2ulUdWQ5AeXk5l19+OQBnnXUWXbp04cADD6yu1717d/bdd1/Ky8uX6aNz586sv/767Ljjjg0Rstlyq6ysLDp2zZoaj1VrKvw3UGtUEfFvSS+QzbxZlf1OlNSNLOnwSJEqd0fEiavymvW0zHXz9md4DPgtMBu4u0jbUyT9EPgUOCwiYkX2doiI9yQ9CTxUcCq35Ks+6rpwLsG0OfBwRExM5fsC/4yIRZLuA86V9KvcrC8zM1v95syZQ8eOHXn77bcZNWoUzz//PLNmzaJz584A3H///ZSVlQEwY8YMNt10U1q0aMH777/P66+/Trdu3RoxejMzM1uVnBSypuASsmVeT0H1TJT5kroXmRnyFrCZpHUi4tO88n4sm+R4kGzGTDmwwSqOeQqwW36BpO7A/FpmCdUqIj6X9DJwKrAN2V5A+f4QEYUzgGqKrR8wIa+sH0vvUfRl+lpuktYBupHtC1STtyKir6QOwLOS9ouIB8mSdLtKqkr1NiBb9vdEbddMY2JBkTHRjzRuatK6ZXOmVexTWxWzRldZWVk9i8NsdTvooIOYN28eLVu2ZPjw4bRv356TTjqJ8ePHI4lu3brxpz9lW8c988wzVFRU0LJlSxYuXMh1111Hhw41rV42MzOzNY2TQtboIuJ1SVOAHwAvpeLfAcMlHZYSAu2AAyPiNkkjgd9L+lnas+YooA3wZEHXNwMfRcQkSeWrOOw7gLMkfTci/pE2nr4auGwl+70SeCoiPliJN7xcAfxV0pMRUZVmTJ0FHLySsZF+DtcBD0TEh3XVj4i5koYCv5ZUSbaEb9OI+Cz1dwxZoqjWpFByOXC1pEPSTKPvAruSLUUzM7N6Gjt2mZXB3H777UVqwo9+9CN+9KMfAV7qYGZm9nXkpJA1FRcDr+Yd/xFoB7wk6QvgC7KECcCvyRIfb0j6EngdOCAiIr/DiHiHLFFTTOHePidERH03PCYlJQYB10gaDjQHbgeuraPpMtcl2zso1+9rLPvWsbqcI+lXeX10kXQm8Lf0KvgvgDMiYnwd/RTuKXRz3hvA/pne7tYMuJ9smVt9PQCcD5wCPJlLCCWjgcskrVVQXsw1wDeASZKWAO+TvWFtefaCMjMzMzMzs0QFv0ebmX2t9OzZM6ZNm9bYYZjVyjMwbE3gcWprAo9TW1N4rFpDkvRyRBR9S0Szhg7GzMzMzMzMzMwan5ePmQGS+pAt/8r3WUT0X4G+jiG9gj3PsxHxi2L111Sr8pmZmZmZmZlZw3NSyAyIiElA31XU1y3ALauir6ZsVT4zMzMzMzMza3hePmZmZmZmZmZmVoKcFDIzMzMzMzMzK0FOCpmZmZmZmZmZlSAnhczMzMzMzMzMSpCTQmZmZmZmZmZmJchJITMzMzMzMzOzEuSkkJmZmZmZmZlZCXJSyMzMzMzMzMysBDkpZGZmZmZmZmZWgpwUMjMzMzMzMzMrQU4KmZmZmZmZmZmVICeFzMzMzMzMzMxKkJNCZmZmZl9jw4YNo6ysjN69e3PVVVctde7KK69EEnPnzgXgjjvuYNttt6VPnz7ssssuTJgwoREiNjMzs4bipJCZmZnZ19TkyZO58cYbefHFF5kwYQIPPfQQb775JgAzZ87k8ccfZ7PNNquuv/nmm/PUU08xadIkzj33XI4//vjGCt3MzMwaQIvGDsAsR9L8iGhXy/n2wBERcd0K9v8r4IaIWLhiES739aqAHSNirqR/RcQukroBu0TEX1bjdcuB0yJi39piqqX9WRFxyeqKL+86fYGNI+KRdLwfsE1EVKzK6yz6Ygndhj68Krs0W+VO7bOYIR6nthpc3m8h/fv3p02bNgDsvvvujBo1ijPOOINTTjmFyy67jEGDBlXX32WXXao/77TTTrzzzjsNHrOZmZk1HM8UsjVJe+CElWj/K6DNygQgaYUSqRGR+1t2N+CIlYmhAZzVQNfpC3w/dxARD67qhJCZWakrKytj7NixzJs3j4ULF/LII48wc+ZMRo8ezSabbMJ2221XY9sRI0aw9957N2C0ZmZm1tA8U8iaHEntgNHAN4CWwDkRMRqoALaQNB54IiJOl3Q6cCiwFnB/RPxGUlvgHqAL0Bz4LbARsDHwT0lzI2KPGq69F3BJajc3IgZIOh/YAugOvC3pl8D1QG6+/a8i4llJGwB3ApsAzwHK6zc3C6oC2Drdw8iI+EORGJqneuXpvoZHxJ/SDKDzgblAGfAy8MOIiBT3VcBC4Jm8vmqL6QFgU2BtYFhE3CCpAmid4nstIo6U9EPgl0Ar4AXghIhYUsPz+yPw/4DWwL0R8ZtU/v+AYUBb4DNgIHBhutauwO9Smx2Bs4GJwOYR8WX6eb6env9mwHBgw3SvP4mI14vEcTxwPECHDhtyXp/FxcI1azI2ap3NFjJb1WbPns2gQYPYeeedad26Nd26dWPGjBkMHTqUyy+/nMrKSv73v//x7LPPst5661W3e/XVV7nmmmu4+uqrqaysBGD+/PnVn82aKo9TW1N4rFpToYho7BjMgK8SJ2k2TpuI+ERSB+B5oAfQFXgoIspS/T2Bg4GfkiU7HgQuI0sY7BURP0n11ouIj+taOiVpQ+AVYLeImCFp/Yj4ICWFfgDsGhGLJP0FuC4inpG0GfD3iNha0tVkiaQLJe0DPARsmJaP5e6tnBqWduXFcTzQMSIukrQW8CxwSLr/0UBv4L1UfjowDpgOfAd4E7g7Pb9964gpd3+tgZeA3SNiXv4yPklbp2d6YER8Iek64PmIuK2G2HN9NgfGkCWTXk9fh0XES5LWJUvo/DD9PE5MbYfkjiWNBq6KiH9KOgwYGBE/ljQG+FlETJfUH/hdRHynpmcJsFn3LaPZocNqq2LW6E7ts5grJ/nfaWzVq6rYZ6njs846i4022oiLL764eknZO++8w8Ybb8yLL75Ip06dmDhxIgcccACPPvooW221VXXbyspKysvLGzJ8s+XmcWprCo9Va0iSXo6IHYud899ArSkScImk3YAvyWa5bFSk3p7p69V03I4seTQWuFLSpWRJpLH1vO5OwNMRMQMgIj7IO/dgRCxKn78LbCNVT7pZN81u2g04MLV9WNKH9bxuoT2BbSUdnI7XS/f1OfBiRLwDkGbzdAPmAzMiYnoq/zNplkwdMf1S0gHp86bpGvMKYhkA9ANeSvfbGphTS+yHpqRWC6AzsA0QwKyIeCnF8UmKs7ZncDdwGPBP4HDguvSMdwH+mtd2rdo6MTMzmDNnDh07duTtt99m1KhRPP/885x88snV57t168a4cePo0KEDb7/9NgceeCC33377UgkhMzMz+3pyUsiaoiPJZvv0S7NTqsiWOBUS2UyRPy1zQtqBbL+aiySNiYgLVzKmBXmfmwE7RcT/Cq65kpf4qivgpIj4e0H/5WRLr3KWsIL/Dae+vgvsHBELJVVS8zMeGRG/rkefmwOnAf8vIj6UdGsNfdbHg2SJwfXJklJPki09+ygi+i5PR61bNmdawb+UmzU1lZWVVB1Z3thh2NfUQQcdxLx582jZsiXDhw+nffv2Nda98MILmTdvHieckG3h16JFC8aNG9dAkZqZmVlD80bT1hStB8xJCaE9yJZNAXwKrJNX7+/AsWkGCZI2kdRR0sbAwoj4M3A5sEMN7Qs9D+yWkhukhEQxjwMn5Q7SW7QAniZtIi1pb7I9kQrVFUPuvn4uqWXqa6u0r05NXge6SdoiHQ/OO1dTTOsBH6aEUC+yWVI5X+SuTbYE7GBJHVMf60vqSnHrkiXPPpa0EZDbnXQa0DntK4SkddISwRqfRUTMJ1vSNoxstteSNMNohqRDUj+SVPMOqWZmBsDYsWOZMmUKEyZMYMCAAcucr6qqokOHDgDcdNNNfPjhh4wfP57x48c7IWRmZvY156SQNUV3ADtKmgQcRZb0ICLmAc9Kmizp8oh4HPgL8Fyqey9ZkqEP8GJaXvUb4KLU7w3AY5L+WeyiEfFfsmVXoyRNIFvCVMwvU3wTJU0BfpbKLyBLKr1GtmTr7SJtJwJLJE2QdEoN/d8ETAFekTQZ+BO1zAhKM5aOBx6W9ApLL++qKabHgBaSppJtav18XpsbgImS7oiIKcA5wOOSJgJPkC0LKxbHBLKlfK+T/VyeTeWfky0FuyY91yfIZhD9k2wZ3vi0b1Chu8n2Hcr/ORwJHJf6eQ0YVKSdmZmZmZmZ1YM3mjazr7WePXvGtGnTGjsMs1p5s0lbE3ic2prA49TWFB6r1pBq22jaM4XMzMzMzMzMzEqQN5q2kiTpBZZ9c9WPImJSA8bwPeDSguIZEXFAsfpNSVN4fmZmZmZmZrZynBSykhQR/ZtADH8n21R6jdMUnp+ZmZmZmZmtHC8fMzMzMzMzMzMrQU4KmZmZmZmZmZmVICeFzMzMzMzMzMxKkJNCZmZmZmZmZmYlyEkhMzMzMzMzM7MS5KSQmZmZmZmZmVkJclLIzMzMzMzMzKwEOSlkZmZmZmZmZlaCnBQyMzMzMzMzMytBTgqZmZmZmZmZmZUgJ4XMzMzMzMzMzEqQk0JmZmZmZmZmZiXISSEzMzOzr6Fhw4ZRVlZG7969ueqqqwA499xz2Xbbbenbty977rkn7733HgCVlZWst9569O3bl759+3LhhRc2YuRmZmbWUJwUMjMzM/uamTx5MjfeeCMvvvgiEyZM4KGHHuLNN9/k9NNPZ+LEiYwfP5599913qeTPt7/9bcaPH8/48eM577zzGjF6MzMzaygtGjsAs1IlaQkwCWgJLAZuA/4QEV/m1XkA6BQRO0nqCLwI7BQR76fzw4F3gGHAjcC2gICPgL0iYn4d1865KyIqJFUC3YGuERF5MXw3ItpJ6gZMBaYBrYCngROAzYCHIqKs4DpdgOHANmRJ6IeA04HfAC0i4sxUryvwT2AH4AGgM7AodfNmRBws6XzgJ8B/gbYp/nMiYkrNTxkWfbGEbkMfrq2KWaM7tc9ihnic2ipSVbEPU6dOpX///rRp0waA3XffnVGjRnHGGWdU11uwYAGSGitMMzMzawI8U8is8SyKiL4R0RsYCOxNliwBQFJ7oB+wnqTuETEHqACuSOd3AL6djk8GZkdEn5SYOQ74oh7Xzn1V5J37CPhWXgydC9q+FRF9yRJQ2wD7F7uAst80RgEPREQPYCugHXAxcBGwv6StU/VhwLkR8VE6PjIvtoPzuv1DKusB3A08KWnDWu7TzKwklZWVMXbsWObNm8fChQt55JFHmDlzJgBnn302m266KXfcccdSM4Wee+45tttuO/bee29ee+21xgrdzMzMGpCTQmZNQEr4HA+cqK/+2fZA4G/AXcDhqewGYAtJe5DNwDkxIr4gS9y8m9fftIj4bAXDyb/egWSJnWIxLwb+BWxZQz/fAf4XEbek+kuAU4BjyWYznQIMl/R9YJ2IuGN5goyIu4HHgSOWp52ZWSnYeuutOfPMM9lzzz3Za6+96Nu3L82bNwfg4osvZubMmRx55JFce+21AOywww785z//YcKECZx00knsv//+jRi9mZmZNRQvHzNrIiLi35KaAx2B2cBg4ML0+T7gkoj4UtLPgSeBByPi6dT8ZuBxSQcDY4CRETG9lsu1ljQ+7/h3KclCan9jiuVwsmTVuYUdSGoDDABq2niiN/BywT1+IultYMuIeETSccBIYNeCtndIyi0feyIiTq/hGq8AvYrEdnyKmw4dNuS8PotraG7WNGzUOltCZrYqVFZWArDFFltw5ZVXAnDjjTey4YYbVp8D6N69O0OHDmWPPfZYqn2bNm349NNPGT16NOutt151+fz585dqb9YUeZzamsJj1ZoKJ4XMmiBJGwE9gGciIiR9IaksIiZHxHhJk4HrcvVTWXdgT+C7wEuSdo6IqTVcYlFaAlbMEuAZsoRQ64ioKthzYouUUApgdEQ8mvYaWhHD0zWmFZQfGRHj6tG+6GYYEXED2awqNuu+ZVw5yX/UWdN2ap/FeJzaqlJ1ZDkAc+bMoWPHjrz99tu8/PLLPP/88/z3v/+lR48eAFxzzTX069eP8vJy3n//fTbaaCMk8eKLL9KqVSv222+/pfYcqqyspLy8vBHuyKz+PE5tTeGxak2F/wZq1kSkpM4SYA5wIvANYEb6C/m6ZDOHzk7Vv0xf1dKm0qOAUZK+BL5Ptin0irgLuB84v8i5t2pJKOWbAuTvB4Skdck2pX4zFS1zH8tpe6DW5FHrls2ZVrHPSlzCbPWrrKys/kXebFU56KCDmDdvHi1btmT48OG0b9+e4447jmnTptGsWTO6du3K9ddfD8C9997LH//4R1q0aEHr1q256667vAm1mZlZCXBSyKwJSJslXw9cm2YGDSZ7e9hz6fzmwD/4KilU2P5bwJSI+FBSK7INoCtXIqSxwO+AO1eijzFAhaSjIuK2tBztSuDWiFi4Ev0CIOkgsplRp65sX2ZmX0djx45dpuy+++4rWvfEE0/kxBNPXN0hmZmZWRPjpJBZ48nt65N7Jf3twO/TUqyuwPO5ihExQ9LHkvpHxAtF+toC+GPapLoZ8DDZPkR1XTvnsYgYmne9IL3lbDn0lPRO3vEpwAHAdZLOTXE9ApxVj77y9xSaGxHfzfUp6Ydkr6SfDHwnIv67nHGamZmZmZkZTgqZNZqIaF7DqSpgkyL1d8j7XF5w7jbgtpW9dmG/eeXt0vcqoKzI+Sqy5FYxP6gljkoKZjTVEsP5FF/OZmZmZmZmZivAr6Q3MzMzMzMzMytBnilk9jUlaQOyfX0KDYiIeQ0dj5mZmZmZmTUtTgqZfU2lxE/fxo7DzMzMzMzMmiYvHzMzMzMzMzMzK0FOCpmZmZmZmZmZlSAnhczMzMzMzMzMSpCTQmZmZmZmZmZmJchJITMzMzMzMzOzEuSkkJmZmZmZmZlZCXJSyMzMzMzMzMysBDkpZGZmZmZmZmZWgpwUMjMzMzMzMzMrQU4KmZmZmZmZmZmVICeFzMzMzMzMzMxKkJNCZmZmZmZmZmYlyEkhMzMzMzMzM7MS5KSQmZmZ2dfQsGHDKCsro3fv3lx11VUAnHvuuWy77bb07duXPffck/fee2+pNi+99BItWrTg3nvvbYSIzczMrKG1aOwAzMxWp0VfLKHb0IcbOwyzWp3aZzFDPE5tFamq2IfJkydz44038uKLL9KqVSv22msv9t13X04//XR++9vfAnD11Vdz4YUXcv311wOwZMkSzjzzTPbcc8/GDN/MzMwakGcKlRhJ+0sKSb3ScTdJiySNlzRF0vWSmtVUXkOf+XVzX0dJWkfSW5J6pHotJU2StHtevQ8kzUif/1FD/80kXS1pcmr/kqTN07n1JN0m6c10rdskrZfOlUt6qKCvWyUdnD5XSpomaULqs29evb0ljUv3/qqkK1P5+ZLeLbjX9jXE/c28OhMkHZB3bkkqfy2dO7Xw+Up6QNLz6XNHSVWSOuWdHy7p15LaSLojPZvJkp6R1K74CFjq2rmvoXnP421JKohhfpGfc+FYmVzkOl0kjZY0Pf1shklqJeliSZfm1esq6d+S2uf9THKx3VvkuU+XNErSNjXdo5lZqZs6dSr9+/enTZs2tGjRgt13351Ro0ax7rrrVtdZsGABeX/kc80113DQQQfRsWPHxgjZzMzMGoGTQqVnMPBM+p7zVkT0BbYFtgH2r6O8mLciom/e120R8Snwa+DaVOc04F8R8VSuHvAgcHo6/m4NfR8GbAxsGxF9gAOAj9K5EcC/I2LLiNgCmAHcVPdjqHZkRGwHXAdcDiCpLMX8w4jYBtgReDOvzR8K7vWjwk6TycCO6T73Av4kKTc7b1Fq2xsYCOwN/CbXMCWa+gHrSeoeEXOACuCKdH4H4Nvp+GRgdkT0iYgy4Djgi1rueVFB/BV55z4CvpUXQ+eCtvUaEymxNAp4ICJ6AFsB7YCLgYuA/SVtnaoPA87Ne45H5sV2cF63uefeA7gbeFLShrXcp5lZySorK2Ps2LHMmzePhQsX8sgjjzBz5kwAzj77bDbddFPuuOMOLrzwQgDeffdd7r//fn7+8583ZthmZmbWwLx8rISk2SO7AnsAfyMvCQEQEYsl/QvYEnilhvLlEhH3SDpO0hnAz4DtVyD0zsCsiPgy9flOup8tyRInh+XVvRB4U9IWy3mN54DT0+czgIsj4vV0vSXAH5c36IhYmHe4NhA11Jsj6XjgJUnnR0QAB5L9jGYDhwOXADcAR0vaIx2fGBFfSOoM/Cevv2nLG2ueu9L1nkkxjAJ6F4m56FjJ8x3gfxFxS6q/RNIpZEm73wCnAMMlXQGsExF3LE+QEXG3pH2AI8iSSktJz/N4gA4dNuS8PouXp3uzBrdR62wJmdmqUFlZCcCgQYPYeeedad26Nd26dWPWrFlUVlYycOBABg4cyB133MFpp53GMcccw/nnn89hhx3G008/zfvvv89rr71Ghw4dlup3/vz51X2bNVUep7am8Fi1psJJodIyCHgsIt6QNE9SP2Be7qSkNsAA4Lz8RjWVF9hC0vi845MiYmz6fDIwFTg+Ij5YgbjvAZ6R9G1gDPDniHiVbKbK+JS0AaqTD+PJEhmfLMc19gIeSJ/LgCtrqXuKpB+mzx9GxB41VZTUH7gZ6Ar8KCKK/tYXEf+W1BzoSJYIGkyW4JoN3AdcEhFfSvo58CTwYEQ8nZrfDDyelsWNAUZGxPRa4m9d8LP6XUTcnT6PAW5MsRxOllg5t8h91TUmegMvF9zjJ5LeBraMiEckHQeMJEtU5rtD0qL0+YmIOJ3iXgF6FTsRETeQJdHYrPuWceUk/1FnTdupfRbjcWqrStWR5QCUl5dz+eWXA3DWWWfRpUsXysvLq+t1796d73//+4wcOZL//Oc/XHbZZQDMnTuXV155he22247999+/un5lZeVS7c2aIo9TW1N4rFpT4b+BlpbBfDWr4q50fC1fJXQCGB0Rj0rqVqy8lr5zy4qK2QuYRZZsWW4R8Y6knmSzT74DjJF0SH2a1qP8DkmtyJY29a1nSH+IiCvqUzEiXgB6p6VSIyU9GhH/q62NpI2AHsAzERGSvpBUFhGTI2J82r/nurxrjJfUHdgT+C7ZjKOdI2JqDZdYVMvPagnZLKHDgdYRUZW/3wQ1j5UVMTxdo3Bm05ERMa4e7VV3FTOz0jVnzhw6duzI22+/zahRo3j++eeZPn06PXr0AGD06NH06pXl1mfMmFHdbsiQIey7775LJYTMzMzs68lJoRIhaX2yhEofSQE0J/vFfjg1J3RqS/TU97obA78Evgn8U9KIiJi4vP1ExGfAo8CjkmaT7WUzDOgrqVluaVnarLkvMIVsydY3CrpaH5ibd3wk2YyWy4FryJZMvUa2LG3C8sZZS/xT04bNZcAyCY+U1FkCzAFOTHHPSAmZdckSeGen6l+mr/z+55Mt9Rol6Uvg+2Szs1bEXcD9wPlFztV3TEwB8vcDQtK6wGZ8tT/TMvexnLanyLMs1Lplc6ZV7LMSlzFb/SorK6tnd5itKgcddBDz5s2jZcuWDB8+nPbt23Pccccxbdo0mjVrRteuXavfPGZmZmalyUmh0nEwcHtE/DRXIOkpYNPVfN0/kC19ekfS/5HtI7Nb2jenXtKmyu9HxHsp6bMtMDEi3pT0KnAO2VIr0udX0rm1gI0lbZ2SMl2B7YDx+f2n2TjnAm8peyvb5WTJlWfSUrtmZEvflutvzsrekDYz7b/TlWypU1WRehsC1wPXplgGA3tFxHN5/fyDr5JChe2/BUyJiA/TrKdtgMrlibXAWOB3wJ0r0ccYoELSURFxW1qOdiVwa8FeSytE0kFkM6NOXdm+zMy+rsaOHbtM2X333Vdnu1tvvXU1RGNmZmZNkZNCpWMwcGlB2X1kbwdbFQr3FLqZbKbKZmRvCCMi/ibpJ8BRZHvJ1FdHsn1u1krHL/LVG82OA66R9FY6fi6VERGfpb1/bpG0NtkbuX4cER8XXiAiFil77fzpEXGcpF8Bd6a9cwLIf7V9/p5CAPtHRFWRuHcFhkr6gmxGzAkRkZullNvXpyWwGLgd+H1aitUVeD4vthmSPpbUPy1HK7QF8Mf0xq9mwMNkP9uaFO4p9FhEDM27XpDecrYcekp6J+/4FLK3xF2XEm7NgP/f3n2HWVWd7R//3gIqiIoGNVgQK5GWAYkYY3Q00VjyUwhY0LzWhNhiiliiRsUSUTRW3tiiYAuKYsOCvugo0aCCgmBBUYiKHUVpIgPP74+9Dh4Pc6bQZoZzf65rrjlnrb3XevY+y3HmYa21HwHOrEVb+XsKfZb3VLrcfV+H7Mlue0bEp3WM08zMzMzMzBLVYcKGmVmj0759+5gyZXkeyGa28nmzSWsMPE6tMfA4tcbCY9VWJUnjI6J7VXVrrOpgzMzMzMzMzMys/nn5mNWapM5ky5zyLYiIHo2h/ZVF0i9YemnetIjoVR/xAEj6Htm+PoV+FhEzV3U8ZmZmZmZm1vA4KWS1FhGTqP1j2xtc+ytLRIwCRtV3HPlS4qesvuMwMzMzMzOzhsvLx8zMzMzMzMzMSpCTQmZmZmZmZmZmJchJITMzMzMzMzOzEuSkkJmZmZmZmZlZCXJSyMzMzMzMzMysBDkpZGZmZmZmZmZWgpwUMjMzMzMzMzMrQU4KmZmZmZmZmZmVICeFzMzMzMzMzMxKkJNCZmZmZmZmZmYlyEkhMzMzMzMzM7MS5KSQmZmZmZmZmVkJclLIzMzMbDVx1VVX0alTJzp27MiVV14JwKmnnsoPfvADunTpQq9evZg1axYA06dPp3nz5pSVlVFWVsZxxx1Xf4GbmZlZvXBSyMzMzGw1MHnyZG688UZeeOEFJk6cyMiRI5k6dSp77bUXkydP5pVXXmH77bfn4osvXnLONttsw4QJE5gwYQLXXXddPUZvZmZm9aFpfQdgtjwkzYmIlstw3h+BGyJi3jKc2xN4MyJeq+u5yyJ3jZI2Ba6OiD7L0MZRwOMR8UF6fxPw95V9Dcv6+dSy7XKgf0T8srrj5i9cRLszHl4ZIZitMKd0ruQoj1NbDtMH7s/rr79Ojx49aNGiBQC77747I0aM4LTTTlty3M4778w999xTX2GamZlZA+OZQlaq/gi0WMZzewIdVlgktRQRHyxLQig5Ctg0r63frKqklpmZrRqdOnVizJgxzJw5k3nz5vHII4/w3nvvfeeYm2++mX333XfJ+2nTptG1a1d23313xowZs6pDNjMzs3rmmUK2WpDUEngA2ABoBpwdEQ9IWge4G9gcaAJcAGxCliB5StJnEbGHpL2BAcBawNvA0RExR9JA4ACgEngcGJHe7y7pbKB3RLxdRTy/BfoBawJTgf+JiHmShgBfA92B9YA/R8TINJOnF7A+sBlwe0QMKGizHTAyIjpJagJcAuwDLAZujIhrJJ0D/D+gOfAc8Dugd+rvDknzgR8Dj5LNshknqS9wJiDg4Yg4PfU3B7gK+CUwHzgwIj4ucv83Aa4Dtk5Fx0fEc3n1Ai4F9gUCuDAi7pLUBrgr3Yum6bwx1Xwe+wBXAvOAf1cVS+qvX7r/tG69Eed0rix2qFmDsEnzbLaQ2bKqqKgA4MADD+THP/4xzZs3p127dnz44YdL6m6//XZmzZrFZpttRkVFBd988w133nkn66+/PlOmTKF3797ccsstrLPOOlX2MWfOnCVtmTVUHqfWWHisWkOhiKjvGMyWWd7SqqZAi4j4SlJrYCywHfArYJ+I+G06fv2I+FLSdKB7RHyWjh8B7BsRcyWdTpaMGEyWWPlBRISkVhExKyV2RkZE0fn3kr4XETPT6wuBj1PSZgjwfWA/YBvgKWBb4FDgYqATWcLjReColLTJXWM7vk0KHQ/8DDg0IiolbRgRn+e+p35vA+6OiIckVZCSQKmuAugPfJDu1Y7AF2SJr6sj4n5JARyQzr8U+CoiLixyvXcB/4mIK1PCqmW6z7nYewPHkSWxWqfr6wEcBqwdERel81qke1/V53Ep8BawJ1mi7a70mVe7fKzt1tvGGgdfVd0hZvXulM6VXD7J/05jy276wP2XKjvzzDPZfPPNOeGEExgyZAjXX389o0ePXrK8rFB5eTmXXXYZ3bt3r7K+oqKC8vLyFRm22QrncWqNhceqrUqSxkdElf+D9/IxW10I+JukV4D/I5ttswkwCdhL0iWSfhoRX1Zx7s5ky8GelTQBOBLYEviSbFbPPyX9iixZU1udJI2RNAk4HOiYV3d3RCyOiLeAd4AfpPInImJmRMwnS4rsWk37Pweuj4hKgFwiCNhD0vOp3z0L+q3Kj4CKiPg0tXUHsFuq+wYYmV6PB9pV086ewD9SLIuquM+7Av9KdR8DT6e+XwSOlnQe0DkiZlP88/gBMC0i3oosm317DddmZlZyPvnkEwDeffddRowYwWGHHcZjjz3GpZdeyoMPPvidhNCnn37KokWLAHjnnXd466232Hrrrats18zMzFZP/mdJW10cDmwE7BgRC9NMoLUj4k1J3chm5lwoaXREnF9wrsgSMn0LG5W0E9mMnD7ASWTJj9oYAvSMiIlpaVh5Xl3h9LyoobxWJK0N/C/ZDKj3UqJl7bq0UWBhfDuVcBEr4edFRDwjaTdgf2CIpL+TzVha6vOQVLYsfTRv1oQpVfwLullDUlFRwfTDy+s7DFsN9O7dm5kzZ9KsWTMGDx5Mq1atOOmkk1iwYAF77bUXkG02fd111/HMM89wzjnn0KxZM9ZYYw2uu+46Ntxww3q+AjMzM1uVnBSy1cX6wCcpIbQH2cwS0hO7Po+I2yXNAn6Tjp8NrAt8RrZ8arCkbSNiatqHaDOypVUtIuIRSc+SzerJP7c66wIfSmpGlrCakVd3kKShwFZke/BMAbqSzWjakGz/np7AMdW0/wTwO0lP5ZaPke0tBPBZ2mOpD5Bb4lYs5heAq9MSui+AvsA1NVxbVUYDxwPfWT6WVz8mxTsU2JBsNtKpkrYE3o+IGyWtBXQDLqLqz+MNoJ2kbdI+Tksl8czMSl1Vm0VPnTq1ymN79+5N7969V3ZIZmZm1oA5KWSrizuAh9KyqXFkCQSAzsAgSYuBhWSJC4AbgMckfZA2mj4K+FdKTACcTZZIeSDNwBHw51Q3DLhR0slAn6o2mgb+CjwPfJq+5ydk3iVLxqwHHBcRX2f7MPMCcC/Zpti35/b/KeImYHvgFUkLyTaavlbSjcBk4COypVk5Q4Dr8jaaBiAiPpR0BtneRrmNph+opt9i/gDcIOlYsllFxwP/yau/L/U7kWwG1GkR8ZGkI8mSQwuBOcAREfFpVZ9HmvXVD3hY0jyyRFNNyTkzMzMzMzMrwhtNm61CxTapTkmQ7hFxUn3EtTpr3759TJkypb7DMKuWN5u0xsDj1BoDj1NrLDxWbVXyRtNmZmZmZmZmZvYdXj5mthwkDQZ+UlB8VUTcUtXxEXFUkfIhZEu8GjRJZwEHFRQPj4iL6iMeMzMzMzMzW3ZOCpkth4g4sb5jWJVS8scJIDMzMzMzs9WAl4+ZmZmZmZmZmZUgJ4XMzMzMzMzMzEqQk0JmZmZmZmZmZiXISSEzMzMzMzMzsxLkpJCZmZmZmZmZWQlyUsjMzMzMzMzMrAQ5KWRmZmZmZmZmVoKcFDIzMzMzMzMzK0FOCpmZmZmZmZmZlSAnhczMzMzMzMzMSpCTQmZmZmZmZmZmJchJITMzMzMzMzOzEuSkkJmZmVkjdtVVV9GpUyc6duzIlVdeCcDw4cPp2LEja6yxBuPGjVty7MKFCznyyCPp3LkzO+ywAxdffHE9RW1mZmYNgZNCZmZmZo3U5MmTufHGG3nhhReYOHEiI0eOZOrUqXTq1IkRI0aw2267fef44cOHs2DBAiZNmsT48eO5/vrrmT59ev0Eb2ZmZvWuaX0HYLY6kNQTuA/YISLekNQOmAZcFBFnp2NaAx8C16fvB6XTOwOT0uubI+LqIn38GjgNaAJUAi8C/SNilqQ1gUuBXwIBvAacGBHvp3M3BwYDHciSwSOBUyPiG0nlwAPAO0AL4GPg0ogYmc5tn2JuBawFjImIfkVizLU1LR07LCIGFJSvDYyMiP7pnKOA7hFxUnp/RLrOSNd5R0RcJmkIsDvwZepuXkTsUlUc+eYvXES7Mx6u6TCzenVK50qO8ji1Opo+cH9ef/11evToQYsWLQDYfffdGTFiBKeddlqV50hi7ty5VFZWMn/+fNZcc03WW2+9VRm2mZmZNSCeKWS2YvQF/p2+50wD9s97fxDwKkBEXBQRZRFRBszPva4mIbQP8Cdg34joCHQDngM2SYf8DVgXaB8R2wH3AyOUACOA+1Pd9kBL4KK8LsZERNeIaA+cDFwr6Wep7mrgihTfDsA1NdyLMem6ugO/ltStoLwr8EtJP6niOvcF/gjsHRGdgZ35NgkEWSIrd69qTAiZma3uOnXqxJgxY5g5cybz5s3jkUce4b333it6fJ8+fVhnnXVo06YNbdu2pX///my44YarMGIzMzNrSJwUMltOkloCuwLHAofmVc0DXpfUPb0/BLh7Gbs5i2xW0AyAiFgUETdHxBRJLYCjgT9FxKJUfwuwANgzfX2dykjH/Ak4Jp37HRExATgfOCkVtQHez6ufVHhOVSJiLjAe2LagfD4wAdisitP+kq7zg3Tsgoi4sTb9mZmVoh122IHTTz+dvffem3322YeysjKaNGlS9PgXXniBJk2a8MEHHzBt2jQuv/xy3nnnnVUYsZmZmTUkXj5mtvwOBB6LiDclzZS0IzAz1Q0DDpX0MbAI+ADYdBn66Ai8VKRuW+DdiPiqoHxcOg+y5MwSEfGVpHcpSNjkeQk4Nb2+AnhS0nPA48AtETGrpoAlfY9sps8FwEZ55RsA2wHPVHFap8JYCwySdHZ6/WpEHF6k735AP4DWrTfinM6VNYVrVq82aZ4tITOri4qKCgC22WYbLr/8cgBuvPFGNtpooyV1s2bNYvz48cyZMweAK6+8kg4dOvDss88CsPXWWzN06FD22GOPGvubM2fOknbNGiqPU2ssPFatoXBSyGz59QWuSq+HpffXpvePkSVFPgbuWhGdSeoM3Ea2XOxM4PUV0W5hN7kXEXGLpFHAPmQJsN9J+mFELChy7k8lvQwsBgZGxKtpT6GfSppIlhC6MiI+Woa4To2Ie2o6KCJuAG4AaLv1tnH5JP+os4btlM6VeJxaXU0/vByATz75hI033ph3332X8ePHM3bsWFq1agVAq1at2HHHHenePZu0+vzzz/PGG29QXl7O3Llz+e9//8sll1xCly5dauyvoqKC8vLylXQ1ZiuGx6k1Fh6r1lD4N1Cz5SBpQ7LlWZ0lBdkm0EG2qTNpI+fxwClkmzwfsIxdvUq2j9BTaflWmaRrgebA20BbSetGxOy8c3Yk21BaQJ+CuNcD2gJTgZ2q6K8recmmtJzrZuBmSZOpfkbPmIj4ZbFySVsBYyXdnZaqFV7njsCTRdqus+bNmjBl4P41H2hWjyoqKpb8gW9WV71792bmzJk0a9aMwYMH06pVK+677z5+//vf8+mnn7L//vtTVlbGqFGjOPHEEzn66KPp2LEjEcHRRx9dq4SQmZmZrZ6cFDJbPn2A2yLid7kCSU8DW+QdcznwdER8nu35vEwuBi6TdGDuiWJkCSEiYq6kocDfJR0XEYvSE7xa8G1yZaCkIyLiVklNUkxDImJeYUySugB/BX6T3u8DjI6IhZK+D3wPmLGsFxIR0yQNBE7nuxtz565zkKT9I+Kj9FS1IyLipmXtz8xsdTdmzJilynr16kWvXr2WKm/ZsiXDhw9fFWGZmZlZI+CkkNny6QtcUlB2L9mGyQBExKukp44tq4h4RNJGwKMpqTMLmAyMSof8BbgMeFPSYuANoFdEBICkXsD/Svor2Qbzj5AtPcvJLflqAXwCnBwRo1Pd3sBVkr5O709dxqVf+a4D+ktqV8V1bgL8X3pqWpDNUMrJ31MIYKeI+GY5YzEzMzMzMytJSn8zmpmtltq3bx9Tpkyp7zDMquV9Bawx8Di1xsDj1BoLj1VblSSNj4juVdX5kfRmZmZmZmZmZiXIy8fMGhBJZwEHFRQPj4iL6iOeYiT9gqWXzU2LiKU3sDAzMzMzM7MGyUkhswYkJX8aVAKoKhExim/3MzIzMzMzM7NGyMvHzMzMzMzMzMxKkJNCZmZmZmZmZmYlyEkhMzMzMzMzM7MS5KSQmZmZmZmZmVkJclLIzMzMzMzMzKwEOSlkZmZmZmZmZlaCnBQyMzMzMzMzMytBTgqZmZmZmZmZmZUgJ4XMzMzMzMzMzEqQk0JmZmZmZmZmZiXISSEzMzMzMzMzsxLkpJCZmZmZmZmZWQlyUsjMzMzMzMzMrAQ5KWRmZmbWQF1xxRV07NiRTp060bdvX77++muefPJJunXrRqdOnTjyyCOprKwE4I477qBLly507tyZXXbZhYkTJ9Zz9GZmZtbQNa3vAMzMVqb5CxfR7oyH6zsMs2qd0rmSozxOLc/0gfszY8YMrr76al577TWaN2/OwQcfzJ133sm5557L6NGj2X777TnnnHMYOnQoxx57LFtttRVPP/00G2ywAY8++ij9+vXj+eefr+9LMTMzswbMM4VKjKSekkLSD9L7dpLmS5og6TVJ10lao1h5kTbzj819HSFpXUlvS9ouHddM0iRJu+cd97mkaen1/xVpfw1JV0uanM5/UdJWqW59SbdKmpr6ulXS+qmuXNLIgraGSOqTXldImiJpYmqzLO+4fSWNS9f+sqTLU/l5kmYUXGurInHvJWl8inm8pD3z6qan8kmpjwslrV1w/pWprzUkrS3pDUmd8+pPlXR9dfenSFy5vnPxX513b+ZJWrcghpDUOr1flM6ZLGm4pBapfE4V/VT52Uj6raS78o5bL9VvnWKYlhfbc+mYoyR9mj6LtySNkrRLsWs0M1tdVFZWMn/+fCorK5k3bx7rrLMOa665Jttvvz0Ae+21F/feey8Au+yyCxtssAEAO++8M++//369xW1mZmaNg5NCpacv8O/0PeftiCgDugAdgJ41lFfl7Ygoy/u6NSJmA38Brk3H9Aeei4inc8cBDwKnpvc/L9L2IcCmQJeI6Az0Amalun8C70TEthGxDTANuKnm27DE4RHxQ+B/gUEAkjqlmH8dER2A7sDUvHOuKLjWWYWNJp8B/y/FfCRwW0H9HqluJ2Br4PpcRUrA9QLeA3aPiK+BPwL/q8xmwHHAGTXcn2L2yIv/5LzyqcCBeTHsCczIq5+fzukEfJNiKKbYZ3MTsIWk3Od9PnBzRLyT3p+aF1t+4ueuiOgaEdsBA4ERknao4TrNzBqtzTbbjP79+9O2bVvatGnD+uuvz8EHH0xlZSXjxo0D4J577uG9995b6tx//vOf7Lvvvqs6ZDMzM2tkvHyshEhqCewK7AE8BJybXx8RlWlmxrbAS0XK6yQi7pZ0rKTTyBIIXZch9DbAhxGxOLX5frqebYEdyZIiOecDUyVtU8c+/gOcml6fBlwUEW+k/hYB/6hr0BHxct7bV4HmktaKiAUFx82RdBzwnqQNI+JzoDydcxdZAu+piHhM0jHAEcD+wHkR8YWkKu/PMhpGdj9vTzE8CxT7q2IMWcJwKdV9NmQJsOOAOyUdBfwsHVtrEfGUpBuAfsCfqui/X6qjdeuNOKdzZV2aN1vlNmmeLSEzy6moqGD27NkMHTqU22+/nZYtW3Leeedx9tlnc9ppp3HMMcewcOFCunfvzvz586moqFhy7ssvv8w111zD1Vdf/Z3y5TVnzpwV2p7ZyuBxao2Fx6o1FE4KlZYDgcci4k1JMyXtCMzMVaalQD8Dzsk/qVh5gW0kTch7//uIGJNe/wF4HeiXEh51dTfwb0k/BUYDt6eESwdgQkraAFkCJ8XREfiqDn3sA9yfXncCLq/m2D9J+nV6/UVE7FGL9nsDLxUmhHIi4itJ04DtgOfJEkH/Ah4A/iapWUQsJJst9ALwVkTkZh4Vuz/VeUpS7r4NjYgr0us3gQMkbZBiuJ0qkkKSmqbyx4q0X+1nExEPShqV4j0wIr7JO3eQpLPT61cj4vAifbwE/K6qioi4AbgBoO3W28blk/yjzhq2UzpX4nFq+aYfXs7w4cPp2rUrPXv2BOCDDz5g7NixXHTRRZx44okAPP744yxYsIDy8nIAXnnlFa699lqeeOKJJUvMVpSKiool/Zg1VB6n1lh4rFpD4d9AS0tf4Kr0elh6fy3fJnQCeCAiHpXUrqryatrOLTWryj7Ah2TJljqLiPcltSdbyrQnMFrSQbU5tRbld0haE2gJlNUypCsi4rJaHoukjsAlwN41HZqOXxPYD/hzRMyW9DzwC2BkRHwg6UlgyV5Jxe5PRIyupq89IuKzInUjgEOBHiyddGmel/wbQ7ZEbFkNBvaNiIqC8lMj4p5anK/l6NvMrMFr27YtY8eOZd68eTRv3pzRo0fTvXt3PvnkEzbeeGMWLFjAJZdcwllnnQXAu+++y69+9Stuu+22FZ4QMjMzs9WTk0IlQtKGZAmDzpICaEKWHBlM8YROdYme2va7KXAy2b45T0n6Z0S8Utd20gybR4FHJX1Mtr/RVUCZpDVyS6fSPjhlwGvA2sAGBU1tSLbXT87hwHiy/YSuAX5FtmxrR2C5n+UraXPgPuCIiHi7muPWBdqRzdT5BdAKmCQJoAUwn28TQYvT1xJF7k91SaHq3EV2T4ZGxOIUQ878Wo6J16j+s6nyOuqoK9kMtGo1b9aEKQP3X45uzFa+iooKph9eXt9hWAPTo0cP+vTpQ7du3WjatCldu3alX79+nH322YwcOZLFixdz/PHHs+ee2XMMzj//fGbOnMkJJ5wAQNOmTZfsPWRmZmZWFSeFSkcf4LaIWDLzQ9LTwBYrud8rgL+l2Sx/BgZL2i0iis3iWYqkbsBHaZbMGmT72LwSEVMlvQycTbZfDen1S6luLWBTSTtExOuStgR+CEzIbz8iQtJfgbeVPZVtENkmxv9OS+3WIFv6dl1dLlzZU8keBs6IiGerOa4l2UbX96c9gvoCv4mIf6X6dYBpklpExLza3p+6xJovIv4r6SygyqfB1bKNaj+bZW03R9LuZHsG1WbpnplZozVgwAAGDBjwnbJBgwYxaNCgpY696aabuOmmujxrwczMzEqdnz5WOvqSzVjJdy/Z08FWhG303ce0nyxpL6AtaYlRRDwEfEG2UXJdbAw8JGkyWbKjkm+faHYssH16pPnbwPapLDd75tfALWnJ0z1kyZYvCzuIiPlk+widmmYy/RH4l6TXgclkmyPn/KngWtsVifskss25z8k7duO8+qfSNb0AvAv8Lu3ftA9ZMikX21yyJ8b9v2W4nih3hgAAH0dJREFUP8U8lRfTrYWVEXF9dTObqtBC0vt5X3+mms+mBoMK7u+aqfyQ9P5N4Eygd0TUOFPIzMzMzMzMqqY6TNgwM2t02rdvH1OmTKnvMMyq5c0mrTHwOLXGwOPUGguPVVuVJI2PiO5V1XmmkJmZmZmZmZlZCfKeQlZrkjoDtxUUL4iIHo2h/ZVF0i/Ini6Wb1pE9KqPeHLSU8vWKij+n4iYVB/xmJmZmZmZWcPipJDVWkomlDXW9leWiBgFjKrvOAo19GSamZmZmZmZ1S8vHzMzMzMzMzMzK0FOCpmZmZmZmZmZlSAnhczMzMzMzMzMSpCTQmZmZmZmZmZmJchJITMzMzMzMzOzEuSkkJmZmZmZmZlZCXJSyMzMzMzMzMysBDkpZGZmZmZmZmZWgpwUMjMzMzMzMzMrQU4KmZmZmZmZmZmVICeFzMzMzMzMzMxKkJNCZmZmZmZmZmYlyEkhMzMzswbqiiuuoGPHjnTq1Im+ffvy9ddf8+STT9KtWzc6derEkUceSWVlJQARwcknn8y2225Lly5deOmll+o5ejMzM2vonBQyMzMza4BmzJjB1Vdfzbhx45g8eTKLFi3izjvv5Mgjj2TYsGFMnjyZLbfckqFDhwLw6KOP8tZbb/HWW29xww03cPzxx9fzFZiZmVlD17S+A1jVJPUE7gN2iIg3JLUDXgemAGsCzwAnAG2rKo+IxdW0/UdgILBJRHyZysqBp4DfRsRNqawMeBk4FdgK+EnqY6vUH8CFEXFPFX0MAUZGxD2SKoCWEdE91XUHLouI8vR+J+AyYBNgHjAeODki5qX7cD7QDKgE/hoR9+f1cXC6jtmp7ErgD8BGEfGZpEXApLzQhkXEwCrivS9dV0tgI2BaqjoBGAdcCvwSCOA14ERgPjA6Hfd9YBHwaXq/E7Ae8CHw+4i4Lq+v6UD3iPisMI6CmH4A3AJ0A86KiMtS+RbArel+BXBDRFxVQ1tNUyz/jIgz8sorgK2BLSMiUtn9wM+BHwO3pUPbAl+mr88i4ufV9PVHio+vAyLioVQ2kmwcVFQ3RiQdle7XSQVx94+Icel+9gBGper8z0LAXOCCiHg0nXsQcGxE7FPdPatJus4bImJeev8IcFhEzFqW9uYvXES7Mx5enpDMVrpTOldylMep5Zk+cH8AKisrmT9/Ps2aNWPevHmss846rLnmmmy//fYA7LXXXlx88cUce+yxPPDAAxxxxBFIYuedd2bWrFl8+OGHtGnTpj4vxczMzBqwUpwp1Bf4d/qe83ZElAFdgA5AzxrKq2v7ReBXBeWTyZIs+cdNBIiIE1Mf++X6S19LJYSK2FjSvoWFkjYBhgOnR0T7iOgKPAasK+mHZMmiAyNiB+AA4DJJXfKamAocmNpaA9gTmJFXPz8v1rKqEkLp+nql6/sNMCbv+OeAvwHrAu0jYjvgfmAE8HnuOOA64Iq8874BDgLG8t3PsC4+B05O9yBfJXBKRHQAdgZOlNShhrb2At4EDpKkgrpZZAk/JLUC2gBExKS863sQODW9L5oQSoqNr/eBs6o5r8oxUkuLinwWPwT6AX+XtLaklmSf54k1NahMdT97/gi0yL2JiP2WNSFkZtaYbbbZZvTv35+2bdvSpk0b1l9/fQ4++GAqKysZN24cAPfccw/vvfcekM0s2mKLLZacv/nmmzNjxowq2zYzMzODEpsplP5w3RXYA3gIODe/PiIqJT0HbAu8VKS8WNvbkM2GOYHsD/Rb8qr/C6yXEjWfAPsAj6yIawIGpf4eLSg/ERgaEf/JFeQSTZIuA/4WEdNS+TRJF5PNXPqfdPgw4BDgdqAceBZY1sTCUiS1AI4GtoqIRSmOWyQdQ5aAGl3N6X2BU4A7JW0eEe/Xpe+I+AT4RNL+BeUfks36ISJmS3od2IxsBlN1sVwFHE82A+i5vLphwKFkSchfkSW8OtYl1pwaxtdEoJmkvSLiiSpOLzZGlktETJb0EHA6sA5wa0S8XST+dmQzjp4HdgT2k3QG8COgOXBPRJwr6WRgU+ApSZ9FxB75M8Ak/Rk4JjV7U0RcWaS/fmRJK1q33ohzOleukGs2W1k2aZ7NFjLLqaioYPbs2QwdOpTbb7+dli1bct5553H22Wdz2mmnccwxx7Bw4UK6d+/O/PnzqaioYObMmbz88stL9hj64osvGD9+PHPmzFkhMc2ZM4eKiooV0pbZyuJxao2Fx6o1FCWVFCKb+fJYRLwpaaakHYGZucqUqPgZcE7+ScXKCxxKlgQYA7SXtElEfJxXfw/ZDJeXyRJOC1bA9QD8B+glaQ9gdl55J2BokXM6svQsmXF8d5bHm8ABkjYgS3zczneTQs0lTch7f3FE3FWHuLcF3o2Ir6qIoyNFkkJpiVebiHhB0t1kiavL69BvraQkRleyJEaxY9YmWw72O6AV2X3KTwqNBm6U1IRsfPQD/rqMIdU0vi4CLgCqSgoVGyMrwgCy8fwN0L2GY7cDjoyIsQCSzoqIz9P9GS2pS0RcnRI/exQuA0z/vR5NtqRNwPOSno6Ilws7iogbgBsA2m69bVw+qdR+1Fljc0rnSjxOLd/0w8sZPnw4Xbt2pWfPngB88MEHjB07losuuogTT8z+l/3444+zYMECysvL6dKlC61bt6a8vByAuXPncsABB6yw5WMVFRVL2jZrqDxOrbHwWLWGotSWj/Ul+8Oa9D23/GiblOB4Fng4t0dKNeVF2057Dt1LlgDKd3cq6wv8azmvo9CFwNkruE3IZrYcSvZH+JiCusLlY3VJCC2PQ8juJXz3M1xh0oyye4E/VpG0yvdL4KmImJ+O75kSHDmLyGYJHQo0j4jpyxFWteMrIp5Jse9a5PyqxkgUObZY+dIHRswF7gJui4iaEp3/zSWEkoMlvUSWKO1ItkSzOrsC90XE3IiYQzY+f1rbWM3MGpu2bdsyduxY5s2bR0QwevRodthhBz755BMAFixYwCWXXMJxxx0HwAEHHMCtt95KRDB27FjWX3997ydkZmZm1SqZf5aUtCHZsqTOkgJoQvbH72C+3TuoULHywrY7k82CeCJtK7Mm2YbK1+aOiYiPJC0k24PmD8Auy3M9+SLiSUkXku2Dk/Mq2TKdB6o45bVUNzGvbMd0Tr67yDanHhoRi5feMme5vA20lbRubjPrvDhGVnNeX+D7kg5P7zeVtF1EvLUigpLUjCzpckdEjKjh8L7Arml5E8D3yMZY/mydYWQbm5+3HDHVOL6Si8gSP0utQSkyRmYCGxQcuiFQ7UbdVVicvmoyN/dC0lZAf+BHEfFF2tx87Tr2WyvNmzVhysD9az7QrB5VVFQw/fDy+g7DGpgePXrQp08funXrRtOmTenatSv9+vXj7LPPZuTIkSxevJjjjz+ePffcE4D99tuPRx55hG233ZYWLVpwyy231NCDmZmZlbqSSQoBfchmM/wuVyDpaWCL4qfUWl/gvIi4OK/taZK2LDjuHGDjiFi0ghMskM0EuQ54J72/FnhB0sMR8XyK6Vdks54uA4ZLejIipqelUmeS3aMlIuK/ks4C/m9FBxsRcyUNJduo+Lh0T44g22D4yarOkbQ92ZO0NssrG0B2/89f3pjSRtH/BF6PiL/XcOx6ZLNUtsjNkJF0dIolPyk0BriY5ZsdVqvxFRGPS7qAtKF1FQrHyIvAtZK+n5KW3YG1gPeWI9baWo8sSfRl2mtrX6Ai1c0m24C8MDk1BhgiaSDZ8rFefLsHlpnZamnAgAEMGDDgO2WDBg1i0KBBSx0ricGDB6+q0MzMzGw1UEpJob7AJQVl9wJ/WQFtH0r29LB896XyJXvSpCdurRQR8YikT/PefyzpULKnim1MNpPjGbI9lT6WdDrwUJoZsxA4LSImVNHu9UW6LNxT6LHIeyR7Lf2FLEH1pqTFwBtAr4gotnypL9l9zXcv2YymXFLoldQWwN0R8efCRiR9n2zvovWAxekR6B3InjL3P8CkvGs7MyKq2hS8F/BkwZKpB4BLJa2VK0jXUrh/U13VanwlF1H17LBiY+QPwCPpaWBzgL5pidpKFRETJb1M9pm/R5aszLkBeEzSBxGxR945L6UZRS+kopuq2k/IzMzMzMzMakfF//42M2v82rdvH1OmTKnvMMyq5c0mrTHwOLXGwOPUGguPVVuVJI2PiCofDFRqG02bmZmZmZmZmRmltXxsuaUNf28rKF4QET1WQl+DgZ8UFF8VEQ1210hJ9wFbFRSfHhGj6imeo8k29c73bEScWMd2VslnsSrH18oi6XvA6CqqfhYRM1d1PGZmZmZmZlack0J1EBGTgLJV1FedEhcNQUT0qu8Y8qWkzXInblbVZ7Eqx9fKkhI/ZfUdh5mZmZmZmdXMy8fMzMzMzMzMzEqQk0JmZmZmZmZmZiXISSEzMzMzMzMzsxLkpJCZmZmZmZmZWQlyUsjMzMzMzMzMrAQ5KWRmZmZmZmZmVoKcFDIzMzMzMzMzK0FOCpmZmZmZmZmZlSAnhczMzMzMzMzMSpCTQmZmZmZmZmZmJchJITMzMzMzMzOzEuSkkJmZmZmZmZlZCXJSyMzMzKwBueKKK+jYsSOdOnWib9++fP3114wePZpu3bpRVlbGrrvuytSpUwF45pln6NatG02bNuWee+6p58jNzMyssXFSyMzMzKyBmDFjBldffTXjxo1j8uTJLFq0iGHDhnH88cdzxx13MGHCBA477DAuvPBCANq2bcuQIUM47LDD6jlyMzMza4ya1ncAtvqQ1BO4D9ghIt6Q1A54HZgCrAk8A5wAtK2qPCIWV9HmGsCVwJ5AAF8DB0fENEktgcuBnwOzgNnA6RHxvKTNgcFAB7Lk50jg1Ij4RlI58AAwDVgbGBkR/VN/RwGDgBl5YRyW4vwHsB6wCLgoIu4qch/uA7YCWgIbpX5I1z4OuBT4Zbqe14ATI+L9au7rImBSXtGwiBgoqQLYGtgyIiIdez/w84hoWcP9HxkRnQr6qfKeAecCTSPi9HTclsBTQLeImFVFvBVAG7LP6hvgtxExIa/+SuAgYAugI3BbqmoLfJm+PgN+kx+npF2Bv5N9BgB/j4gbit23nPkLF9HujIdrOsysXp3SuZKjPE5L3vSB+wNQWVnJ/PnzadasGfPmzWPTTTdFEl999RUAX375JZtuuikA7dq1A2CNNfzvfGZmZlZ3TgrZitQX+Hf6fm4qezsiyiQ1BZ4EegIvFSkfUUWbhwCbAl0iYnFKXMxNdTeRJVy2S3VbAR0kKbX1j4g4UFIT4AbgIrIkB8CYiPilpObAy5Lui4hnU91dEXFSfhCStgeOiIi3JG0KjJc0qqqkSET0SueUA/0j4pd57VwGrAu0j4hFko4GRkjqkUvsVGF+RJQVqZsF/AT4t6RWZMmYfMXu/3fUcM/OASZIGhIRrwNXAX+t6trzHB4R49L1DQL2Sv2sAfQC3gN2j4ingLJUN4QsCXRPet8uL77vA3cCPSPiJUmtgVGSZkSE/5I2s9XGZpttRv/+/Wnbti3Nmzdn7733Zu+99+amm25iv/32o3nz5qy33nqMHTu2vkM1MzOz1YCTQrZCpFk7uwJ7AA/xbVIIgIiolPQcsC15SYmC8qq0AT7MzSLKzaiRtA3Qgyz5kKubBkyT9DPg64i4JZUvkvSnVFcY13xJE4DNqru+iHgz7/UHkj4hmwU0q7rz8klqARwNbBURi1Jbt0g6hmwm1OjatpVnGHAoWTLuV2SJnY5VxF/l/c+zJ0XuGdln+SdgcC6pFRF31DK+//BtIg6gHHgVuIssefhULds5ERgSES+l+D6TdBpwHrBUUkhSP6AfQOvWG3FO58padmNWPzZpns0WstJWUVHB7NmzGTp0KLfffjstW7bkvPPO46yzzmLMmDFccMEFdOjQgWHDhtG3b19OPfXbH68fffQRr776Kq1bt15p8c2ZM4eKioqV1r7ZiuBxao2Fx6o1FE4K2YpyIPBYRLwpaaakHYGZucqUEPkZ2awTairPczfZLJifkiVNbo+Il8kSHxNyyZUCHYHx+QUR8ZWkdylIPknaANiObGlVziFpqVLOjyNift45O5Etx3q7SMzFbAu8GxFfFZSPSzEXSwo1T4mrnIvzlq6NBm5MM3sOJUuE/LWwgVrc52rvWUQ8IulYYChZ8q+29gHuz3vfF/gX2fK9v0lqFhELa9FOx9R3vtx9W0paVnYDQNutt43LJ/lHnTVsp3SuxOPUph9ezvDhw+natSs9e/YE4IMPPuA///kPM2bM4IQTTgBg6623Zp999qG8vHzJuUOGDKFjx47fKVvRKioqVmr7ZiuCx6k1Fh6r1lB4AbqtKH3JZq2QvvdNr7dJCY1ngYcj4tEayr8jzQxqD/wFWAyMTjOBltdPJU0k2ztoVER8lFd3V0SU5X3lJ4TakO2Bc3RVeyCtJPML4snfy2gR2SyhQ4HmETG94Nxa3edaGgy8GBFTanHsHZKmAWel85C0JrAfcH9KjD0P/GI54jEzW+20bduWsWPHMm/ePCKC0aNH06FDB7788kvefDObtPrEE0+www471HOkZmZmtjrwP0vacpO0Idnyo86SAmhCtonyYNKeNlWcVqx8KRGxAHgUeFTSx2T74lwJ/FBSkypmC70G9CmIcT2yjYynAjvx7Z5CWwFjJd2dvxlyketcj2yp0lkRsSybObwNtJW0bkTMzivfkWxT52U1jGyD7/Oq6rOW97mmewZZUq62ibDDyWYeDQKuIVva9gugFTAp28KIFsB8anftr5HdpwfyynYkW4pWrebNmjAlbd5q1lBVVFQw/fDy+g7DGoAePXrQp0+fJY+Z79q1K/369WPzzTend+/erLHGGmywwQbcfPPNALz44ov06tWLL774goceeohzzz2XV1+t8UejmZmZGeCZQrZi9AFui4gtI6JdRGxBthfNFsvbsKRuaWPn3CbFXYD/RsTbZMuHBqRNkpHUTtL+ZEuqWkg6IpU3IXtK2ZCImJffftqHaCBweg1xrEmWeLk1txFyXUXEXLIlUH9PMZFibEG2CfSyGgNcTLYsa1nV+p7VVto4+6/AzpJ+QDZ77DdpjLQje0LbXmlpW00GA0dJKkvxfQ+4hOxJbmZmq5UBAwbwxhtvMHnyZG677TbWWmstevXqxaRJk5g4cSIVFRVsvfXWAPzoRz/i/fffZ+7cucycOdMJITMzM6sTJ4VsRehLljDJdy/Zkq/ltTHwkKTJwCtAJXBtqvsNsAkwNdUPAT5JyYhewEGS3gLeJHs8+plF+rgO2C3vaVeHSJqQ97ULcDCwG1liIldetgzX85cUy5sptoOAXtU8eQzSnkJ5XwPzKyNzWUR8Voc42kt6P/dFltiryz2rlbT07nKypNs+5G0KnZJk/wb+Xy3a+RD4Ndn+SW8AzwE3R8RDyxOfmZmZmZlZKVP1f4uamTVu7du3jylTarMNkln98WaT1hh4nFpj4HFqjYXHqq1KksZHRPeq6jxTyMzMzMzMzMysBHmjaWsQJHUme6pXvgUR0aM+4qktSfeR7Y2T7/SIGFXHdr5H1Y+k/1lEzFzW+FamFXXtZmZmZmZmVj+cFLIGISImAWX1HUddRUSvFdTOTBrZ9a+oazczMzMzM7P64eVjZmZmZmZmZmYlyEkhMzMzMzMzM7MS5KSQmZmZmZmZmVkJclLIzMzMzMzMzKwEOSlkZmZmZmZmZlaCnBQyMzMzMzMzMytBTgqZmZmZmZmZmZUgJ4XMzMzMzMzMzEqQk0JmZmZmZmZmZiXISSEzMzMzMzMzsxLkpJCZmZmZmZmZWQlyUsjMzMzMzMzMrAQ5KWRmZmZmZmZmVoKcFDIzMzMzMzMzK0FOCpmZmZmZmZmZlSAnhczMzMzMzMzMSpCTQmZmZmZmZmZmJUgRUd8xmJmtNJJmA1PqOw6zGrQGPqvvIMxq4HFqjYHHqTUWHqu2Km0ZERtVVdF0VUdiZraKTYmI7vUdhFl1JI3zOLWGzuPUGgOPU2ssPFatofDyMTMzMzMzMzOzEuSkkJmZmZmZmZlZCXJSyMxWdzfUdwBmteBxao2Bx6k1Bh6n1lh4rFqD4I2mzczMzMzMzMxKkGcKmZmZmZmZmZmVICeFzMzMzMzMzMxKkJNCZrZakrSPpCmSpko6o77jsdImabqkSZImSBqXyjaU9ISkt9L3DVK5JF2dxu4rkrrVb/S2OpN0s6RPJE3OK6vz2JR0ZDr+LUlH1se12OqryDg9T9KM9HN1gqT98ur+ksbpFEm/yCv37wa20kjaQtJTkl6T9KqkP6Ry/0y1Bs1JITNb7UhqAgwG9gU6AH0ldajfqMzYIyLKIqJ7en8GMDoitgNGp/eQjdvt0lc/4B+rPFIrJUOAfQrK6jQ2JW0InAv0AHYCzs390WO2ggxh6XEKcEX6uVoWEY8ApP/fHwp0TOf8r6Qm/t3AVoFK4JSI6ADsDJyYxph/plqD5qSQma2OdgKmRsQ7EfENMAw4sJ5jMit0IDA0vR4K9MwrvzUyY4FWktrUQ3xWAiLiGeDzguK6js1fAE9ExOcR8QXwBFX/AW+2TIqM02IOBIZFxIKImAZMJfu9wL8b2EoVER9GxEvp9WzgdWAz/DPVGjgnhcxsdbQZ8F7e+/dTmVl9CeBxSeMl9Utlm0TEh+n1R8Am6bXHr9W3uo5Nj1mrLyelZTc3582k8Di1eiepHdAVeB7/TLUGzkkhMzOzlW/XiOhGNlX8REm75VdGRJAljswaFI9Na8D+AWwDlAEfApfXazRmiaSWwL3AHyPiq/w6/0y1hshJITNbHc0Atsh7v3kqM6sXETEjff8EuI9sGcPHuWVh6fsn6XCPX6tvdR2bHrO2ykXExxGxKCIWAzeS/VwFj1OrR5KakSWE7oiIEanYP1OtQXNSyMxWRy8C20naStKaZBtOPljPMVmJkrSOpHVzr4G9gclkYzL3RJEjgQfS6weBI9JTSXYGvsybdm62KtR1bI4C9pa0QVrCs3cqM1tpCvZa60X2cxWycXqopLUkbUW2ie8L+HcDW8kkCfgn8HpE/D2vyj9TrUFrWt8BmJmtaBFRKekksv+BNgFujohX6zksK12bAPdlvyvSFLgzIh6T9CJwt6Rjgf8CB6fjHwH2I9scdR5w9KoP2UqFpH8B5UBrSe+TPfFmIHUYmxHxuaQLyP7oBjg/Imq7KbBZjYqM03JJZWRLcaYDvwOIiFcl3Q28RvY0qBMjYlFqx78b2Mr0E+B/gEmSJqSyM/HPVGvglC1rNDMzMzMzMzOzUuLlY2ZmZmZmZmZmJchJITMzMzMzMzOzEuSkkJmZmZmZmZlZCXJSyMzMzMzMzMysBDkpZGZmZmZmZmZWgpwUMjMzM7MGTdIiSRPyvtotQxs9JXVYCeEhaVNJ96yMtqvps0zSfquyTzMzW/00re8AzMzMzMxqMD8iypazjZ7ASOC12p4gqWlEVNZ0XER8APRZ9tDqRlJToAzoDjyyqvo1M7PVj2cKmZmZmVmjI2lHSU9LGi9plKQ2qfy3kl6UNFHSvZJaSNoFOAAYlGYabSOpQlL3dE5rSdPT66MkPSjpSWC0pHUk3SzpBUkvSzqwiljaSZqcd/79kp6QNF3SSZL+nM4dK2nDdFyFpKtSPJMl7ZTKN0znv5KO75LKz5N0m6RngduA84FD0vmHSNpJ0n9SP89Jap8XzwhJj0l6S9KleXHvI+mldK9Gp7Iar9fMzFYfnilkZmZmZg1dc0kT0utpwMHANcCBEfGppEOAi4BjgBERcSOApAuBYyPiGkkPAiMj4p5UV11/3YAuEfG5pL8BT0bEMZJaAS9I+r+ImFvN+Z2ArsDawFTg9IjoKukK4AjgynRci4gok7QbcHM6bwDwckT0lLQncCvZrCCADsCuETFf0lFA94g4KV3PesBPI6JS0s+BvwG903llKZ4FwBRJ1wBfAzcCu0XEtFyyCjhrGa7XzMwaKSeFzMzMzKyh+87yMUmdyBIoT6TkThPgw1TdKSWDWgEtgVHL0N8TEfF5er03cICk/un92kBb4PVqzn8qImYDsyV9CTyUyicBXfKO+xdARDwjab2UhNmVlMyJiCclfS8lfAAejIj5RfpcHxgqaTsggGZ5daMj4ksASa8BWwIbAM9ExLTU1/Jcr5mZNVJOCpmZmZlZYyPg1Yj4cRV1Q4CeETExzaYpL9JGJd9upbB2QV3+rBgBvSNiSh3iW5D3enHe+8V89/fvKDiv8H2h6mbrXECWjOqVNuKuKBLPIqr/G2BZrtfMzBop7ylkZmZmZo3NFGAjST8GkNRMUsdUty7woaRmwOF558xOdTnTgR3T6+o2iR4F/F5pSpKkrssf/hKHpDZ3Bb5Ms3nGkOKWVA58FhFfVXFu4fWsD8xIr4+qRd9jgd0kbZX6yi0fW5nXa2ZmDYyTQmZmZmbWqETEN2SJnEskTQQmALuk6r8CzwPPAm/knTYMODVtnrwNcBlwvKSXgdbVdHcB2VKsVyS9mt6vKF+n/q8Djk1l5wE7SnoFGAgcWeTcp4AOuY2mgUuBi1N7Na4GiIhPgX7AiHQP70pVK/N6zcysgVFETbNUzczMzMxsRZJUAfSPiHH1HYuZmZUuzxQyMzMzMzMzMytBnilkZmZmZmZmZlaCPFPIzMzMzMzMzKwEOSlkZmZmZmZmZlaCnBQyMzMzMzMzMytBTgqZmZmZmZmZmZUgJ4XMzMzMzMzMzErQ/wcIbdGyG1wi5wAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"test = pd.read_csv(\"../input/msba-6420-predictive-analytics-project/Alldata_v3/test.csv\",low_memory=False)\ntest = test.rename(columns = lambda x: re.sub('[^A-Za-z0-9_]+', '', x))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T13:27:44.989647Z","iopub.execute_input":"2022-04-22T13:27:44.990228Z","iopub.status.idle":"2022-04-22T13:27:52.725791Z","shell.execute_reply.started":"2022-04-22T13:27:44.990188Z","shell.execute_reply":"2022-04-22T13:27:52.725046Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Result for the model with all features (no scale_pos_weight)","metadata":{}},{"cell_type":"code","source":"prediction1 = clf1.predict_proba(test.drop(columns=['SK_ID_CURR']))\nresult1 = pd.DataFrame({'SK_ID_CURR':test['SK_ID_CURR'],\n              'TARGET':pd.DataFrame(prediction1)[1]})\n\nresult1.to_csv(\"Result_LGBM1.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T13:28:44.865826Z","iopub.execute_input":"2022-04-22T13:28:44.866084Z","iopub.status.idle":"2022-04-22T13:29:18.744224Z","shell.execute_reply.started":"2022-04-22T13:28:44.866057Z","shell.execute_reply":"2022-04-22T13:29:18.743484Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Tuning the scale_pos_weight parameter to handle imbalanced data","metadata":{}},{"cell_type":"code","source":"def LGB_CV(scale_pos_weight):\n    params = clf1.get_params()\n    params['scale_pos_weight'] = int(round(scale_pos_weight))\n    params['early_stopping_round'] = 30\n    cv_result = lgb.cv(params, lgb.Dataset(data=train.drop(columns=['TARGET','SK_ID_CURR']), label=train['TARGET']), nfold=5, seed=6, stratified=True,metrics=['auc'],verbose_eval=False)\n    return max(cv_result['auc-mean'])","metadata":{"execution":{"iopub.status.busy":"2022-04-21T21:58:45.350656Z","iopub.execute_input":"2022-04-21T21:58:45.350971Z","iopub.status.idle":"2022-04-21T21:58:45.356865Z","shell.execute_reply.started":"2022-04-21T21:58:45.350940Z","shell.execute_reply":"2022-04-21T21:58:45.355946Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"LightGBM_BO1 = BayesianOptimization(LGB_CV,{'scale_pos_weight': (2,10)},random_state=0, verbose=-1)\n\nLightGBM_BO1.maximize(init_points=1, n_iter=3)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-04-21T21:59:13.924868Z","iopub.execute_input":"2022-04-21T21:59:13.925563Z","iopub.status.idle":"2022-04-22T00:23:29.482343Z","shell.execute_reply.started":"2022-04-21T21:59:13.925524Z","shell.execute_reply":"2022-04-22T00:23:29.481563Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"|   iter    |  target   | scale_... |\n-------------------------------------\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 64668\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 435 dense feature groups (102.29 MB) transferred to GPU in 0.213983 secs. 1 sparse feature groups\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 64668\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 435 dense feature groups (102.29 MB) transferred to GPU in 0.214277 secs. 1 sparse feature groups\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 64668\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 435 dense feature groups (102.29 MB) transferred to GPU in 0.224811 secs. 1 sparse feature groups\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 64668\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 435 dense feature groups (102.29 MB) transferred to GPU in 0.218846 secs. 1 sparse feature groups\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 64668\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 435 dense feature groups (102.29 MB) transferred to GPU in 0.216014 secs. 1 sparse feature groups\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7921  \u001b[0m | \u001b[0m 7.433   \u001b[0m |\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 64668\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 435 dense feature groups (102.29 MB) transferred to GPU in 0.219522 secs. 1 sparse feature groups\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 64668\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 435 dense feature groups (102.29 MB) transferred to GPU in 0.218098 secs. 1 sparse feature groups\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 64668\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 435 dense feature groups (102.29 MB) transferred to GPU in 0.218955 secs. 1 sparse feature groups\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 64668\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 435 dense feature groups (102.29 MB) transferred to GPU in 0.220994 secs. 1 sparse feature groups\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 64668\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 435 dense feature groups (102.29 MB) transferred to GPU in 0.349425 secs. 1 sparse feature groups\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n| \u001b[95m 2       \u001b[0m | \u001b[95m 0.793   \u001b[0m | \u001b[95m 2.001   \u001b[0m |\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 64668\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 435 dense feature groups (102.29 MB) transferred to GPU in 0.220796 secs. 1 sparse feature groups\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 64668\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 435 dense feature groups (102.29 MB) transferred to GPU in 0.226333 secs. 1 sparse feature groups\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 64668\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 435 dense feature groups (102.29 MB) transferred to GPU in 0.213696 secs. 1 sparse feature groups\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 64668\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 435 dense feature groups (102.29 MB) transferred to GPU in 0.222200 secs. 1 sparse feature groups\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 64668\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 435 dense feature groups (102.29 MB) transferred to GPU in 0.218483 secs. 1 sparse feature groups\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n| \u001b[95m 3       \u001b[0m | \u001b[95m 0.793   \u001b[0m | \u001b[95m 2.029   \u001b[0m |\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 64668\n[LightGBM] [Info] Number of data points in the train set: 246004, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 435 dense feature groups (102.29 MB) transferred to GPU in 0.383320 secs. 1 sparse feature groups\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 64668\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 435 dense feature groups (102.29 MB) transferred to GPU in 0.223959 secs. 1 sparse feature groups\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 64668\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 435 dense feature groups (102.29 MB) transferred to GPU in 0.227113 secs. 1 sparse feature groups\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] Number of positive: 19859, number of negative: 226146\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 64668\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 435 dense feature groups (102.29 MB) transferred to GPU in 0.223540 secs. 1 sparse feature groups\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] Number of positive: 19860, number of negative: 226145\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 64668\n[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 882\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 435 dense feature groups (102.29 MB) transferred to GPU in 0.238039 secs. 1 sparse feature groups\n[LightGBM] [Warning] Unknown parameter: silent\n[LightGBM] [Warning] Unknown parameter: importance_type\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432519\n[LightGBM] [Info] Start training from score -2.432519\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080726 -> initscore=-2.432524\n[LightGBM] [Info] Start training from score -2.432524\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432469\n[LightGBM] [Info] Start training from score -2.432469\n| \u001b[0m 4       \u001b[0m | \u001b[0m 0.793   \u001b[0m | \u001b[0m 2.425   \u001b[0m |\n=====================================\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 2. Building a Model with the best parameters - handling for Imbalanced data with scale_pos_weight","metadata":{}},{"cell_type":"code","source":"clf2 = lgb.LGBMClassifier(objective='binary',\n                         metric='auc',\n                         device='gpu',\n                         gpu_platform_id=0,\n                         gpu_device_id=0,\n                         max_bin=150,\n                         bagging_fraction= LightGBM_BO.max['params']['bagging_fraction'],\n                         colsample_bytree= LightGBM_BO.max['params']['colsample_bytree'],\n                         lambda_l2= LightGBM_BO.max['params']['lambda_l2'],\n                         learning_rate= LightGBM_BO.max['params']['learning_rate'],\n                         max_depth= int(round(LightGBM_BO.max['params']['max_depth'])),\n                         min_child_weight= LightGBM_BO.max['params']['min_child_weight'],\n                         min_split_gain= LightGBM_BO.max['params']['min_split_gain'],\n                         n_estimators= int(round(LightGBM_BO.max['params']['n_estimators'])),\n                         num_leaves= int(round(LightGBM_BO.max['params']['num_leaves'])),\n                         reg_alpha= LightGBM_BO.max['params']['reg_alpha'],\n                         min_child_samples = int(round(LightGBM_BO.max['params']['min_child_samples'])),\n                         scale_pos_weight = int(round(LightGBM_BO1.max['params']['scale_pos_weight'])))\nclf2","metadata":{"execution":{"iopub.status.busy":"2022-04-22T13:32:21.377867Z","iopub.execute_input":"2022-04-22T13:32:21.378159Z","iopub.status.idle":"2022-04-22T13:32:21.385838Z","shell.execute_reply.started":"2022-04-22T13:32:21.378128Z","shell.execute_reply":"2022-04-22T13:32:21.385009Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"LGBMClassifier(bagging_fraction=0.5912384186379205,\n               colsample_bytree=0.22489950447691787, device='gpu',\n               gpu_device_id=0, gpu_platform_id=0, lambda_l2=7.2476570775749085,\n               learning_rate=0.010091730086664408, max_bin=150, max_depth=12,\n               metric='auc', min_child_samples=148,\n               min_child_weight=18.396999797852718,\n               min_split_gain=0.15249740640007858, n_estimators=9751,\n               num_leaves=21, objective='binary', reg_alpha=1.6477598520053405,\n               scale_pos_weight=2)"},"metadata":{}}]},{"cell_type":"code","source":"clf2.fit(train.drop(columns=['TARGET','SK_ID_CURR']),train['TARGET'], eval_metric= 'roc_auc',verbose=200)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T13:32:42.092829Z","iopub.execute_input":"2022-04-22T13:32:42.093096Z","iopub.status.idle":"2022-04-22T13:53:33.992018Z","shell.execute_reply.started":"2022-04-22T13:32:42.093067Z","shell.execute_reply":"2022-04-22T13:53:33.991336Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] bagging_fraction is set=0.5912384186379205, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5912384186379205\n[LightGBM] [Warning] lambda_l2 is set=7.2476570775749085, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.2476570775749085\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"LGBMClassifier(bagging_fraction=0.5912384186379205,\n               colsample_bytree=0.22489950447691787, device='gpu',\n               gpu_device_id=0, gpu_platform_id=0, lambda_l2=7.2476570775749085,\n               learning_rate=0.010091730086664408, max_bin=150, max_depth=12,\n               metric='auc', min_child_samples=148,\n               min_child_weight=18.396999797852718,\n               min_split_gain=0.15249740640007858, n_estimators=9751,\n               num_leaves=21, objective='binary', reg_alpha=1.6477598520053405,\n               scale_pos_weight=2)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Result for the model with all features","metadata":{}},{"cell_type":"code","source":"prediction2 = clf2.predict_proba(test.drop(columns=['SK_ID_CURR']))\nresult2 = pd.DataFrame({'SK_ID_CURR':test['SK_ID_CURR'],\n              'TARGET':pd.DataFrame(prediction2)[1]})\n\nresult2.to_csv(\"Result_LGBM2.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T13:53:33.993939Z","iopub.execute_input":"2022-04-22T13:53:33.994193Z","iopub.status.idle":"2022-04-22T13:54:03.676564Z","shell.execute_reply.started":"2022-04-22T13:53:33.994156Z","shell.execute_reply":"2022-04-22T13:54:03.675807Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## 3. Use the best classifier to build the final model - OOF predicitions","metadata":{}},{"cell_type":"code","source":"clf3 = clf1","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:08:17.212531Z","iopub.execute_input":"2022-04-22T15:08:17.212949Z","iopub.status.idle":"2022-04-22T15:08:17.216664Z","shell.execute_reply.started":"2022-04-22T15:08:17.212905Z","shell.execute_reply":"2022-04-22T15:08:17.215895Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"folds = KFold(n_splits = 5, shuffle=True, random_state = 6)\noof_preds = np.zeros(train.shape[0])\nprediction3 = np.zeros(test.shape[0])\n\nfor fold_idx, (train_idx , valid_idx) in enumerate(folds.split(train.drop(columns=['SK_ID_CURR','TARGET']))):\n    print(\"##### iteration \", fold_idx, 'starts')\n\n    clf3.fit(train.drop(columns=['SK_ID_CURR','TARGET']).iloc[train_idx, :],\n                   train['TARGET'].iloc[train_idx],\n                   eval_set=[(train.drop(columns=['SK_ID_CURR','TARGET']).iloc[train_idx, :], train['TARGET'].iloc[train_idx]),\n                             (train.drop(columns=['SK_ID_CURR','TARGET']).iloc[valid_idx, :], train['TARGET'].iloc[valid_idx])],\n                   eval_metric= 'auc', verbose= 200, \n                   early_stopping_rounds= 200)\n    gc.collect()\n    prediction3 += clf3.predict_proba(test.drop(columns=['SK_ID_CURR'])\n                                           ,num_iteration=clf3.best_iteration_)[:, 1] / folds.n_splits\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T02:15:15.050587Z","iopub.execute_input":"2022-04-22T02:15:15.050967Z","iopub.status.idle":"2022-04-22T03:58:35.889945Z","shell.execute_reply.started":"2022-04-22T02:15:15.050925Z","shell.execute_reply":"2022-04-22T03:58:35.888864Z"},"scrolled":true,"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"##### iteration  0 starts\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[200]\tvalid_0's auc: 0.776595\tvalid_1's auc: 0.767259\n[400]\tvalid_0's auc: 0.79312\tvalid_1's auc: 0.779212\n[600]\tvalid_0's auc: 0.802697\tvalid_1's auc: 0.785135\n[800]\tvalid_0's auc: 0.809872\tvalid_1's auc: 0.78839\n[1000]\tvalid_0's auc: 0.815921\tvalid_1's auc: 0.790386\n[1200]\tvalid_0's auc: 0.821182\tvalid_1's auc: 0.791464\n[1400]\tvalid_0's auc: 0.825812\tvalid_1's auc: 0.792346\n[1600]\tvalid_0's auc: 0.83018\tvalid_1's auc: 0.792862\n[1800]\tvalid_0's auc: 0.834402\tvalid_1's auc: 0.79331\n[2000]\tvalid_0's auc: 0.838434\tvalid_1's auc: 0.793664\n[2200]\tvalid_0's auc: 0.842328\tvalid_1's auc: 0.793958\n[2400]\tvalid_0's auc: 0.846036\tvalid_1's auc: 0.794145\n[2600]\tvalid_0's auc: 0.849602\tvalid_1's auc: 0.79428\n[2800]\tvalid_0's auc: 0.853056\tvalid_1's auc: 0.794515\n[3000]\tvalid_0's auc: 0.856442\tvalid_1's auc: 0.794673\n[3200]\tvalid_0's auc: 0.859733\tvalid_1's auc: 0.794807\n[3400]\tvalid_0's auc: 0.862967\tvalid_1's auc: 0.794943\n[3600]\tvalid_0's auc: 0.866066\tvalid_1's auc: 0.79498\n[3800]\tvalid_0's auc: 0.869183\tvalid_1's auc: 0.794898\n##### iteration  1 starts\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[200]\tvalid_0's auc: 0.775796\tvalid_1's auc: 0.767688\n[400]\tvalid_0's auc: 0.792627\tvalid_1's auc: 0.780557\n[600]\tvalid_0's auc: 0.802204\tvalid_1's auc: 0.786384\n[800]\tvalid_0's auc: 0.809608\tvalid_1's auc: 0.789791\n[1000]\tvalid_0's auc: 0.815738\tvalid_1's auc: 0.792069\n[1200]\tvalid_0's auc: 0.821029\tvalid_1's auc: 0.793548\n[1400]\tvalid_0's auc: 0.825811\tvalid_1's auc: 0.794375\n[1600]\tvalid_0's auc: 0.830192\tvalid_1's auc: 0.794906\n[1800]\tvalid_0's auc: 0.834343\tvalid_1's auc: 0.795272\n[2000]\tvalid_0's auc: 0.838242\tvalid_1's auc: 0.7956\n[2200]\tvalid_0's auc: 0.842048\tvalid_1's auc: 0.795789\n[2400]\tvalid_0's auc: 0.845776\tvalid_1's auc: 0.795987\n[2600]\tvalid_0's auc: 0.84943\tvalid_1's auc: 0.796149\n[2800]\tvalid_0's auc: 0.852943\tvalid_1's auc: 0.796268\n[3000]\tvalid_0's auc: 0.856428\tvalid_1's auc: 0.796419\n[3200]\tvalid_0's auc: 0.859735\tvalid_1's auc: 0.796412\n##### iteration  2 starts\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[200]\tvalid_0's auc: 0.776658\tvalid_1's auc: 0.764692\n[400]\tvalid_0's auc: 0.793513\tvalid_1's auc: 0.777264\n[600]\tvalid_0's auc: 0.803125\tvalid_1's auc: 0.783097\n[800]\tvalid_0's auc: 0.810465\tvalid_1's auc: 0.786368\n[1000]\tvalid_0's auc: 0.816686\tvalid_1's auc: 0.788429\n[1200]\tvalid_0's auc: 0.822061\tvalid_1's auc: 0.789834\n[1400]\tvalid_0's auc: 0.826875\tvalid_1's auc: 0.790732\n[1600]\tvalid_0's auc: 0.831314\tvalid_1's auc: 0.791268\n[1800]\tvalid_0's auc: 0.835495\tvalid_1's auc: 0.791747\n[2000]\tvalid_0's auc: 0.839448\tvalid_1's auc: 0.792037\n[2200]\tvalid_0's auc: 0.843286\tvalid_1's auc: 0.792423\n[2400]\tvalid_0's auc: 0.846915\tvalid_1's auc: 0.792552\n[2600]\tvalid_0's auc: 0.850438\tvalid_1's auc: 0.792751\n[2800]\tvalid_0's auc: 0.853951\tvalid_1's auc: 0.792984\n[3000]\tvalid_0's auc: 0.857318\tvalid_1's auc: 0.793173\n[3200]\tvalid_0's auc: 0.860531\tvalid_1's auc: 0.793291\n[3400]\tvalid_0's auc: 0.863773\tvalid_1's auc: 0.79338\n[3600]\tvalid_0's auc: 0.86693\tvalid_1's auc: 0.793532\n[3800]\tvalid_0's auc: 0.86998\tvalid_1's auc: 0.793603\n[4000]\tvalid_0's auc: 0.873022\tvalid_1's auc: 0.793696\n[4200]\tvalid_0's auc: 0.875944\tvalid_1's auc: 0.793825\n[4400]\tvalid_0's auc: 0.87878\tvalid_1's auc: 0.793916\n[4600]\tvalid_0's auc: 0.881541\tvalid_1's auc: 0.794048\n[4800]\tvalid_0's auc: 0.884296\tvalid_1's auc: 0.794142\n[5000]\tvalid_0's auc: 0.887053\tvalid_1's auc: 0.794272\n[5200]\tvalid_0's auc: 0.889685\tvalid_1's auc: 0.794294\n[5400]\tvalid_0's auc: 0.892227\tvalid_1's auc: 0.794367\n[5600]\tvalid_0's auc: 0.894724\tvalid_1's auc: 0.794353\n##### iteration  3 starts\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[200]\tvalid_0's auc: 0.776015\tvalid_1's auc: 0.767648\n[400]\tvalid_0's auc: 0.792723\tvalid_1's auc: 0.780468\n[600]\tvalid_0's auc: 0.802325\tvalid_1's auc: 0.786198\n[800]\tvalid_0's auc: 0.809715\tvalid_1's auc: 0.789294\n[1000]\tvalid_0's auc: 0.816005\tvalid_1's auc: 0.791374\n[1200]\tvalid_0's auc: 0.821394\tvalid_1's auc: 0.792561\n[1400]\tvalid_0's auc: 0.82611\tvalid_1's auc: 0.793258\n[1600]\tvalid_0's auc: 0.830576\tvalid_1's auc: 0.793659\n[1800]\tvalid_0's auc: 0.834741\tvalid_1's auc: 0.793924\n[2000]\tvalid_0's auc: 0.838696\tvalid_1's auc: 0.79422\n[2200]\tvalid_0's auc: 0.842499\tvalid_1's auc: 0.794296\n[2400]\tvalid_0's auc: 0.84623\tvalid_1's auc: 0.794454\n[2600]\tvalid_0's auc: 0.849874\tvalid_1's auc: 0.79456\n[2800]\tvalid_0's auc: 0.853382\tvalid_1's auc: 0.794625\n[3000]\tvalid_0's auc: 0.856817\tvalid_1's auc: 0.794699\n[3200]\tvalid_0's auc: 0.860162\tvalid_1's auc: 0.794758\n[3400]\tvalid_0's auc: 0.863443\tvalid_1's auc: 0.79481\n[3600]\tvalid_0's auc: 0.866583\tvalid_1's auc: 0.794763\n##### iteration  4 starts\n[LightGBM] [Warning] lambda_l2 is set=8.18198695183353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.18198695183353\n[LightGBM] [Warning] bagging_fraction is set=0.8497981211186849, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8497981211186849\n[200]\tvalid_0's auc: 0.777934\tvalid_1's auc: 0.761492\n[400]\tvalid_0's auc: 0.79464\tvalid_1's auc: 0.773027\n[600]\tvalid_0's auc: 0.804047\tvalid_1's auc: 0.778626\n[800]\tvalid_0's auc: 0.811389\tvalid_1's auc: 0.781966\n[1000]\tvalid_0's auc: 0.817615\tvalid_1's auc: 0.784181\n[1200]\tvalid_0's auc: 0.822914\tvalid_1's auc: 0.785398\n[1400]\tvalid_0's auc: 0.827667\tvalid_1's auc: 0.78612\n[1600]\tvalid_0's auc: 0.832098\tvalid_1's auc: 0.786653\n[1800]\tvalid_0's auc: 0.836343\tvalid_1's auc: 0.786995\n[2000]\tvalid_0's auc: 0.840369\tvalid_1's auc: 0.787308\n[2200]\tvalid_0's auc: 0.844249\tvalid_1's auc: 0.787593\n[2400]\tvalid_0's auc: 0.847956\tvalid_1's auc: 0.787792\n[2600]\tvalid_0's auc: 0.851453\tvalid_1's auc: 0.787982\n[2800]\tvalid_0's auc: 0.855152\tvalid_1's auc: 0.788185\n[3000]\tvalid_0's auc: 0.85845\tvalid_1's auc: 0.788366\n[3200]\tvalid_0's auc: 0.861699\tvalid_1's auc: 0.788512\n[3400]\tvalid_0's auc: 0.865015\tvalid_1's auc: 0.788676\n[3600]\tvalid_0's auc: 0.868183\tvalid_1's auc: 0.788736\n[3800]\tvalid_0's auc: 0.871302\tvalid_1's auc: 0.78881\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Result for the model with OOF prediction","metadata":{}},{"cell_type":"code","source":"result3 = pd.DataFrame({'SK_ID_CURR':test['SK_ID_CURR'],\n              'TARGET':predicition3})\n\nresult3.to_csv(\"Result_LGBM3.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T04:03:29.690810Z","iopub.execute_input":"2022-04-22T04:03:29.691661Z","iopub.status.idle":"2022-04-22T04:03:29.914187Z","shell.execute_reply.started":"2022-04-22T04:03:29.691604Z","shell.execute_reply":"2022-04-22T04:03:29.913041Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## 4. Building a model with top 400 features","metadata":{}},{"cell_type":"code","source":"clf4 = clf1\nclf4","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:09:33.887902Z","iopub.execute_input":"2022-04-22T15:09:33.888599Z","iopub.status.idle":"2022-04-22T15:09:33.899088Z","shell.execute_reply.started":"2022-04-22T15:09:33.888557Z","shell.execute_reply":"2022-04-22T15:09:33.898175Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"LGBMClassifier(bagging_fraction=0.5912384186379205,\n               colsample_bytree=0.22489950447691787, device='gpu',\n               gpu_device_id=0, gpu_platform_id=0, lambda_l2=7.2476570775749085,\n               learning_rate=0.010091730086664408, max_bin=150, max_depth=12,\n               metric='auc', min_child_samples=148,\n               min_child_weight=18.396999797852718,\n               min_split_gain=0.15249740640007858, n_estimators=9751,\n               num_leaves=21, objective='binary', reg_alpha=1.6477598520053405)"},"metadata":{}}]},{"cell_type":"code","source":"clf4.fit(train.drop(columns=['TARGET','SK_ID_CURR']),train['TARGET'], eval_metric= 'roc_auc',verbose=200)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:12:02.813324Z","iopub.execute_input":"2022-04-22T15:12:02.813600Z","iopub.status.idle":"2022-04-22T15:33:20.278206Z","shell.execute_reply.started":"2022-04-22T15:12:02.813570Z","shell.execute_reply":"2022-04-22T15:33:20.277481Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] bagging_fraction is set=0.5912384186379205, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5912384186379205\n[LightGBM] [Warning] lambda_l2 is set=7.2476570775749085, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.2476570775749085\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"LGBMClassifier(bagging_fraction=0.5912384186379205,\n               colsample_bytree=0.22489950447691787, device='gpu',\n               gpu_device_id=0, gpu_platform_id=0, lambda_l2=7.2476570775749085,\n               learning_rate=0.010091730086664408, max_bin=150, max_depth=12,\n               metric='auc', min_child_samples=148,\n               min_child_weight=18.396999797852718,\n               min_split_gain=0.15249740640007858, n_estimators=9751,\n               num_leaves=21, objective='binary', reg_alpha=1.6477598520053405)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Selecting Top 400 features","metadata":{}},{"cell_type":"code","source":"feature_importance = pd.DataFrame({'feature':clf4.feature_name_,\n                                   'importance':clf4.feature_importances_}).sort_values(by='importance',ascending=False).reset_index(drop=True)\ntop400 = feature_importance.iloc[:400,0].to_list()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:46:14.060108Z","iopub.execute_input":"2022-04-22T15:46:14.060375Z","iopub.status.idle":"2022-04-22T15:46:14.072987Z","shell.execute_reply.started":"2022-04-22T15:46:14.060345Z","shell.execute_reply":"2022-04-22T15:46:14.072213Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"clf4.fit(train[top400],train['TARGET'], eval_metric= 'roc_auc',verbose=200)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:47:10.978904Z","iopub.execute_input":"2022-04-22T15:47:10.979378Z","iopub.status.idle":"2022-04-22T15:55:47.247266Z","shell.execute_reply.started":"2022-04-22T15:47:10.979340Z","shell.execute_reply":"2022-04-22T15:55:47.246552Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"LGBMClassifier(bagging_fraction=0.5912384186379205,\n               colsample_bytree=0.22489950447691787, device='gpu',\n               gpu_device_id=0, gpu_platform_id=0, lambda_l2=7.2476570775749085,\n               learning_rate=0.010091730086664408, max_bin=150, max_depth=12,\n               metric='auc', min_child_samples=148,\n               min_child_weight=18.396999797852718,\n               min_split_gain=0.15249740640007858, n_estimators=9751,\n               num_leaves=21, objective='binary', reg_alpha=1.6477598520053405)"},"metadata":{}}]},{"cell_type":"code","source":"test = pd.read_csv(\"../input/msba-6420-predictive-analytics-project/Alldata_v3/test.csv\",low_memory=False)\ntest = test.rename(columns = lambda x: re.sub('[^A-Za-z0-9_]+', '', x))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:59:06.815957Z","iopub.execute_input":"2022-04-22T15:59:06.816271Z","iopub.status.idle":"2022-04-22T15:59:14.469246Z","shell.execute_reply.started":"2022-04-22T15:59:06.816238Z","shell.execute_reply":"2022-04-22T15:59:14.468469Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"prediction4 = clf4.predict_proba(test[top400])\nresult4 = pd.DataFrame({'SK_ID_CURR':test['SK_ID_CURR'],\n              'TARGET':pd.DataFrame(prediction4)[1]})\n\nresult4.to_csv(\"Result_LGBM4.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T15:59:14.470653Z","iopub.execute_input":"2022-04-22T15:59:14.470922Z","iopub.status.idle":"2022-04-22T15:59:43.472978Z","shell.execute_reply.started":"2022-04-22T15:59:14.470886Z","shell.execute_reply":"2022-04-22T15:59:43.472194Z"},"trusted":true},"execution_count":24,"outputs":[]}]}